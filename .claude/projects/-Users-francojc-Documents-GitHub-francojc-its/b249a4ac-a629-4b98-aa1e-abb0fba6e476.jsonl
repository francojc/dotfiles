{"type":"summary","summary":"Claude Creates CLAUDE.md for Research Project","leafUuid":"12392d75-c22b-487b-b4df-be8709537062"}
{"type":"summary","summary":"Permissions Command Execution with No Output","leafUuid":"60c17d12-086f-47bc-88a5-a17036723905"}
{"type":"summary","summary":"GitHub App Installation Failure: API Key Missing","leafUuid":"1a39b86e-7f27-49b5-885d-02ebd8972bf2"}
{"type":"summary","summary":"GitHub Actions App Installation Completed","leafUuid":"d4563f07-6ac7-4fa4-8a8e-cf44b9bd714f"}
{"type":"summary","summary":"CLI Config Setup: Verbose, Model, Editor Preferences","leafUuid":"84f6ee7f-dcd7-4d46-a416-a427a2041291"}
{"type":"summary","summary":"Terminal Command: Clear Screen Executed","leafUuid":"b9f1ce66-d431-4486-9b3d-49ba129819d2"}
{"type":"summary","summary":"Claude Pro Cost Check: Subscription Covers Usage","leafUuid":"693c1d07-0d91-4cd6-bf36-a48f430617c6"}
{"type":"summary","summary":"Local Command Execution: Doctor Command Attempted","leafUuid":"cea119f6-f7c5-4793-b7f5-f6f66f839088"}
{"type":"summary","summary":"MCP Server Configuration: Initial Setup Needed","leafUuid":"00aee62a-f52f-4cc2-bc65-953324e4e1bb"}
{"type":"summary","summary":"Gemma 3 LLM Research Proposal: Citation Markdown","leafUuid":"bc739802-ee22-4316-98c2-bf6f0e4f335d"}
{"type":"summary","summary":"Terminal Command: Clear Screen Executed","leafUuid":"d9119fcc-f0f0-49d3-96bb-552319bd1f33"}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to."},"isMeta":true,"uuid":"92ad797c-c7ff-4907-9258-b93d83c03789","timestamp":"2025-06-18T12:52:38.783Z"}
{"parentUuid":"92ad797c-c7ff-4907-9258-b93d83c03789","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"<command-name>mcp</command-name>\n            <command-message>mcp</command-message>\n            <command-args></command-args>"},"uuid":"89dc3626-b793-49d4-aa1b-0c25157d5ef7","timestamp":"2025-06-18T12:53:10.465Z"}
{"parentUuid":"89dc3626-b793-49d4-aa1b-0c25157d5ef7","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"<local-command-stdout>No MCP servers configured. Run `claude mcp` to learn about how to configure MCP servers.</local-command-stdout>"},"uuid":"1a6c4272-f998-47ff-86f7-3fb2034a8889","timestamp":"2025-06-18T12:53:10.465Z"}
{"type":"summary","summary":"LLM Tutoring Research: Bloom's 2 Sigma Problem Explored","leafUuid":"462a1a3d-9d61-4cb6-8161-ca684a51abce"}
{"type":"summary","summary":"LLM Tutoring Research: Bloom's 2 Sigma Problem Update","leafUuid":"8e6ad084-b62c-42e9-bde3-7c2f8e2339f7"}
{"type":"summary","summary":"ITS4LL: Adaptive AI Language Learning System Design","leafUuid":"658f106e-b838-4c43-84bf-779a5af4b73b"}
{"type":"summary","summary":"Terminal Command: Clear Screen Executed","leafUuid":"824ba31d-dab6-49d7-af68-939ef845508a"}
{"type":"summary","summary":"Update Image Paths in Quarto Markdown Files","leafUuid":"88fd6c67-218f-4f38-83a1-f8ab766194be"}
{"type":"summary","summary":"Repo Restructure: Scaling Research and Development","leafUuid":"33138986-2920-4a8a-aac0-5a483d250d97"}
{"type":"summary","summary":"Terminal Command: Clear Screen Executed","leafUuid":"c113f83c-d365-4869-a9d5-dc4ad523da36"}
{"type":"summary","summary":"Mermaid Diagrams Troubleshoot: Quarto Documentation Visualization","leafUuid":"75c0acdb-07d7-4c7d-bedc-c8588f47dcba"}
{"type":"summary","summary":"Terminal Command: Clear Screen Executed","leafUuid":"4edbeb1a-f063-4e00-b6dd-e01c31cf3f43"}
{"type":"summary","summary":"Local Command Exit and Empty Stdout","leafUuid":"13f7d5d6-43cc-49eb-bd60-55d88a1c0763"}
{"parentUuid":"1a6c4272-f998-47ff-86f7-3fb2034a8889","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"Help me plan to address the sections in the @docs/grants/research_leave.qmd documents which are part of a research leave proposal for my university research leave. Use the information about this project that I have amassed, primarily in the @docs/ section of this repo. Identify the sections which this repo already provids context for and then identify those sections (or subsections) which I still need to add more information to help adequately prepare this proposal."},"uuid":"cf9bd750-6af1-4ca3-bedc-720ddd136c90","timestamp":"2025-06-18T13:42:02.070Z"}
{"parentUuid":"cf9bd750-6af1-4ca3-bedc-720ddd136c90","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_014AqB1fUMhU3dUqYdrRAsWk","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"I'll analyze the research leave proposal document and examine the existing documentation in your repository to help you identify what's already covered and what still needs development."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":16684,"cache_read_input_tokens":0,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnPWrb2h2SZo6SbYH3H","type":"assistant","uuid":"2bdc43a1-c83a-4be3-913c-fc21899bf987","timestamp":"2025-06-18T13:42:06.282Z"}
{"parentUuid":"2bdc43a1-c83a-4be3-913c-fc21899bf987","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_014AqB1fUMhU3dUqYdrRAsWk","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01WXUxPeeHjcNU3AfTCMBhNP","name":"Read","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/docs/literature/literature_review.qmd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":16684,"cache_read_input_tokens":0,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnPWrb2h2SZo6SbYH3H","type":"assistant","uuid":"4121671a-06c6-4d81-8582-bd55c481dbb9","timestamp":"2025-06-18T13:42:07.760Z"}
{"parentUuid":"4121671a-06c6-4d81-8582-bd55c481dbb9","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_014AqB1fUMhU3dUqYdrRAsWk","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_012fNvyURWDGfa34zzUTAvWn","name":"Read","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/docs/research/technical-plan.qmd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":16684,"cache_read_input_tokens":0,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnPWrb2h2SZo6SbYH3H","type":"assistant","uuid":"2d17b4f9-9970-4dda-9d61-520a5ae27391","timestamp":"2025-06-18T13:42:08.799Z"}
{"parentUuid":"2d17b4f9-9970-4dda-9d61-520a5ae27391","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_014AqB1fUMhU3dUqYdrRAsWk","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01WuUDxUBzPqBmech8nMn29e","name":"Read","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/docs/grants/step_proposal.qmd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":16684,"cache_read_input_tokens":0,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnPWrb2h2SZo6SbYH3H","type":"assistant","uuid":"e3d5cdce-2a27-4384-86af-4b03513b9804","timestamp":"2025-06-18T13:42:09.867Z"}
{"parentUuid":"e3d5cdce-2a27-4384-86af-4b03513b9804","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_014AqB1fUMhU3dUqYdrRAsWk","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01HqhmD9imKifcf3r2NihDFG","name":"Read","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/index.qmd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":16684,"cache_read_input_tokens":0,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnPWrb2h2SZo6SbYH3H","type":"assistant","uuid":"742dda79-3fff-4bb4-8e41-b83d778c3798","timestamp":"2025-06-18T13:42:09.943Z"}
{"parentUuid":"742dda79-3fff-4bb4-8e41-b83d778c3798","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012fNvyURWDGfa34zzUTAvWn","type":"tool_result","content":"     1→---\n     2→title: \"Technical Implementation Plan\"\n     3→bibliography: ../../assets/data/references.bib\n     4→---\n     5→\n     6→# ITS4LL Technical Implementation Plan\n     7→\n     8→## Overview\n     9→\n    10→This document outlines the technical implementation approach for ITS4LL (Intelligent Tutoring Systems for Language Learning), an adaptive second language tutoring system using fine-tuned and RAG-enhanced local LLMs.\n    11→\n    12→## Current Architecture Assessment\n    13→\n    14→### Existing Infrastructure\n    15→\n    16→- **Documentation Platform**: Quarto-based website with R/Nix development environment\n    17→- **Version Control**: Git repository with academic content structure\n    18→- **Target Deployment**: WFU DEAC cluster with Ollama for local LLM deployment\n    19→- **Current State**: Research documentation phase, no implementation yet\n    20→\n    21→### Project Structure\n    22→\n    23→```\n    24→its/\n    25→├── _quarto.yml         # Website configuration\n    26→├── flake.nix           # Nix development environment\n    27→├── proposal.qmd        # STEP grant proposal\n    28→├── literature.qmd      # Literature review\n    29→├── posts/              # Research blog posts\n    30→└── research/           # Research documents\n    31→```\n    32→\n    33→## Recommended Implementation Stack\n    34→\n    35→### Core Application Architecture\n    36→\n    37→**Primary Language**: Python\n    38→\n    39→- Rationale: Best ecosystem for ML/NLP with extensive LLM tooling\n    40→- Rich libraries for fine-tuning, RAG, and deployment\n    41→\n    42→**Web Framework**: FastAPI\n    43→\n    44→- Async support for concurrent LLM requests\n    45→- Automatic OpenAPI documentation\n    46→- Easy integration with Python ML stack\n    47→- Production-ready with uvicorn\n    48→\n    49→**Frontend Strategy**:\n    50→\n    51→- **Phase 1**: Gradio (rapid prototyping, built-in chat interface)\n    52→- **Phase 2**: Streamlit (enhanced UI components)\n    53→- **Phase 3**: React/Next.js (production interface)\n    54→\n    55→### LLM Infrastructure\n    56→\n    57→**Local Deployment**: Ollama\n    58→\n    59→- Specified in grant proposal\n    60→- Simplified model management and serving\n    61→- GPU acceleration support\n    62→- REST API for integration\n    63→\n    64→**Base Models**:\n    65→\n    66→- **Gemma 3 27B**: Primary production model with 140+ language support and 128K context\n    67→- **Gemma 3 12B**: High-throughput fallback with multimodal capabilities\n    68→- **Gemma 3 4B**: Development and prototyping model with full feature set\n    69→\n    70→**Fine-tuning Framework**:\n    71→\n    72→- **Primary**: Unsloth (memory-efficient, fast training)\n    73→- **Alternative**: MLX-LM (Mac optimization for development)\n    74→- **Techniques**: LoRA/QLoRA for parameter-efficient fine-tuning\n    75→\n    76→### Gemma 3 Advantages for Language Learning\n    77→\n    78→**Multilingual Excellence**:\n    79→- Native support for 140+ languages including Spanish, French, German, Portuguese\n    80→- Cross-lingual understanding without translation overhead\n    81→- Cultural context awareness for authentic language learning\n    82→\n    83→**Extended Context Window**:\n    84→- 128K tokens enable entire curriculum chapters in single interactions\n    85→- Comprehensive document analysis and reference\n    86→- Long-form conversational tutoring sessions\n    87→\n    88→**Multimodal Capabilities**:\n    89→- Text and image processing for visual learning materials\n    90→- Grammar diagrams, cultural images, and infographics integration\n    91→- Enhanced engagement through visual explanations\n    92→\n    93→**Academic Suitability**:\n    94→- Google-backed with strong institutional credibility\n    95→- Apache 2.0 license for unrestricted academic use\n    96→- Built-in safety measures appropriate for educational settings\n    97→\n    98→### RAG Implementation\n    99→\n   100→```{mermaid}\n   101→graph TD\n   102→    A[Curriculum Documents<br/>PDFs, Images, Text] --> B[Document Loader<br/>LangChain]\n   103→    B --> C[Content Extraction<br/>Text + Metadata]\n   104→    C --> D[Chunking Strategy<br/>Educational Context]\n   105→    D --> E[Embedding Generation<br/>Multilingual Models]\n   106→    E --> F[Vector Database<br/>ChromaDB/Qdrant]\n   107→    \n   108→    G[Student Query] --> H[Query Embedding]\n   109→    H --> I[Similarity Search<br/>Vector DB]\n   110→    I --> J[Retrieved Documents<br/>+ Metadata]\n   111→    J --> K[Context Assembly<br/>128K Window]\n   112→    K --> L[Enhanced Prompt<br/>Curriculum + Query]\n   113→    L --> M[Fine-tuned LLM<br/>Gemma 3]\n   114→    M --> N[Pedagogical Response]\n   115→    \n   116→    O[Course Metadata<br/>Level, Topic, Culture] --> F\n   117→    P[Visual Content<br/>Diagrams, Images] --> E\n   118→    Q[Grammar Rules<br/>Vocabulary Lists] --> E\n   119→```\n   120→\n   121→**Vector Database**:\n   122→\n   123→- **Development**: ChromaDB (embedded, no server required)\n   124→- **Production**: Qdrant (scalable, persistent)\n   125→\n   126→**Embedding Models**:\n   127→\n   128→- sentence-transformers with multilingual models\n   129→- `paraphrase-multilingual-MiniLM-L12-v2` for cross-lingual retrieval\n   130→- Custom domain-specific embeddings if needed\n   131→\n   132→**Document Processing Pipeline**:\n   133→\n   134→- LangChain for document loading and chunking\n   135→- Custom parsers for curriculum materials (text, images, diagrams)\n   136→- Metadata extraction for course alignment\n   137→- Multimodal content integration (leveraging Gemma 3's vision capabilities)\n   138→\n   139→### Core Dependencies\n   140→\n   141→```python\n   142→# ML/NLP Core\n   143→transformers>=4.35.0\n   144→torch>=2.0.0\n   145→sentence-transformers>=2.2.0\n   146→unsloth>=2024.1\n   147→pillow>=10.0.0  # Multimodal image processing\n   148→\n   149→# RAG Components\n   150→chromadb>=0.4.0\n   151→langchain>=0.1.0\n   152→llama-index>=0.9.0\n   153→\n   154→# Web Framework\n   155→fastapi>=0.104.0\n   156→uvicorn>=0.24.0\n   157→pydantic>=2.5.0\n   158→gradio>=4.0.0\n   159→\n   160→# Data Processing\n   161→pandas>=2.0.0\n   162→numpy>=1.24.0\n   163→datasets>=2.14.0\n   164→\n   165→# Evaluation\n   166→rouge-score>=0.1.2\n   167→sacrebleu>=2.3.0\n   168→nltk>=3.8.0\n   169→```\n   170→\n   171→## Implementation Phases\n   172→\n   173→### Project Timeline\n   174→\n   175→```{mermaid}\n   176→gantt\n   177→    title ITS4LL Implementation Timeline\n   178→    dateFormat  X\n   179→    axisFormat %s\n   180→    \n   181→    section Phase 1: RAG Prototype\n   182→    Document ingestion system    :p1a, 0, 3d\n   183→    Vector store setup          :p1b, after p1a, 2d\n   184→    Basic RAG pipeline          :p1c, after p1b, 3d\n   185→    Gradio interface           :p1d, after p1c, 2d\n   186→    Evaluation metrics         :p1e, after p1d, 4d\n   187→    \n   188→    section Phase 2: Fine-tuning\n   189→    Dataset creation           :p2a, after p1e, 4d\n   190→    Training pipeline          :p2b, after p2a, 3d\n   191→    Model evaluation          :p2c, after p2b, 3d\n   192→    Ollama integration        :p2d, after p2c, 4d\n   193→    \n   194→    section Phase 3: Web Interface\n   195→    FastAPI backend           :p3a, after p2d, 4d\n   196→    Session management        :p3b, after p3a, 3d\n   197→    Progress tracking         :p3c, after p3b, 3d\n   198→    Enhanced frontend         :p3d, after p3c, 4d\n   199→    \n   200→    section Phase 4: DEAC Deployment\n   201→    Containerization          :p4a, after p3d, 3d\n   202→    DEAC setup               :p4b, after p4a, 3d\n   203→    Monitoring setup         :p4c, after p4b, 2d\n   204→    Pilot testing            :p4d, after p4c, 6d\n   205→```\n   206→\n   207→### Phase 1: RAG Prototype (Weeks 1-2)\n   208→\n   209→**Objectives**:\n   210→\n   211→- Implement basic RAG pipeline with existing models\n   212→- Create curriculum document ingestion system\n   213→- Develop simple chat interface\n   214→\n   215→**Deliverables**:\n   216→\n   217→- Working RAG system with course materials\n   218→- Gradio-based tutoring interface\n   219→- Basic evaluation metrics\n   220→\n   221→**Technical Tasks**:\n   222→\n   223→```python\n   224→# Core RAG components\n   225→- Document loader for curriculum PDFs/texts\n   226→- Chunking strategy for educational content\n   227→- Vector store setup with course metadata\n   228→- Retrieval-augmented generation pipeline\n   229→- Simple chat interface with Gradio\n   230→```\n   231→\n   232→### Phase 2: Fine-tuning Pipeline (Weeks 3-4)\n   233→\n   234→**Objectives**:\n   235→\n   236→- Develop pedagogical fine-tuning datasets\n   237→- Implement parameter-efficient fine-tuning\n   238→- Create model evaluation framework\n   239→\n   240→**Deliverables**:\n   241→\n   242→- Fine-tuned models for language tutoring\n   243→- Automated training pipeline\n   244→- Performance benchmarking system\n   245→\n   246→**Technical Tasks**:\n   247→\n   248→```python\n   249→# Fine-tuning infrastructure\n   250→- Dataset creation from language learning corpora\n   251→- LoRA/QLoRA training scripts with Unsloth\n   252→- Model evaluation on tutoring-specific metrics\n   253→- Integration with Ollama for deployment\n   254→```\n   255→\n   256→### Fine-tuning Pipeline Architecture\n   257→\n   258→```{mermaid}\n   259→graph LR\n   260→    A[Language Learning<br/>Corpora] --> B[Dataset<br/>Preparation]\n   261→    B --> C[Instruction<br/>Formatting]\n   262→    C --> D[Train/Val<br/>Split]\n   263→    \n   264→    E[Base Model<br/>Gemma 3] --> F[LoRA Adapter<br/>Configuration]\n   265→    F --> G[Parameter-Efficient<br/>Fine-tuning]\n   266→    \n   267→    D --> G\n   268→    H[Pedagogical<br/>Examples] --> B\n   269→    I[Cultural Context<br/>Data] --> B\n   270→    \n   271→    G --> J[Model<br/>Validation]\n   272→    J --> K{Quality<br/>Check}\n   273→    K -->|Pass| L[Model Export<br/>GGUF Format]\n   274→    K -->|Fail| M[Hyperparameter<br/>Adjustment]\n   275→    M --> G\n   276→    \n   277→    L --> N[Ollama<br/>Integration]\n   278→    N --> O[Production<br/>Deployment]\n   279→    \n   280→    P[Evaluation Metrics<br/>BLEU, ROUGE, Custom] --> J\n   281→```\n   282→\n   283→### Phase 3: Web Interface (Weeks 5-6)\n   284→\n   285→**Objectives**:\n   286→\n   287→- Develop production-ready web interface\n   288→- Implement user session management\n   289→- Add progress tracking and analytics\n   290→\n   291→**Deliverables**:\n   292→\n   293→- FastAPI backend with async LLM handling\n   294→- Enhanced frontend with learning analytics\n   295→- User authentication and session persistence\n   296→\n   297→**Technical Tasks**:\n   298→\n   299→```python\n   300→# Web application components\n   301→- FastAPI routes for tutoring sessions\n   302→- User session management with Redis\n   303→- Progress tracking database (SQLite/PostgreSQL)\n   304→- Enhanced UI with React components\n   305→```\n   306→\n   307→### Phase 4: DEAC Deployment (Weeks 7-8)\n   308→\n   309→**Objectives**:\n   310→\n   311→- Deploy system on WFU DEAC cluster\n   312→- Implement monitoring and logging\n   313→- Conduct pilot testing with educators\n   314→\n   315→**Deliverables**:\n   316→\n   317→- Production deployment on DEAC cluster\n   318→- Monitoring dashboard and logging\n   319→- Pilot evaluation results\n   320→\n   321→**Technical Tasks**:\n   322→\n   323→```python\n   324→# Deployment infrastructure\n   325→- Docker containerization\n   326→- Ollama server configuration on DEAC\n   327→- Load balancing and scaling setup\n   328→- Monitoring with Prometheus/Grafana\n   329→```\n   330→\n   331→## Technical Architecture\n   332→\n   333→### System Components\n   334→\n   335→```{mermaid}\n   336→\n   337→graph TB\n   338→\n   339→    A[Web Interface] --> B[FastAPI Backend]\n   340→    B --> C[RAG Pipeline]\n   341→    B --> D[Fine-tuned Models]\n   342→    C --> E[Vector Database]\n   343→    C --> F[Document Store]\n   344→    D --> G[Ollama Server]\n   345→    G --> H[DEAC Cluster]\n   346→    B --> I[Session Management]\n   347→    B --> J[Analytics DB]\n   348→\n   349→```\n   350→\n   351→### Data Flow\n   352→\n   353→```{mermaid}\n   354→sequenceDiagram\n   355→    participant S as Student\n   356→    participant WI as Web Interface\n   357→    participant API as FastAPI Backend\n   358→    participant RAG as RAG Pipeline\n   359→    participant VDB as Vector Database\n   360→    participant LLM as Fine-tuned LLM\n   361→    participant SM as Session Manager\n   362→    participant ADB as Analytics DB\n   363→    \n   364→    S->>WI: Submit question/response (text + images)\n   365→    WI->>API: Forward student input\n   366→    API->>SM: Check session context\n   367→    SM->>API: Return learning history\n   368→    API->>RAG: Query with context\n   369→    RAG->>VDB: Retrieve relevant curriculum content\n   370→    VDB->>RAG: Return matching documents\n   371→    RAG->>LLM: Enhanced prompt with context\n   372→    LLM->>RAG: Generate pedagogical response\n   373→    RAG->>API: Return formatted response\n   374→    API->>ADB: Log interaction for analytics\n   375→    API->>SM: Update session state\n   376→    API->>WI: Send response + follow-ups\n   377→    WI->>S: Display adaptive tutoring response\n   378→```\n   379→\n   380→The detailed learning interaction flow demonstrates how each component contributes to personalized language tutoring:\n   381→\n   382→1. **Student Input** → Web interface captures student questions/responses (text and images)\n   383→2. **Context Retrieval** → RAG system retrieves relevant curriculum content (128K context window)\n   384→3. **Multimodal Processing** → Gemma 3 processes text and visual materials simultaneously\n   385→4. **LLM Processing** → Fine-tuned model generates pedagogically appropriate response\n   386→5. **Response Delivery** → Formatted response with explanations, follow-up questions, and visual aids\n   387→6. **Progress Tracking** → Student interactions logged for adaptive progression across 140+ languages\n   388→\n   389→## Evaluation Framework\n   390→\n   391→### Technical Metrics\n   392→\n   393→- **Response Latency**: <2 seconds for typical interactions\n   394→- **Throughput**: Support for 50+ concurrent users\n   395→- **Model Accuracy**: BLEU/ROUGE scores on language learning tasks\n   396→\n   397→### Pedagogical Metrics\n   398→\n   399→- **Content Relevance**: Alignment with curriculum objectives\n   400→- **Cultural Appropriateness**: Evaluation by language educators\n   401→- **Adaptive Progression**: Personalization effectiveness\n   402→\n   403→## Development Environment Setup\n   404→\n   405→### Local Development\n   406→\n   407→```bash\n   408→# Clone repository\n   409→git clone <repository-url>\n   410→cd its\n   411→\n   412→# Enter Nix development shell (includes R, Quarto, Pandoc)\n   413→nix develop\n   414→\n   415→# Create Python virtual environment\n   416→python -m venv venv\n   417→source venv/bin/activate\n   418→\n   419→# Install dependencies\n   420→pip install -r requirements.txt\n   421→\n   422→# Start Ollama server\n   423→ollama serve\n   424→\n   425→# Pull Gemma 3 models\n   426→ollama pull gemma3:4b   # Development\n   427→ollama pull gemma3:12b  # Testing\n   428→ollama pull gemma3:27b  # Production (DEAC only)\n   429→\n   430→# Run development server\n   431→uvicorn main:app --reload\n   432→```\n   433→\n   434→### DEAC Cluster Integration\n   435→\n   436→```{mermaid}\n   437→graph TB\n   438→    subgraph \"Local Development\"\n   439→        A1[Developer Machine] --> B1[Nix Environment]\n   440→        B1 --> C1[Python venv]\n   441→        C1 --> D1[Ollama Local<br/>Gemma 3 4B]\n   442→        C1 --> E1[ChromaDB]\n   443→        C1 --> F1[Gradio Interface]\n   444→    end\n   445→    \n   446→    subgraph \"DEAC Cluster Production\"\n   447→        A2[Load Balancer] --> B2[Docker Containers]\n   448→        B2 --> C2[FastAPI Services]\n   449→        C2 --> D2[Ollama Cluster<br/>Gemma 3 12B/27B]\n   450→        C2 --> E2[Qdrant Vector DB]\n   451→        C2 --> F2[PostgreSQL<br/>Session Store]\n   452→        \n   453→        G2[A40 48GB GPUs] --> D2\n   454→        H2[A100 80GB GPUs] --> D2\n   455→        I2[Monitoring<br/>Prometheus/Grafana] --> B2\n   456→        J2[WFU Auth<br/>System] --> C2\n   457→    end\n   458→    \n   459→    K[Student Access] --> A2\n   460→    L[Educator Dashboard] --> A2\n   461→```\n   462→\n   463→**Resource Requirements for Gemma 3:**\n   464→\n   465→- **Gemma 3 4B**: Single A40 48GB (development/testing)\n   466→- **Gemma 3 12B**: Single A100 80GB (high-throughput production)\n   467→- **Gemma 3 27B**: 2x A40 48GB or 1x A100 80GB (primary production)\n   468→\n   469→**Deployment Strategy:**\n   470→\n   471→- Leverage existing Nix environment setup\n   472→- Docker containers for Python services\n   473→- Ollama deployment with GPU acceleration\n   474→- Integration with WFU authentication systems\n   475→- Load balancing between 12B and 27B models based on demand\n   476→\n   477→## Risk Mitigation\n   478→\n   479→### Technical Risks\n   480→\n   481→- **Model Performance**: Benchmark multiple base models early\n   482→- **Resource Constraints**: Implement efficient caching and batching\n   483→- **Deployment Complexity**: Use containerization and infrastructure as code\n   484→\n   485→### Pedagogical Risks\n   486→\n   487→- **Content Quality**: Implement human-in-the-loop evaluation\n   488→- **Cultural Sensitivity**: Regular review by language education experts\n   489→- **Privacy Concerns**: Local deployment eliminates external data sharing\n   490→\n   491→## Success Criteria\n   492→\n   493→### Phase 1 Success\n   494→\n   495→- Functional RAG system retrieving course-relevant content\n   496→- Basic tutoring interface with acceptable response quality\n   497→- Technical feasibility demonstrated\n   498→\n   499→### Project Success\n   500→\n   501→- Stable deployment on DEAC cluster\n   502→- Positive educator evaluation of pedagogical value\n   503→- Technical foundation for future scaling and grant applications\n   504→\n   505→## Future Extensions\n   506→\n   507→### Potential Enhancements\n   508→\n   509→- Audio processing integration (leveraging Gemma 3's multimodal foundation)\n   510→- Advanced progress analytics and reporting with visual learning patterns\n   511→- Integration with existing LMS platforms\n   512→- Expansion to all 140+ supported languages beyond Spanish\n   513→- Real-time collaborative learning sessions\n   514→- Cultural context adaptation for different regions\n   515→\n   516→### Scalability Considerations\n   517→\n   518→- Microservices architecture for component scaling\n   519→- Database sharding for large user bases\n   520→- CDN integration for global content delivery\n   521→- Advanced caching strategies for model responses\n   522→\n   523→---\n   524→\n   525→*This technical plan provides the foundation for implementing the ITS4LL system as outlined in the STEP grant proposal. Regular updates will be made as development progresses and new requirements emerge.*\n   526→"}]},"uuid":"afc048cd-9253-49c9-a501-bfdd72cdbbaa","timestamp":"2025-06-18T13:42:09.976Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/francojc/Documents/GitHub/francojc/its/docs/research/technical-plan.qmd","content":"---\ntitle: \"Technical Implementation Plan\"\nbibliography: ../../assets/data/references.bib\n---\n\n# ITS4LL Technical Implementation Plan\n\n## Overview\n\nThis document outlines the technical implementation approach for ITS4LL (Intelligent Tutoring Systems for Language Learning), an adaptive second language tutoring system using fine-tuned and RAG-enhanced local LLMs.\n\n## Current Architecture Assessment\n\n### Existing Infrastructure\n\n- **Documentation Platform**: Quarto-based website with R/Nix development environment\n- **Version Control**: Git repository with academic content structure\n- **Target Deployment**: WFU DEAC cluster with Ollama for local LLM deployment\n- **Current State**: Research documentation phase, no implementation yet\n\n### Project Structure\n\n```\nits/\n├── _quarto.yml         # Website configuration\n├── flake.nix           # Nix development environment\n├── proposal.qmd        # STEP grant proposal\n├── literature.qmd      # Literature review\n├── posts/              # Research blog posts\n└── research/           # Research documents\n```\n\n## Recommended Implementation Stack\n\n### Core Application Architecture\n\n**Primary Language**: Python\n\n- Rationale: Best ecosystem for ML/NLP with extensive LLM tooling\n- Rich libraries for fine-tuning, RAG, and deployment\n\n**Web Framework**: FastAPI\n\n- Async support for concurrent LLM requests\n- Automatic OpenAPI documentation\n- Easy integration with Python ML stack\n- Production-ready with uvicorn\n\n**Frontend Strategy**:\n\n- **Phase 1**: Gradio (rapid prototyping, built-in chat interface)\n- **Phase 2**: Streamlit (enhanced UI components)\n- **Phase 3**: React/Next.js (production interface)\n\n### LLM Infrastructure\n\n**Local Deployment**: Ollama\n\n- Specified in grant proposal\n- Simplified model management and serving\n- GPU acceleration support\n- REST API for integration\n\n**Base Models**:\n\n- **Gemma 3 27B**: Primary production model with 140+ language support and 128K context\n- **Gemma 3 12B**: High-throughput fallback with multimodal capabilities\n- **Gemma 3 4B**: Development and prototyping model with full feature set\n\n**Fine-tuning Framework**:\n\n- **Primary**: Unsloth (memory-efficient, fast training)\n- **Alternative**: MLX-LM (Mac optimization for development)\n- **Techniques**: LoRA/QLoRA for parameter-efficient fine-tuning\n\n### Gemma 3 Advantages for Language Learning\n\n**Multilingual Excellence**:\n- Native support for 140+ languages including Spanish, French, German, Portuguese\n- Cross-lingual understanding without translation overhead\n- Cultural context awareness for authentic language learning\n\n**Extended Context Window**:\n- 128K tokens enable entire curriculum chapters in single interactions\n- Comprehensive document analysis and reference\n- Long-form conversational tutoring sessions\n\n**Multimodal Capabilities**:\n- Text and image processing for visual learning materials\n- Grammar diagrams, cultural images, and infographics integration\n- Enhanced engagement through visual explanations\n\n**Academic Suitability**:\n- Google-backed with strong institutional credibility\n- Apache 2.0 license for unrestricted academic use\n- Built-in safety measures appropriate for educational settings\n\n### RAG Implementation\n\n```{mermaid}\ngraph TD\n    A[Curriculum Documents<br/>PDFs, Images, Text] --> B[Document Loader<br/>LangChain]\n    B --> C[Content Extraction<br/>Text + Metadata]\n    C --> D[Chunking Strategy<br/>Educational Context]\n    D --> E[Embedding Generation<br/>Multilingual Models]\n    E --> F[Vector Database<br/>ChromaDB/Qdrant]\n    \n    G[Student Query] --> H[Query Embedding]\n    H --> I[Similarity Search<br/>Vector DB]\n    I --> J[Retrieved Documents<br/>+ Metadata]\n    J --> K[Context Assembly<br/>128K Window]\n    K --> L[Enhanced Prompt<br/>Curriculum + Query]\n    L --> M[Fine-tuned LLM<br/>Gemma 3]\n    M --> N[Pedagogical Response]\n    \n    O[Course Metadata<br/>Level, Topic, Culture] --> F\n    P[Visual Content<br/>Diagrams, Images] --> E\n    Q[Grammar Rules<br/>Vocabulary Lists] --> E\n```\n\n**Vector Database**:\n\n- **Development**: ChromaDB (embedded, no server required)\n- **Production**: Qdrant (scalable, persistent)\n\n**Embedding Models**:\n\n- sentence-transformers with multilingual models\n- `paraphrase-multilingual-MiniLM-L12-v2` for cross-lingual retrieval\n- Custom domain-specific embeddings if needed\n\n**Document Processing Pipeline**:\n\n- LangChain for document loading and chunking\n- Custom parsers for curriculum materials (text, images, diagrams)\n- Metadata extraction for course alignment\n- Multimodal content integration (leveraging Gemma 3's vision capabilities)\n\n### Core Dependencies\n\n```python\n# ML/NLP Core\ntransformers>=4.35.0\ntorch>=2.0.0\nsentence-transformers>=2.2.0\nunsloth>=2024.1\npillow>=10.0.0  # Multimodal image processing\n\n# RAG Components\nchromadb>=0.4.0\nlangchain>=0.1.0\nllama-index>=0.9.0\n\n# Web Framework\nfastapi>=0.104.0\nuvicorn>=0.24.0\npydantic>=2.5.0\ngradio>=4.0.0\n\n# Data Processing\npandas>=2.0.0\nnumpy>=1.24.0\ndatasets>=2.14.0\n\n# Evaluation\nrouge-score>=0.1.2\nsacrebleu>=2.3.0\nnltk>=3.8.0\n```\n\n## Implementation Phases\n\n### Project Timeline\n\n```{mermaid}\ngantt\n    title ITS4LL Implementation Timeline\n    dateFormat  X\n    axisFormat %s\n    \n    section Phase 1: RAG Prototype\n    Document ingestion system    :p1a, 0, 3d\n    Vector store setup          :p1b, after p1a, 2d\n    Basic RAG pipeline          :p1c, after p1b, 3d\n    Gradio interface           :p1d, after p1c, 2d\n    Evaluation metrics         :p1e, after p1d, 4d\n    \n    section Phase 2: Fine-tuning\n    Dataset creation           :p2a, after p1e, 4d\n    Training pipeline          :p2b, after p2a, 3d\n    Model evaluation          :p2c, after p2b, 3d\n    Ollama integration        :p2d, after p2c, 4d\n    \n    section Phase 3: Web Interface\n    FastAPI backend           :p3a, after p2d, 4d\n    Session management        :p3b, after p3a, 3d\n    Progress tracking         :p3c, after p3b, 3d\n    Enhanced frontend         :p3d, after p3c, 4d\n    \n    section Phase 4: DEAC Deployment\n    Containerization          :p4a, after p3d, 3d\n    DEAC setup               :p4b, after p4a, 3d\n    Monitoring setup         :p4c, after p4b, 2d\n    Pilot testing            :p4d, after p4c, 6d\n```\n\n### Phase 1: RAG Prototype (Weeks 1-2)\n\n**Objectives**:\n\n- Implement basic RAG pipeline with existing models\n- Create curriculum document ingestion system\n- Develop simple chat interface\n\n**Deliverables**:\n\n- Working RAG system with course materials\n- Gradio-based tutoring interface\n- Basic evaluation metrics\n\n**Technical Tasks**:\n\n```python\n# Core RAG components\n- Document loader for curriculum PDFs/texts\n- Chunking strategy for educational content\n- Vector store setup with course metadata\n- Retrieval-augmented generation pipeline\n- Simple chat interface with Gradio\n```\n\n### Phase 2: Fine-tuning Pipeline (Weeks 3-4)\n\n**Objectives**:\n\n- Develop pedagogical fine-tuning datasets\n- Implement parameter-efficient fine-tuning\n- Create model evaluation framework\n\n**Deliverables**:\n\n- Fine-tuned models for language tutoring\n- Automated training pipeline\n- Performance benchmarking system\n\n**Technical Tasks**:\n\n```python\n# Fine-tuning infrastructure\n- Dataset creation from language learning corpora\n- LoRA/QLoRA training scripts with Unsloth\n- Model evaluation on tutoring-specific metrics\n- Integration with Ollama for deployment\n```\n\n### Fine-tuning Pipeline Architecture\n\n```{mermaid}\ngraph LR\n    A[Language Learning<br/>Corpora] --> B[Dataset<br/>Preparation]\n    B --> C[Instruction<br/>Formatting]\n    C --> D[Train/Val<br/>Split]\n    \n    E[Base Model<br/>Gemma 3] --> F[LoRA Adapter<br/>Configuration]\n    F --> G[Parameter-Efficient<br/>Fine-tuning]\n    \n    D --> G\n    H[Pedagogical<br/>Examples] --> B\n    I[Cultural Context<br/>Data] --> B\n    \n    G --> J[Model<br/>Validation]\n    J --> K{Quality<br/>Check}\n    K -->|Pass| L[Model Export<br/>GGUF Format]\n    K -->|Fail| M[Hyperparameter<br/>Adjustment]\n    M --> G\n    \n    L --> N[Ollama<br/>Integration]\n    N --> O[Production<br/>Deployment]\n    \n    P[Evaluation Metrics<br/>BLEU, ROUGE, Custom] --> J\n```\n\n### Phase 3: Web Interface (Weeks 5-6)\n\n**Objectives**:\n\n- Develop production-ready web interface\n- Implement user session management\n- Add progress tracking and analytics\n\n**Deliverables**:\n\n- FastAPI backend with async LLM handling\n- Enhanced frontend with learning analytics\n- User authentication and session persistence\n\n**Technical Tasks**:\n\n```python\n# Web application components\n- FastAPI routes for tutoring sessions\n- User session management with Redis\n- Progress tracking database (SQLite/PostgreSQL)\n- Enhanced UI with React components\n```\n\n### Phase 4: DEAC Deployment (Weeks 7-8)\n\n**Objectives**:\n\n- Deploy system on WFU DEAC cluster\n- Implement monitoring and logging\n- Conduct pilot testing with educators\n\n**Deliverables**:\n\n- Production deployment on DEAC cluster\n- Monitoring dashboard and logging\n- Pilot evaluation results\n\n**Technical Tasks**:\n\n```python\n# Deployment infrastructure\n- Docker containerization\n- Ollama server configuration on DEAC\n- Load balancing and scaling setup\n- Monitoring with Prometheus/Grafana\n```\n\n## Technical Architecture\n\n### System Components\n\n```{mermaid}\n\ngraph TB\n\n    A[Web Interface] --> B[FastAPI Backend]\n    B --> C[RAG Pipeline]\n    B --> D[Fine-tuned Models]\n    C --> E[Vector Database]\n    C --> F[Document Store]\n    D --> G[Ollama Server]\n    G --> H[DEAC Cluster]\n    B --> I[Session Management]\n    B --> J[Analytics DB]\n\n```\n\n### Data Flow\n\n```{mermaid}\nsequenceDiagram\n    participant S as Student\n    participant WI as Web Interface\n    participant API as FastAPI Backend\n    participant RAG as RAG Pipeline\n    participant VDB as Vector Database\n    participant LLM as Fine-tuned LLM\n    participant SM as Session Manager\n    participant ADB as Analytics DB\n    \n    S->>WI: Submit question/response (text + images)\n    WI->>API: Forward student input\n    API->>SM: Check session context\n    SM->>API: Return learning history\n    API->>RAG: Query with context\n    RAG->>VDB: Retrieve relevant curriculum content\n    VDB->>RAG: Return matching documents\n    RAG->>LLM: Enhanced prompt with context\n    LLM->>RAG: Generate pedagogical response\n    RAG->>API: Return formatted response\n    API->>ADB: Log interaction for analytics\n    API->>SM: Update session state\n    API->>WI: Send response + follow-ups\n    WI->>S: Display adaptive tutoring response\n```\n\nThe detailed learning interaction flow demonstrates how each component contributes to personalized language tutoring:\n\n1. **Student Input** → Web interface captures student questions/responses (text and images)\n2. **Context Retrieval** → RAG system retrieves relevant curriculum content (128K context window)\n3. **Multimodal Processing** → Gemma 3 processes text and visual materials simultaneously\n4. **LLM Processing** → Fine-tuned model generates pedagogically appropriate response\n5. **Response Delivery** → Formatted response with explanations, follow-up questions, and visual aids\n6. **Progress Tracking** → Student interactions logged for adaptive progression across 140+ languages\n\n## Evaluation Framework\n\n### Technical Metrics\n\n- **Response Latency**: <2 seconds for typical interactions\n- **Throughput**: Support for 50+ concurrent users\n- **Model Accuracy**: BLEU/ROUGE scores on language learning tasks\n\n### Pedagogical Metrics\n\n- **Content Relevance**: Alignment with curriculum objectives\n- **Cultural Appropriateness**: Evaluation by language educators\n- **Adaptive Progression**: Personalization effectiveness\n\n## Development Environment Setup\n\n### Local Development\n\n```bash\n# Clone repository\ngit clone <repository-url>\ncd its\n\n# Enter Nix development shell (includes R, Quarto, Pandoc)\nnix develop\n\n# Create Python virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Start Ollama server\nollama serve\n\n# Pull Gemma 3 models\nollama pull gemma3:4b   # Development\nollama pull gemma3:12b  # Testing\nollama pull gemma3:27b  # Production (DEAC only)\n\n# Run development server\nuvicorn main:app --reload\n```\n\n### DEAC Cluster Integration\n\n```{mermaid}\ngraph TB\n    subgraph \"Local Development\"\n        A1[Developer Machine] --> B1[Nix Environment]\n        B1 --> C1[Python venv]\n        C1 --> D1[Ollama Local<br/>Gemma 3 4B]\n        C1 --> E1[ChromaDB]\n        C1 --> F1[Gradio Interface]\n    end\n    \n    subgraph \"DEAC Cluster Production\"\n        A2[Load Balancer] --> B2[Docker Containers]\n        B2 --> C2[FastAPI Services]\n        C2 --> D2[Ollama Cluster<br/>Gemma 3 12B/27B]\n        C2 --> E2[Qdrant Vector DB]\n        C2 --> F2[PostgreSQL<br/>Session Store]\n        \n        G2[A40 48GB GPUs] --> D2\n        H2[A100 80GB GPUs] --> D2\n        I2[Monitoring<br/>Prometheus/Grafana] --> B2\n        J2[WFU Auth<br/>System] --> C2\n    end\n    \n    K[Student Access] --> A2\n    L[Educator Dashboard] --> A2\n```\n\n**Resource Requirements for Gemma 3:**\n\n- **Gemma 3 4B**: Single A40 48GB (development/testing)\n- **Gemma 3 12B**: Single A100 80GB (high-throughput production)\n- **Gemma 3 27B**: 2x A40 48GB or 1x A100 80GB (primary production)\n\n**Deployment Strategy:**\n\n- Leverage existing Nix environment setup\n- Docker containers for Python services\n- Ollama deployment with GPU acceleration\n- Integration with WFU authentication systems\n- Load balancing between 12B and 27B models based on demand\n\n## Risk Mitigation\n\n### Technical Risks\n\n- **Model Performance**: Benchmark multiple base models early\n- **Resource Constraints**: Implement efficient caching and batching\n- **Deployment Complexity**: Use containerization and infrastructure as code\n\n### Pedagogical Risks\n\n- **Content Quality**: Implement human-in-the-loop evaluation\n- **Cultural Sensitivity**: Regular review by language education experts\n- **Privacy Concerns**: Local deployment eliminates external data sharing\n\n## Success Criteria\n\n### Phase 1 Success\n\n- Functional RAG system retrieving course-relevant content\n- Basic tutoring interface with acceptable response quality\n- Technical feasibility demonstrated\n\n### Project Success\n\n- Stable deployment on DEAC cluster\n- Positive educator evaluation of pedagogical value\n- Technical foundation for future scaling and grant applications\n\n## Future Extensions\n\n### Potential Enhancements\n\n- Audio processing integration (leveraging Gemma 3's multimodal foundation)\n- Advanced progress analytics and reporting with visual learning patterns\n- Integration with existing LMS platforms\n- Expansion to all 140+ supported languages beyond Spanish\n- Real-time collaborative learning sessions\n- Cultural context adaptation for different regions\n\n### Scalability Considerations\n\n- Microservices architecture for component scaling\n- Database sharding for large user bases\n- CDN integration for global content delivery\n- Advanced caching strategies for model responses\n\n---\n\n*This technical plan provides the foundation for implementing the ITS4LL system as outlined in the STEP grant proposal. Regular updates will be made as development progresses and new requirements emerge.*\n","numLines":526,"startLine":1,"totalLines":526}}}
{"parentUuid":"afc048cd-9253-49c9-a501-bfdd72cdbbaa","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WuUDxUBzPqBmech8nMn29e","type":"tool_result","content":"     1→---\n     2→title: \"STEP Grant Proposal\"\n     3→bibliography: ../../assets/data/references.bib\n     4→---\n     5→\n     6→1. **Project title:** Adaptive Second Language Tutoring with Fine-Tuned and RAG-Enhanced local LLMs\n     7→\n     8→2. **Project description:**\n     9→\n    10→  - This project aims to enhance second language education by integrating AI with targeted tutoring techniques. Leveraging open-access LLMs from HuggingFace, fine-tuning through frameworks such as Unsloth or MLX-LM, and efficient local deployment tools like Ollama, the goal is to develop a personalized, scalable, and interactive platform specifically for second language learners. This system not only aims to offer real-time feedback but also can be tailored for existing curricula using Retrieval Augmented Generation (RAG) to enhance learning materials with relevant target cultural and linguistic content.\n    11→\n    12→3. **Names and affiliations of faculty and staff participants:**\n    13→\n    14→   - Sean Anderson, Ph.D. HPC UNIX Systems Administrator, Information Systems Wake Forest University @WakeHPC. Sean Anderson will provide expert support for the deployment and management of the Ollama infrastructure on the university's DEAC cluster, ensuring system stability and efficient resource utilization.\n    15→\n    16→4. **What is the issue, problem, or opportunity -whether pedagogical, scholarly, or creative-- that your project intends to address?**\n    17→\n    18→  - Second language education presents a significant opportunity to leverage advancements in AI to create more personalized and effective learning experiences. Traditional curricula, however, are frequently rigid and fail to adapt to individual learner needs, offering limited opportunities for real-time feedback and personalized content. This one-size-fits-all approach neglects the diverse proficiency levels and cultural backgrounds of learners, hindering effective language acquisition. Furthermore, existing solutions often lack mechanisms for integrating culturally relevant materials (for a given course). This project aims to address these gaps by creating a dynamic, adaptive, and culturally responsive language tutoring system, which will enhance both student learning and provide opportunities for scholarly investigation into AI-driven pedagogy.\n    19→\n    20→5. **Describe the current solution to this problem or issue, if any:**\n    21→\n    22→  Current AI solutions frequently prioritize general conversation practice over structured pedagogical progression while introducing data privacy risks through cloud-based commercial providers.\n    23→\n    24→  - Existing approaches include:\n    25→    - Static language apps (Duolingo, Babbel) with fixed progression paths\n    26→    - Human tutoring (limited scalability/cost)\n    27→    - Basic AI chat interfaces lacking curriculum integration\n    28→    - Textbook-based cultural content (static/dated) While valuable, these fail to combine real-time adaptive feedback with structured curriculum alignment and cultural contextualization.\n    29→\n    30→6. **How will your proposed project address this issue, problem, or opportunity stated above?**\n    31→\n    32→  This project addresses the critical opportunity to enhance and personalize student learning experiences with AI through technologies which are tailored to particular educational contexts and can guarantee a much higher level of privacy that commercial systems. By providing a more engaging and adaptive learning environment, this project aims to improve student learning outcomes and offer instructors a tool to deliver more effective and personalized language instruction.\n    33→\n    34→  - Curriculum-Anchored Fine-Tuning: LLMs fine-tuned on pedagogical datasets rather than general conversation\n    35→  - RAG Integration: Dynamic injection of course-specific materials (relevant vocabulary, grammar, and cultural content)\n    36→  - Ollama deployment: Balances local processing (latency) with cloud scalability (with assistance with the WFU DEAC Cluster Team). This enables context-aware tutoring that adapts to both individual learner needs and institutional curriculum requirements that can be made available to students through a course-based web interface.\n    37→  - Privacy-first architecture: Open-access models deployed locally via Ollama eliminate dependence on external APIs, keeping sensitive learner data on-premises/institution-controlled infrastructure.\n    38→\n    39→7. **Describe the metrics you will use to determine the impact and success of your project.**\n    40→\n    41→This project aims to generate a proof of concept for adaptive second language tutoring using fine-tuned and RAG-enhanced local LLMs. Success will be evaluated by the technical feasibility of the system, the quality of the generated content, and educator evaluations of the system's pedagogical value. Technical feasibility will be measured by successful deployment on the DEAC cluster and stable operation of the tutoring system. The quality of generated content will be assessed through evaluations by myself as a language educator, focusing on grammatical accuracy, cultural appropriateness, and pedagogical relevance.  If the proof of concept is promising, we will seek larger grants to scale the project.  Future, student and instructor feedback from a pilot deployment will be crucial for understanding the potential impact of the system in future iterations, but is not the primary metric for the success of this summer project.\n    42→\n    43→8. **Budget:**\n    44→\n    45→ - $2,500 Summer stipend (Professor Francom)\n    46→\n    47→ *No other expenses are requested as the project will leverage open-source software, existing university computing infrastructure (DEAC cluster), and support from IS. This approach maximizes resource efficiency and aligns with the grant's emphasis on utilizing available resources.*\n    48→\n    49→9. **Do you anticipate this project to involve or impact students? If so, how?**\n    50→\n    51→Yes, this project is ultimately student-centered and designed to directly benefit students of second languages. While the initial summer phase focuses on development and technical validation, the longer-term goal is to pilot the system with students in Spanish language courses to enhance their learning experience through personalized tutoring. The adaptive tutoring approach developed in this project could also be extended to other language courses, such as French or German, and potentially adapted for personalized learning in other disciplines requiring structured practice and feedback.\n    52→"}]},"uuid":"932f711e-fc15-4fdd-b8d1-bdb47be0c885","timestamp":"2025-06-18T13:42:09.977Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/francojc/Documents/GitHub/francojc/its/docs/grants/step_proposal.qmd","content":"---\ntitle: \"STEP Grant Proposal\"\nbibliography: ../../assets/data/references.bib\n---\n\n1. **Project title:** Adaptive Second Language Tutoring with Fine-Tuned and RAG-Enhanced local LLMs\n\n2. **Project description:**\n\n  - This project aims to enhance second language education by integrating AI with targeted tutoring techniques. Leveraging open-access LLMs from HuggingFace, fine-tuning through frameworks such as Unsloth or MLX-LM, and efficient local deployment tools like Ollama, the goal is to develop a personalized, scalable, and interactive platform specifically for second language learners. This system not only aims to offer real-time feedback but also can be tailored for existing curricula using Retrieval Augmented Generation (RAG) to enhance learning materials with relevant target cultural and linguistic content.\n\n3. **Names and affiliations of faculty and staff participants:**\n\n   - Sean Anderson, Ph.D. HPC UNIX Systems Administrator, Information Systems Wake Forest University @WakeHPC. Sean Anderson will provide expert support for the deployment and management of the Ollama infrastructure on the university's DEAC cluster, ensuring system stability and efficient resource utilization.\n\n4. **What is the issue, problem, or opportunity -whether pedagogical, scholarly, or creative-- that your project intends to address?**\n\n  - Second language education presents a significant opportunity to leverage advancements in AI to create more personalized and effective learning experiences. Traditional curricula, however, are frequently rigid and fail to adapt to individual learner needs, offering limited opportunities for real-time feedback and personalized content. This one-size-fits-all approach neglects the diverse proficiency levels and cultural backgrounds of learners, hindering effective language acquisition. Furthermore, existing solutions often lack mechanisms for integrating culturally relevant materials (for a given course). This project aims to address these gaps by creating a dynamic, adaptive, and culturally responsive language tutoring system, which will enhance both student learning and provide opportunities for scholarly investigation into AI-driven pedagogy.\n\n5. **Describe the current solution to this problem or issue, if any:**\n\n  Current AI solutions frequently prioritize general conversation practice over structured pedagogical progression while introducing data privacy risks through cloud-based commercial providers.\n\n  - Existing approaches include:\n    - Static language apps (Duolingo, Babbel) with fixed progression paths\n    - Human tutoring (limited scalability/cost)\n    - Basic AI chat interfaces lacking curriculum integration\n    - Textbook-based cultural content (static/dated) While valuable, these fail to combine real-time adaptive feedback with structured curriculum alignment and cultural contextualization.\n\n6. **How will your proposed project address this issue, problem, or opportunity stated above?**\n\n  This project addresses the critical opportunity to enhance and personalize student learning experiences with AI through technologies which are tailored to particular educational contexts and can guarantee a much higher level of privacy that commercial systems. By providing a more engaging and adaptive learning environment, this project aims to improve student learning outcomes and offer instructors a tool to deliver more effective and personalized language instruction.\n\n  - Curriculum-Anchored Fine-Tuning: LLMs fine-tuned on pedagogical datasets rather than general conversation\n  - RAG Integration: Dynamic injection of course-specific materials (relevant vocabulary, grammar, and cultural content)\n  - Ollama deployment: Balances local processing (latency) with cloud scalability (with assistance with the WFU DEAC Cluster Team). This enables context-aware tutoring that adapts to both individual learner needs and institutional curriculum requirements that can be made available to students through a course-based web interface.\n  - Privacy-first architecture: Open-access models deployed locally via Ollama eliminate dependence on external APIs, keeping sensitive learner data on-premises/institution-controlled infrastructure.\n\n7. **Describe the metrics you will use to determine the impact and success of your project.**\n\nThis project aims to generate a proof of concept for adaptive second language tutoring using fine-tuned and RAG-enhanced local LLMs. Success will be evaluated by the technical feasibility of the system, the quality of the generated content, and educator evaluations of the system's pedagogical value. Technical feasibility will be measured by successful deployment on the DEAC cluster and stable operation of the tutoring system. The quality of generated content will be assessed through evaluations by myself as a language educator, focusing on grammatical accuracy, cultural appropriateness, and pedagogical relevance.  If the proof of concept is promising, we will seek larger grants to scale the project.  Future, student and instructor feedback from a pilot deployment will be crucial for understanding the potential impact of the system in future iterations, but is not the primary metric for the success of this summer project.\n\n8. **Budget:**\n\n - $2,500 Summer stipend (Professor Francom)\n\n *No other expenses are requested as the project will leverage open-source software, existing university computing infrastructure (DEAC cluster), and support from IS. This approach maximizes resource efficiency and aligns with the grant's emphasis on utilizing available resources.*\n\n9. **Do you anticipate this project to involve or impact students? If so, how?**\n\nYes, this project is ultimately student-centered and designed to directly benefit students of second languages. While the initial summer phase focuses on development and technical validation, the longer-term goal is to pilot the system with students in Spanish language courses to enhance their learning experience through personalized tutoring. The adaptive tutoring approach developed in this project could also be extended to other language courses, such as French or German, and potentially adapted for personalized learning in other disciplines requiring structured practice and feedback.\n","numLines":52,"startLine":1,"totalLines":52}}}
{"parentUuid":"932f711e-fc15-4fdd-b8d1-bdb47be0c885","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HqhmD9imKifcf3r2NihDFG","type":"tool_result","content":"     1→---\n     2→title: \"ITS4LL - Intelligent Tutoring Systems for Language Learning\"\n     3→subtitle: \"Research project developing adaptive second language tutoring systems using fine-tuned and RAG-enhanced local LLMs\"\n     4→---\n     5→\n     6→## Project Overview\n     7→\n     8→ITS4LL is a research initiative focused on developing intelligent tutoring systems specifically designed for second language acquisition. The project combines modern language model technologies with established pedagogical principles to create adaptive, personalized learning experiences.\n     9→\n    10→## Key Components\n    11→\n    12→### 🔬 [Research Documentation](docs/)\n    13→Comprehensive literature reviews, technical plans, and academic research findings that inform the project's development.\n    14→\n    15→### 💰 [Grant Proposals](docs/grants/)  \n    16→Funding proposals and related documentation, including our STEP grant application.\n    17→\n    18→### 📝 [Research Blog](blog/)\n    19→Development notes, implementation insights, and progress updates throughout the project lifecycle.\n    20→\n    21→### 💻 [Codebase](code/)\n    22→Implementation of the tutoring system, including model fine-tuning pipelines, RAG systems, and user interfaces.\n    23→\n    24→## Recent Activity\n    25→\n    26→::: {.callout-note}\n    27→## Latest Updates\n    28→Check our [research blog](blog/) for the most recent developments and insights.\n    29→:::\n    30→\n    31→## Architecture Vision\n    32→\n    33→The system integrates three core technologies:\n    34→\n    35→1. **Fine-tuned Local LLMs** for personalized pedagogical interactions\n    36→2. **RAG-Enhanced Systems** for curriculum-aligned content delivery  \n    37→3. **Adaptive Learning Algorithms** for optimized learning path generation\n    38→\n    39→This combination addresses the challenges of scalable, effective language instruction while maintaining data privacy through local deployment.\n    40→\n    41→\n    42→"}]},"uuid":"d60ad6ec-4c0c-48a8-8e45-1cd2f9f7c0c1","timestamp":"2025-06-18T13:42:09.977Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/francojc/Documents/GitHub/francojc/its/index.qmd","content":"---\ntitle: \"ITS4LL - Intelligent Tutoring Systems for Language Learning\"\nsubtitle: \"Research project developing adaptive second language tutoring systems using fine-tuned and RAG-enhanced local LLMs\"\n---\n\n## Project Overview\n\nITS4LL is a research initiative focused on developing intelligent tutoring systems specifically designed for second language acquisition. The project combines modern language model technologies with established pedagogical principles to create adaptive, personalized learning experiences.\n\n## Key Components\n\n### 🔬 [Research Documentation](docs/)\nComprehensive literature reviews, technical plans, and academic research findings that inform the project's development.\n\n### 💰 [Grant Proposals](docs/grants/)  \nFunding proposals and related documentation, including our STEP grant application.\n\n### 📝 [Research Blog](blog/)\nDevelopment notes, implementation insights, and progress updates throughout the project lifecycle.\n\n### 💻 [Codebase](code/)\nImplementation of the tutoring system, including model fine-tuning pipelines, RAG systems, and user interfaces.\n\n## Recent Activity\n\n::: {.callout-note}\n## Latest Updates\nCheck our [research blog](blog/) for the most recent developments and insights.\n:::\n\n## Architecture Vision\n\nThe system integrates three core technologies:\n\n1. **Fine-tuned Local LLMs** for personalized pedagogical interactions\n2. **RAG-Enhanced Systems** for curriculum-aligned content delivery  \n3. **Adaptive Learning Algorithms** for optimized learning path generation\n\nThis combination addresses the challenges of scalable, effective language instruction while maintaining data privacy through local deployment.\n\n\n","numLines":42,"startLine":1,"totalLines":42}}}
{"parentUuid":"d60ad6ec-4c0c-48a8-8e45-1cd2f9f7c0c1","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WXUxPeeHjcNU3AfTCMBhNP","type":"tool_result","content":"     1→---\n     2→title: Literature Review \n     3→---\n     4→\n     5→> Adaptive Second Language Tutoring with Fine-Tuned and RAG-Enhanced Local LLMs\n     6→\n     7→## 1. Introduction\n     8→\n     9→### 1.1. Context: The Rise of LLMs in Education and Second Language Acquisition (SLA)\n    10→\n    11→The rapid development and proliferation of Large Language Models (LLMs)\n    12→represent a significant technological advancement, impacting numerous\n    13→domains including academia and education.[^1] These sophisticated\n    14→artificial intelligence (AI) systems, often built upon deep learning\n    15→architectures like transformers, demonstrate remarkable capabilities in\n    16→processing, understanding, and generating human-like text based on\n    17→patterns learned from massive datasets.[^3] This proficiency enables a\n    18→wide array of applications, from text summarization and translation to\n    19→complex question answering and content creation.[^4]\n    20→\n    21→Within the educational sector, LLMs present novel opportunities for\n    22→enhancing learning experiences and administrative efficiency.[^5] Their\n    23→potential to simulate human interaction and provide tailored content has\n    24→sparked particular interest in the field of Second Language Acquisition\n    25→(SLA) and Foreign Language Education (FLE).[^19] The perennial challenges\n    26→of providing personalized, scalable, and interactive language practice,\n    27→often constrained by the limitations of traditional classroom settings\n    28→or the high cost of human tutoring, appear addressable through AI-driven\n    29→solutions.[^24] LLMs offer the possibility of creating dynamic learning\n    30→environments that can adapt to individual learner needs and provide\n    31→immediate feedback.[^21]\n    32→\n    33→However, the integration of LLMs into language education is not without\n    34→its complexities. While their potential is widely acknowledged, current\n    35→applications often rely on general-purpose models that may lack the\n    36→specific pedagogical grounding and adaptability required for effective\n    37→language learning.[^19] Many existing LLM-based tools prioritize\n    38→conversational fluency over structured pedagogical progression,\n    39→potentially failing to guide learners systematically through the\n    40→complexities of acquiring a new language.[^19] Furthermore, concerns\n    41→regarding factual accuracy, contextual appropriateness, cultural\n    42→sensitivity, and data privacy persist.[^12] The research proposal\n    43→underpinning this review, \\\"Adaptive Second Language Tutoring with\n    44→Fine-Tuned and RAG-Enhanced local LLMs,\\\" aims precisely at addressing\n    45→these shortcomings by developing a system tailored for pedagogical\n    46→effectiveness, curriculum alignment, cultural relevance, and privacy.\n    47→\n    48→### 1.2. Purpose and Scope of the Report\n    49→\n    50→The primary objective of this report is to conduct a comprehensive\n    51→background literature review based on the aforementioned research\n    52→proposal and a curated set of research materials. The review focuses\n    53→specifically on the intersection of LLMs, SLA, and AI-driven tutoring.\n    54→It examines the current state of research concerning the use of LLMs in\n    55→language learning applications, delving into specific techniques central\n    56→to the proposal: fine-tuning LLMs for pedagogical objectives, employing\n    57→Retrieval-Augmented Generation (RAG) for curriculum and cultural content\n    58→integration, and leveraging local deployment frameworks like Ollama for\n    59→enhanced privacy and control. Furthermore, the report analyzes existing\n    60→language learning methods in comparison to LLM-based tutors and\n    61→identifies critical gaps in the current research landscape.\n    62→\n    63→This analysis synthesizes findings from the provided research snippets\n    64→to evaluate how the proposed project, through its unique combination of\n    65→fine-tuning, RAG, and local deployment, aims to address these identified\n    66→gaps and contribute meaningfully to the field of AI-enhanced language\n    67→education. The report structure follows a logical progression, starting\n    68→with an overview of the current landscape, followed by detailed\n    69→examinations of fine-tuning, RAG, and local deployment strategies. It\n    70→then synthesizes these findings to pinpoint research gaps and concludes\n    71→by positioning the proposed project within this context, highlighting\n    72→its novelty and potential impact.\n    73→\n    74→## 2. Current Landscape of LLMs in Second Language Acquisition (SLA) and Tutoring\n    75→\n    76→### 2.1. Overview of LLM Roles and Applications in Language Education\n    77→\n    78→The integration of LLMs into language education is rapidly evolving,\n    79→with researchers exploring diverse roles and applications for these\n    80→powerful AI tools. LLMs are envisioned to function in several key\n    81→capacities within educational settings, particularly in FLE. They can\n    82→serve as **data enhancers**, assisting in the creation and refinement of\n    83→learning materials or simulating student interactions for training\n    84→purposes; as **task predictors**, enabling learner assessment or\n    85→optimizing individual learning pathways; and as **agents**, facilitating\n    86→personalized and inclusive educational experiences, including\n    87→tutoring.[^19]\n    88→\n    89→Specific applications leveraging these roles are numerous and growing. A\n    90→primary use case is **conversation practice**, where LLMs act as\n    91→interactive partners, allowing learners to engage in dialogue, practice\n    92→speaking and writing, and build fluency in a low-pressure\n    93→environment.[^23] They are also employed for targeted skill development,\n    94→such as **grammar and vocabulary acquisition**, providing explanations,\n    95→examples, exercises, and corrective feedback.[^20] LLMs can function as\n    96→sophisticated **writing assistants**, offering feedback on essays\n    97→regarding content, organization, and language use [^5], and similarly\n    98→support **reading comprehension**.[^5]\n    99→\n   100→Beyond direct student interaction, LLMs assist educators by **generating\n   101→learner-centric materials**, such as customized exercises, lesson plans,\n   102→worksheets, and assessments, potentially alleviating teacher workload\n   103→and allowing for more focus on individual student needs.[^11] Their\n   104→ability to simulate human-like interaction [^20] and provide detailed\n   105→explanations [^5] makes them suitable for creating interactive practice\n   106→environments that go beyond static exercises.[^31]\n   107→\n   108→### 2.2. Reported Benefits of LLM-Based Language Tutoring\n   109→\n   110→The burgeoning research on LLMs in language education highlights several\n   111→potential benefits that drive their adoption and investigation.\n   112→\n   113→-   **Personalization & Adaptivity:** A frequently cited advantage is\n   114→    the potential for LLMs to deliver highly personalized learning\n   115→    experiences.[^2] Unlike traditional one-size-fits-all approaches, AI\n   116→    tutors can theoretically adapt learning paths, content difficulty,\n   117→    and interaction styles based on individual student proficiency\n   118→    levels, learning pace, preferences, and real-time performance.[^11]\n   119→    This adaptability aims to keep learners optimally challenged and\n   120→    engaged, fostering more effective language acquisition. The proposal\n   121→    explicitly targets this potential for personalization (Proposal\n   122→    Sections 2, 4, 6).\n   123→\n   124→-   **Immediate Feedback:** LLMs can provide instant feedback on various\n   125→    aspects of language use, including grammar, vocabulary, spelling,\n   126→    and potentially pronunciation when integrated with speech\n   127→    recognition technology.[^20] This real-time feedback loop allows\n   128→    learners to identify and correct errors quickly, reinforcing correct\n   129→    usage and potentially accelerating the learning process.[^26]\n   130→    Immediate reinforcement can also build learner confidence.[^43]\n   131→\n   132→-   **Accessibility & Scalability:** AI-powered tutors offer\n   133→    unparalleled accessibility, being available 24/7 from potentially\n   134→    any location with an internet connection (or offline, in the case of\n   135→    local deployment).[^15] This overcomes the scheduling and\n   136→    geographical limitations inherent in human tutoring. Furthermore, AI\n   137→    solutions can scale to serve a large number of learners\n   138→    simultaneously, a significant advantage over human tutors whose\n   139→    capacity is inherently limited.[^6] The proposal acknowledges the\n   140→    scalability limits of human tutoring as a motivating factor\n   141→    (Proposal Section 5).\n   142→\n   143→-   **Reduced Anxiety & Increased Motivation:** Many language learners\n   144→    experience anxiety when speaking or writing in a foreign language,\n   145→    particularly in front of peers or instructors. Interacting with an\n   146→    AI tutor can provide a non-judgmental, safe environment for\n   147→    practice, reducing this language anxiety or \\\"affective\n   148→    filter\\\".[^31] This lower-pressure environment may encourage learners\n   149→    to take more risks, practice more frequently, and consequently\n   150→    increase their motivation and engagement.[^31]\n   151→\n   152→-   **Content Generation & Teacher Support:** LLMs can significantly\n   153→    reduce the burden on educators by automating the creation of diverse\n   154→    educational materials, including lesson plans, exercises, quizzes,\n   155→    and assessments.[^11] This allows teachers to dedicate more time to\n   156→    higher-level instructional activities, such as providing\n   157→    personalized guidance and fostering deeper student\n   158→    understanding.[^20]\n   159→\n   160→### 2.3. Limitations and Challenges of Current LLM Approaches\n   161→\n   162→Despite the enthusiasm surrounding LLMs in language education, numerous\n   163→limitations and challenges temper their immediate applicability and\n   164→effectiveness.\n   165→\n   166→-   **Lack of Pedagogical Soundness:** A critical shortcoming is that\n   167→    standard LLMs, primarily trained on vast amounts of general text\n   168→    data, often lack inherent pedagogical understanding.[^19] They may\n   169→    excel at generating fluent and coherent text but fail to employ\n   170→    effective teaching strategies grounded in learning sciences.[^19] For\n   171→    instance, they might provide direct answers rather than scaffolding\n   172→    student learning through guided questioning or hints [^29],\n   173→    potentially hindering deeper understanding and critical\n   174→    thinking.[^13] The proposal\\'s focus on fine-tuning directly targets\n   175→    this limitation (Proposal Sections 4, 6).\n   176→\n   177→-   **Factual Inaccuracy & Hallucinations:** LLMs are known to\n   178→    \\\"hallucinate,\\\" generating information that sounds plausible but is\n   179→    factually incorrect or nonsensical.^12^ This is particularly\n   180→    problematic in education where accuracy is paramount. Outdated\n   181→    training data can exacerbate this issue, leading to the\n   182→    dissemination of obsolete information.[^13] Retrieval-Augmented\n   183→    Generation (RAG) is proposed as a technique to mitigate this by\n   184→    grounding responses in external, verified knowledge sources\n   185→    (Proposal Section 6).\n   186→\n   187→-   **Limited Contextual/Cultural Understanding:** While LLMs process\n   188→    language statistically, they often lack the deep, nuanced\n   189→    understanding of context, idioms, slang, humor, and cultural\n   190→    subtleties that human communicators possess.[^25] This limitation can\n   191→    hinder their ability to provide culturally appropriate explanations\n   192→    or engage in truly authentic communicative interactions. The\n   193→    proposal aims to enhance cultural relevance via RAG (Proposal\n   194→    Sections 2, 4, 6).\n   195→\n   196→-   **Generic or Ineffective Feedback:** LLM-generated feedback can\n   197→    sometimes be too generic, overly positive, or indirect, failing to\n   198→    provide the specific, constructive guidance learners need to\n   199→    improve.[^24] LLMs may struggle to accurately identify the root cause\n   200→    of a learner\\'s error or tailor feedback effectively to their\n   201→    specific needs.\n   202→\n   203→-   **Technological Limitations:** Current chatbot technologies,\n   204→    including those powered by LLMs, face inherent limitations. They may\n   205→    struggle with non-linear conversations where context needs to be\n   206→    recalled and integrated dynamically [^31], offer limited depth in\n   207→    interaction [^31], be overly sensitive to typos or grammatical errors\n   208→    in user input [^40], or be constrained by context window size,\n   209→    limiting the amount of previous interaction they can consider.[^51]\n   210→\n   211→-   **Bias and Ethical Concerns:** LLMs can inherit and amplify societal\n   212→    biases present in their vast training data, leading to potentially\n   213→    unfair, stereotyped, or discriminatory outputs.[^6] Broader ethical\n   214→    concerns in educational AI include student data privacy and security\n   215→    (especially with cloud-based models), the potential for misuse\n   216→    (e.g., cheating on assignments), ensuring equitable access (the\n   217→    digital divide), and the lack of transparency in AI\n   218→    decision-making.[^9] The proposal\\'s emphasis on local deployment\n   219→    aims to mitigate privacy risks specifically (Proposal Sections 5,\n   220→    6).\n   221→\n   222→-   **Over-reliance & Novelty Effect:** There is a risk that students\n   223→    may become overly reliant on AI tutors, potentially hindering the\n   224→    development of independent problem-solving skills and deeper\n   225→    conceptual understanding.[^15] Additionally, the initial high\n   226→    engagement observed with new AI tools might diminish over time as\n   227→    the novelty wears off.[^40]\n   228→\n   229→### 2.4. Comparative Analysis: LLM Tutors vs. Other Language Learning Methods\n   230→\n   231→Evaluating the potential of LLM-based tutors requires comparing them\n   232→against existing language learning approaches, particularly in light of\n   233→foundational educational research on tutoring effectiveness and scalability.\n   234→\n   235→#### 2.4.1. Bloom's 2 Sigma Problem and the Promise of AI Tutoring\n   236→\n   237→The theoretical foundation for AI tutoring is deeply rooted in Benjamin Bloom's seminal 1984 research on educational effectiveness, which identified what became known as the \"2 Sigma Problem.\" Bloom's study demonstrated that students receiving one-on-one tutoring performed two standard deviations better (at the 98th percentile) than students in conventional classroom instruction (at the 50th percentile). This remarkable finding suggested that personalized tutoring could move the average student from the median to the top 2% of conventional classroom performance.\n   238→\n   239→However, Bloom's research also highlighted a fundamental scalability challenge: while one-on-one tutoring produced exceptional learning gains, it was economically and logistically impractical to provide individual human tutors for all students. This limitation led Bloom to propose \"Mastery Learning\" as a scalable alternative—a pedagogical approach where students must demonstrate competency in foundational concepts before progressing to more advanced material, combined with corrective instruction and enrichment activities tailored to individual needs.\n   240→\n   241→The emergence of LLM-based tutoring systems represents a potential solution to Bloom's 2 Sigma Problem by offering the personalization benefits of one-on-one tutoring at the scale of traditional classroom instruction. AI tutors can theoretically provide individualized attention, immediate feedback, and adaptive pacing—key characteristics of effective human tutoring—while serving unlimited numbers of students simultaneously. This positions AI tutoring as a bridge between the effectiveness of human tutoring and the scalability requirements of modern education.\n   242→\n   243→#### 2.4.2. Mastery Learning and Its Connection to the Current Project\n   244→\n   245→Mastery Learning principles align closely with the objectives of the proposed AI tutoring system for second language acquisition. Core tenets of Mastery Learning include:\n   246→\n   247→- **Criterion-Referenced Assessment:** Students must demonstrate proficiency at predetermined competency levels before advancing, rather than competing against peers or following fixed time schedules.\n   248→- **Corrective Instruction:** When students fail to achieve mastery, they receive additional instruction tailored to their specific learning gaps.\n   249→- **Enrichment Activities:** Students who achieve mastery quickly engage in extension activities that deepen or broaden their understanding.\n   250→- **Individualized Pacing:** Learning progression is determined by individual competency rather than calendar constraints.\n   251→\n   252→The proposed RAG-enhanced, fine-tuned LLM system embodies these principles through several mechanisms. The fine-tuning component can be designed to implement mastery-based pedagogical strategies, ensuring students demonstrate competency in fundamental language structures before introducing more complex concepts. The RAG system can dynamically retrieve appropriate corrective materials or enrichment content based on individual student performance, effectively personalizing the learning path. Furthermore, the 24/7 availability of the AI tutor supports individualized pacing, allowing students to progress through mastery checkpoints at their own rate.\n   253→\n   254→#### 2.4.3. Comparative Analysis of Learning Approaches\n   255→\n   256→-   **LLM Tutors vs. Static Apps (e.g., Duolingo, Babbel):** Compared to\n   257→    popular language learning apps characterized by fixed progression\n   258→    paths and limited feedback mechanisms, LLMs offer the potential for\n   259→    much more dynamic, interactive, and personalized learning\n   260→    experiences (Proposal Section 5). LLMs can engage in more natural\n   261→    conversations and potentially adapt content more fluidly. However,\n   262→    static apps often provide a clear, structured curriculum that might\n   263→    be beneficial for absolute beginners, whereas the pedagogical\n   264→    structure of basic AI chat interfaces can be lacking (Proposal\n   265→    Section 5). Notably, most static apps lack true mastery learning implementation, advancing students based on time-based metrics rather than demonstrated competency.\n   266→\n   267→-   **LLM Tutors vs. Human Tutors:** This comparison directly addresses Bloom's findings about tutoring effectiveness.\n   268→\n   269→    -   *Human Strengths:* Human tutors possess deep understanding of\n   270→        linguistic nuance, cultural context, and learner emotions. They\n   271→        can adapt their teaching strategies flexibly based on subtle\n   272→        cues, build rapport, provide empathetic support, and excel at\n   273→        explaining complex or creative concepts.[^25] Their ability to\n   274→        engage in spontaneous, unpredictable conversation fosters\n   275→        real-life communication skills.[^52] Human tutors naturally implement many mastery learning principles through responsive instruction and adaptive pacing.\n   276→\n   277→    -   *AI Strengths:* LLM tutors offer significant advantages in\n   278→        scalability, 24/7 availability, and potentially lower cost.[^20]\n   279→        They provide consistent, immediate feedback, particularly for\n   280→        foundational skills like grammar and vocabulary, and can create\n   281→        a less intimidating practice environment, reducing learner\n   282→        anxiety.[^32] AI tutors can implement systematic mastery learning protocols more consistently than human tutors, ensuring all students receive equivalent opportunities for corrective instruction and competency demonstration.\n   283→\n   284→    -   *Human Weaknesses:* Human tutoring is expensive, difficult to\n   285→        scale, and subject to scheduling and geographical constraints\n   286→        [^25] (Proposal Section 5). These limitations prevent widespread implementation of the tutoring model that Bloom demonstrated to be most effective.\n   287→\n   288→    -   *AI Weaknesses:* LLMs lack genuine understanding, emotional\n   289→        intelligence, and cultural depth. They can be factually\n   290→        inaccurate, provide generic feedback, and raise privacy concerns\n   291→        when deployed via cloud services. Their pedagogical capabilities\n   292→        are often limited without specific tuning.[^19] Additionally, current AI tutors may struggle to implement the nuanced diagnostic assessments that effective mastery learning requires.\n   293→\n   294→-   **LLM Tutors vs. Traditional Classroom:** Traditional classrooms\n   295→    provide valuable social interaction and peer learning opportunities.\n   296→    However, they often struggle to cater to individual learning paces\n   297→    and needs due to their inherent one-size-fits-all nature, offering\n   298→    limited opportunities for personalized feedback [^25] (Proposal\n   299→    Section 4). This is precisely the limitation that Bloom's 2 Sigma Problem identified. LLM tutors promise personalization at scale but cannot\n   300→    replicate the rich social dynamics of a classroom. Interestingly, classroom implementations of Mastery Learning have shown significant improvements over traditional instruction, though still falling short of one-on-one tutoring effectiveness.\n   301→\n   302→-   **LLM Tutors vs. Mastery Learning Systems:** Traditional computer-based mastery learning systems have existed for decades, showing moderate effectiveness improvements over conventional instruction. However, these systems typically lack the natural language interaction capabilities and adaptive content generation that LLMs provide. The proposed system represents an evolution of mastery learning technologies, potentially combining the structured competency progression of traditional mastery systems with the conversational flexibility and content adaptability of modern LLMs.\n   303→\n   304→#### 2.4.4. Synthesis and Implications for the Current Project\n   305→\n   306→The distinct profiles of AI and human tutors strongly suggest that an\n   307→optimal approach may involve combining their strengths while addressing Bloom's scalability challenge. AI systems\n   308→appear well-suited for providing scalable practice, instant feedback on\n   309→discrete language points, and accessible learning opportunities. Human\n   310→tutors, conversely, remain indispensable for fostering deep\n   311→understanding, navigating cultural and emotional nuances, developing\n   312→advanced communicative competence, and providing mentorship.[^26] This\n   313→recognition stems from observing that AI\\'s advantages in cost,\n   314→availability, and consistency [^25] are counterbalanced by human\n   315→superiority in adaptability, empathy, and nuanced understanding.[^25]\n   316→Direct comparisons consistently highlight this complementarity.[^26]\n   317→\n   318→The proposed project's integration of fine-tuning, RAG, and local deployment addresses key limitations identified in this comparative analysis. Fine-tuning can instill mastery learning pedagogical principles, ensuring the AI tutor implements competency-based progression and appropriate corrective instruction strategies. RAG integration enables dynamic retrieval of curriculum-aligned content and culturally relevant materials, supporting both the corrective instruction and enrichment components of mastery learning. Local deployment addresses privacy concerns while enabling institutional control over the learning environment.\n   319→\n   320→Consequently, rather than viewing AI as a replacement for human\n   321→teachers, a more productive path forward involves exploring hybrid\n   322→models where AI tools augment human instruction, handle specific\n   323→drill-and-practice components, or provide supplementary support.[^26] The proposed system could serve as the scalable component of such a hybrid model, providing mastery-based skill building and practice while human instructors focus on higher-order language skills, cultural competency development, and motivational support. This approach potentially addresses Bloom's 2 Sigma Problem by combining the scalability of technology-mediated instruction with the effectiveness principles identified in one-on-one tutoring research.\n   324→\n   325→To summarize these comparisons, Table 1 provides a qualitative\n   326→assessment of different language learning approaches based on key\n   327→features identified in the literature and the proposal\\'s aims.\n   328→\n   329→**Table 1: Comparison of Language Learning Approaches**\n   330→\n   331→  ----------------------------------------------------------------------------------------------\n   332→  **Feature**           **Human        **Static Apps  **Basic AI      **Proposed System\n   333→                        Tutors**       (e.g.,         Chatbots        (Fine-tuned+RAG+Local)**\n   334→                                       Duolingo)**    (Generic        \n   335→                                                      LLMs)**         \n   336→  --------------------- -------------- -------------- --------------- --------------------------\n   337→  **Personalization**   High           Low            Medium          High (Targeted)\n   338→                                                      (potential)     \n   339→\n   340→  **Feedback Quality**  High (Nuanced) Low (Basic     Variable (Often High (Targeted &\n   341→                                       Correction)    Generic)        Pedagogical)\n   342→\n   343→  **Curriculum          Variable       High (Fixed    Low (Generic    High (Dynamic via RAG)\n   344→  Integration**                        Curriculum)    Knowledge)      \n   345→\n   346→  **Scalability**       Low            High           High            High\n   347→\n   348→  **Cost**              High           Low/Freemium   Variable (API   Low (Operational, after\n   349→                                                      costs)          setup)\n   350→\n   351→  **Cultural Nuance**   High           Low            Low/Variable    Medium/High (via RAG)\n   352→\n   353→  **Privacy (Learner    Variable       Medium (App    Low             High (Local Deployment)\n   354→  Data)**                              Policies)      (Cloud-based)   \n   355→\n   356→  **Human Interaction** High           None           Low (Simulated) Low (Simulated)\n   357→  ----------------------------------------------------------------------------------------------\n   358→\n   359→*Note: Assessments for the \\\"Proposed System\\\" reflect the project\\'s\n   360→intended goals and potential based on its design.*\n   361→\n   362→## 3. Fine-Tuning LLMs for Pedagogical Goals in Language Education\n   363→\n   364→### 3.1. Rationale and Methodologies\n   365→\n   366→While pre-trained LLMs possess broad language understanding capabilities\n   367→derived from vast datasets [^3], they are essentially generalists.\n   368→Fine-tuning is a critical process for adapting these models to perform\n   369→specific tasks or excel within particular domains.[^57] It involves\n   370→further training a pre-trained model on a smaller, more specialized\n   371→dataset to refine its capabilities and align its behavior with desired\n   372→outcomes.[^57] In the context of education, and specifically language\n   373→tutoring, the rationale for fine-tuning is to move beyond generic\n   374→conversational ability and instill specific pedagogical\n   375→competencies.[^29] The goal is \\\"pedagogical alignment\\\"---training LLMs\n   376→to emulate effective teaching strategies, such as providing guided\n   377→discovery rather than direct answers, offering constructive feedback,\n   378→and adapting to learner progress.[^29] This contrasts with standard LLMs\n   379→often optimized for simply providing the most plausible or preferred\n   380→response to a prompt.[^47] The proposal explicitly aims for\n   381→curriculum-anchored fine-tuning to achieve this pedagogical focus\n   382→(Proposal Section 6).\n   383→\n   384→Several methodologies exist for fine-tuning LLMs:\n   385→\n   386→-   **Supervised Fine-Tuning (SFT):** This is a common approach where\n   387→    the model is trained on a dataset of labeled examples, typically\n   388→    prompt-response pairs that demonstrate the desired behavior.[^29] For\n   389→    pedagogical fine-tuning, this dataset might consist of examples of\n   390→    effective tutor-student interactions, Socratic questioning\n   391→    sequences, or well-structured feedback. The process involves\n   392→    defining the target task clearly, selecting an appropriate\n   393→    pre-trained base model, choosing relevant hyperparameters (like\n   394→    learning rate and batch size), and training the model to minimize\n   395→    the difference between its predictions and the target labels.[^57]\n   396→\n   397→-   **Instruction Fine-Tuning:** A variant of SFT, this involves\n   398→    training the model specifically on examples that show how it should\n   399→    respond to various instructional prompts or queries.[^57] This helps\n   400→    the model learn to follow specific pedagogical instructions.\n   401→\n   402→-   **Parameter-Efficient Fine-Tuning (PEFT):** Recognizing that\n   403→    fine-tuning all parameters of a large LLM is computationally\n   404→    intensive and requires significant memory [^13], PEFT methods have\n   405→    emerged. Techniques like Low-Rank Adaptation (LoRA) (though not\n   406→    explicitly named in the snippets, frameworks like Unsloth mentioned\n   407→    in the proposal often use them) involve updating only a small\n   408→    fraction of the model\\'s parameters. This significantly reduces the\n   409→    computational resources and time required for fine-tuning, making it\n   410→    more feasible.[^57]\n   411→\n   412→-   **Preference Optimization (e.g., DPO):** Methods like Direct\n   413→    Preference Optimization (DPO) align LLMs based on preferences\n   414→    between pairs of possible responses.[^29] For instance, given a\n   415→    student query, one response might be a direct answer, while another\n   416→    might be a guiding question. A human or AI judge labels the guiding\n   417→    question as preferred. The model is then trained to increase the\n   418→    likelihood of generating preferred responses over rejected ones.[^29]\n   419→    This technique has shown promise for steering LLMs towards Socratic\n   420→    behavior.[^49]\n   421→\n   422→### 3.2. Applications in Language Pedagogy\n   423→\n   424→Fine-tuning enables the customization of LLMs to serve specific\n   425→pedagogical functions within language education. Researchers are\n   426→applying these techniques to develop tutors capable of:\n   427→\n   428→-   **Implementing Specific Teaching Strategies:** Fine-tuning can train\n   429→    LLMs to adopt particular pedagogical approaches, such as the\n   430→    Socratic method, where the tutor guides the student towards\n   431→    discovering answers through carefully crafted questions rather than\n   432→    providing them directly.[^29] It can also be used to encourage\n   433→    scaffolded guidance, providing hints or breaking down problems.[^29]\n   434→\n   435→-   **Improving Feedback Quality and Characteristics:** Fine-tuning can\n   436→    target the generation of more effective feedback. This includes\n   437→    improving dimensions like the level of detail, accuracy, relevance\n   438→    to learning objectives, and overall helpfulness.[^13] Furthermore, it\n   439→    can shape the *characteristics* of the feedback, such as its tone\n   440→    (positive vs. negative), directness (direct vs. indirect), and\n   441→    specificity (general vs. specific), aligning it with pedagogical\n   442→    best practices or learner preferences.[^24] For example, score-based\n   443→    prompting, which guides feedback generation based on rubric scores,\n   444→    improved feedback quality in EFL writing tutoring.[^24]\n   445→\n   446→-   **Curriculum Alignment:** As mentioned in the proposal, fine-tuning\n   447→    can be used to anchor the LLM\\'s knowledge and responses within a\n   448→    specific curriculum, ensuring its interactions are relevant to the\n   449→    course content (Proposal Section 6).\n   450→\n   451→Examples from recent studies illustrate these applications. GuideLM, an\n   452→LLM fine-tuned for programming education using SFT, demonstrated\n   453→improved Socratic guidance and economy of words compared to the base\n   454→model.[^48] Another study successfully used DPO to fine-tune an LLM for\n   455→Socratic interactions, showing significant improvement over prompting\n   456→alone.[^49] Research investigating Learning from Human Preferences (LHP)\n   457→algorithms (which include methods like DPO) found they outperformed SFT\n   458→in achieving pedagogical alignment for tutoring tasks.[^29]\n   459→\n   460→### 3.3. Effectiveness, Challenges, and Trade-offs\n   461→\n   462→While fine-tuning holds considerable promise for creating pedagogically\n   463→effective LLM tutors, it also presents significant challenges and\n   464→inherent trade-offs.\n   465→\n   466→-   **Effectiveness:** Studies confirm that fine-tuning can successfully\n   467→    steer LLMs towards desired pedagogical behaviors, resulting in\n   468→    interactions that are perceived as more educationally valuable than\n   469→    those from generic models or prompted base models.[^24] Expert raters\n   470→    have shown preference for fine-tuned models specifically for\n   471→    educational purposes, even when acknowledging certain\n   472→    trade-offs.[^48]\n   473→\n   474→-   **Challenge: Pedagogical Alignment vs. Accuracy Trade-off:** A major\n   475→    challenge is the observed trade-off between optimizing for\n   476→    pedagogical goals and maintaining the model\\'s general knowledge and\n   477→    accuracy.[^48] Fine-tuning an LLM to be more Socratic, concise, or to\n   478→    avoid giving direct answers might inadvertently reduce its ability\n   479→    to provide factually correct information or solve problems\n   480→    accurately when needed.[^48] This suggests a potential conflict\n   481→    between specialized pedagogical behavior and broad knowledge\n   482→    retention.\n   483→\n   484→-   **Challenge: The \\\"Student Data Paradox\\\":** A related but distinct\n   485→    challenge arises when fine-tuning involves datasets containing\n   486→    authentic student-tutor interactions. Such data inevitably includes\n   487→    student errors, misconceptions, and non-standard language. Research\n   488→    has uncovered the \\\"Student Data Paradox\\\": training LLMs on this\n   489→    data to better understand and model learner behavior can\n   490→    paradoxically degrade the LLM\\'s own factual knowledge base and\n   491→    reasoning capabilities.[^59] This creates a fundamental difficulty:\n   492→    making the tutor better at understanding students might make it\n   493→    worse at providing accurate guidance.\n   494→\n   495→-   **Challenge: Data Requirements, Cost, and Maintenance:** Effective\n   496→    fine-tuning hinges on the availability of large, high-quality,\n   497→    task-specific datasets.[^49] Creating datasets that accurately\n   498→    represent complex pedagogical strategies is a non-trivial task,\n   499→    requiring significant pedagogical expertise and effort.[^49]\n   500→    Furthermore, the process of fine-tuning, especially full\n   501→    fine-tuning, is computationally expensive, requiring substantial\n   502→    hardware resources.[^13] While PEFT methods alleviate this burden\n   503→    [^57], costs remain. Additionally, as underlying foundation models\n   504→    are frequently updated, fine-tuned versions need to be maintained\n   505→    and potentially retrained, adding ongoing costs and effort.[^48]\n   506→\n   507→-   **Challenge: Evaluation Complexity:** Assessing the true pedagogical\n   508→    effectiveness of fine-tuned LLM tutors is inherently difficult.\n   509→    Current evaluation methods often rely on subjective judgments or\n   510→    lack standardized metrics, particularly for measuring\n   511→    adaptivity---how well the tutor adjusts to the learner\\'s evolving\n   512→    state.[^24] The development of robust evaluation taxonomies and\n   513→    benchmarks is an active area of research.[^61]\n   514→\n   515→The interplay between the pedagogical alignment vs. accuracy trade-off\n   516→[^48] and the Student Data Paradox [^59] highlights a significant hurdle.\n   517→Attempting to make an LLM behave more like an effective tutor through\n   518→fine-tuning risks compromising its knowledge integrity from two\n   519→directions: the inherent trade-offs of specialization and the potential\n   520→\\\"contamination\\\" from learning student errors. This suggests that\n   521→fine-tuning, while valuable for shaping interaction style, might be\n   522→insufficient on its own for building reliable and knowledgeable AI\n   523→tutors. It points towards the need for complementary techniques, such as\n   524→RAG, to ensure the tutor has access to accurate, up-to-date, and\n   525→curriculum-specific information, mitigating the knowledge degradation\n   526→risks associated with fine-tuning.\n   527→\n   528→## 4. Retrieval-Augmented Generation (RAG) for Curriculum and Cultural Integration\n   529→\n   530→### 4.1. RAG Explained: Bridging Internal Knowledge and External Data\n   531→\n   532→Retrieval-Augmented Generation (RAG) represents a powerful architectural\n   533→approach designed to enhance the capabilities of LLMs by dynamically\n   534→integrating external knowledge into the generation process.[^62] Unlike\n   535→standard LLMs that rely solely on the information encoded within their\n   536→parameters during training (parametric knowledge), RAG systems first\n   537→retrieve relevant information from an external, often domain-specific or\n   538→up-to-date, knowledge base before generating a response.[^64]\n   539→\n   540→The typical RAG architecture consists of two main components [^62]:\n   541→\n   542→1.  **Retriever:** This component takes the user\\'s input query and\n   543→    searches an external corpus (e.g., a collection of documents,\n   544→    database records, web pages) to find the most relevant pieces of\n   545→    information. This retrieval process often employs techniques like\n   546→    dense vector retrieval, where text is converted into numerical\n   547→    embeddings, and similarity searches (e.g., cosine similarity) are\n   548→    performed within a vector database to find contextually related data\n   549→    chunks.[^62]\n   550→\n   551→2.  **Generator:** This component is typically a standard LLM. It\n   552→    receives the original user prompt *augmented* with the relevant\n   553→    context retrieved by the retriever. The LLM then synthesizes this\n   554→    combined information to generate a final, more informed, accurate,\n   555→    and contextually relevant response.[^62]\n   556→\n   557→The core advantage of RAG is its ability to ground LLM outputs in\n   558→specific, verifiable, and potentially real-time external data\n   559→sources.[^63] This allows LLMs to access knowledge beyond their static\n   560→training cut-off dates and incorporate domain-specific or proprietary\n   561→information without the need for expensive and time-consuming retraining\n   562→of the entire model.[^62] Consequently, RAG is a key technique for\n   563→addressing common LLM limitations such as generating factually incorrect\n   564→information (hallucinations) and relying on outdated knowledge.[^63]\n   565→\n   566→### 4.2. Applications of RAG in Educational AI\n   567→\n   568→The ability of RAG to connect LLMs with external knowledge sources makes\n   569→it particularly promising for educational applications, where accuracy,\n   570→relevance, and alignment with specific learning contexts are crucial.\n   571→\n   572→-   **Curriculum Integration:** A major challenge for generic LLMs in\n   573→    tutoring is their lack of awareness of specific course curricula.\n   574→    RAG provides a mechanism to overcome this by allowing the system to\n   575→    retrieve information directly from course materials---such as\n   576→    textbooks, lecture notes, syllabi, specific vocabulary lists, or\n   577→    grammar rules---stored in an external knowledge base.[^44] When a\n   578→    student asks a question or engages in an activity, the RAG system\n   579→    can retrieve the relevant sections of the curriculum and use them to\n   580→    generate a response that is directly aligned with what is being\n   581→    taught in the course (Proposal Sections 2, 6). This ensures the\n   582→    tutoring is relevant and reinforces classroom learning.[^44]\n   583→\n   584→-   **Cultural Relevance:** Similar to curriculum integration, RAG can\n   585→    be used to enhance the cultural relevance of language tutoring. By\n   586→    creating knowledge bases containing culturally specific information,\n   587→    examples, social norms, or relevant media pertaining to the target\n   588→    language culture, the RAG system can retrieve and incorporate this\n   589→    context into its interactions (Proposal Sections 2, 4, 6). This can\n   590→    help learners develop not just linguistic competence but also\n   591→    intercultural understanding.\n   592→\n   593→-   **Factual Grounding and Accuracy:** Education demands a high degree\n   594→    of factual accuracy. RAG significantly improves the reliability of\n   595→    LLM outputs by grounding them in authoritative external sources.[^44]\n   596→    For language learning, this means the tutor can provide verified\n   597→    definitions, accurate grammar explanations, and reliable cultural\n   598→    information, citing sources if necessary.[^63] Studies specifically\n   599→    investigating RAG in educational contexts confirm its effectiveness\n   600→    in reducing hallucinations and improving the trustworthiness of AI\n   601→    responses.[^69]\n   602→\n   603→-   **Personalization and Context-Awareness:** RAG can enhance\n   604→    personalization by retrieving information tailored to a specific\n   605→    student\\'s query, previous interactions, or identified knowledge\n   606→    gaps.[^65] This allows for more context-aware tutoring that adapts to\n   607→    the immediate learning need.\n   608→\n   609→-   **Specific Educational Implementations:** RAG is being actively\n   610→    explored in various educational tools. Surveys are identifying\n   611→    numerous uses for RAG chatbots in education.[^66] Advanced forms like\n   612→    Knowledge Graph-enhanced RAG (KG-RAG), which leverages structured\n   613→    knowledge representations, have shown promise in improving learning\n   614→    outcomes in AI tutoring systems by enabling more effective\n   615→    context-aware retrieval.[^70] RAG can also serve as a tool for\n   616→    educators, streamlining their access to relevant curricular\n   617→    resources and supporting materials.[^44]\n   618→\n   619→### 4.3. Potential and Challenges of RAG in Language Tutoring\n   620→\n   621→RAG offers significant potential to transform LLM-based language tutors\n   622→into more effective, reliable, and contextually relevant educational\n   623→tools.\n   624→\n   625→-   **Potential:** By dynamically injecting curriculum-specific content,\n   626→    cultural nuances, and verified factual information, RAG directly\n   627→    addresses key weaknesses of standalone LLMs, namely their lack of\n   628→    specific knowledge, potential for inaccuracy, and generic\n   629→    nature.[^44] It enables the creation of tutors that are adaptable to\n   630→    specific courses and learner contexts without requiring constant\n   631→    retraining of the base LLM, making personalized and relevant AI\n   632→    tutoring more feasible.\n   633→\n   634→-   **Challenge: Retrieval Quality:** The effectiveness of RAG is\n   635→    fundamentally dependent on the retriever\\'s ability to find truly\n   636→    relevant and high-quality information from the knowledge base.[^68]\n   637→    If the retrieved documents are irrelevant, noisy, or inaccurate, the\n   638→    generator\\'s output will likely be compromised, regardless of the\n   639→    LLM\\'s capabilities. Ensuring high-quality retrieval is a major\n   640→    focus of ongoing RAG research, leading to techniques like reranking\n   641→    retrieved results [^63] or implementing self-correction mechanisms\n   642→    within the retrieval process (e.g., CRAG).[^68]\n   643→\n   644→-   **Challenge: Knowledge Base Creation and Maintenance:** Implementing\n   645→    RAG requires the creation and ongoing maintenance of the external\n   646→    knowledge bases.[^64] For educational applications, this involves\n   647→    curating, structuring, preprocessing (e.g., chunking, embedding),\n   648→    and indexing relevant curriculum materials, cultural information,\n   649→    and factual resources. This requires significant upfront effort,\n   650→    subject matter expertise, and processes for keeping the knowledge\n   651→    base updated as curricula or information changes.[^44] Ensuring the\n   652→    quality and accessibility of this data is critical.[^65]\n   653→\n   654→-   **Challenge: Integration Complexity and Latency:** Setting up a\n   655→    functional RAG pipeline involves integrating multiple components:\n   656→    the retriever, the vector database/knowledge store, and the\n   657→    generator LLM.[^62] Ensuring these components work together\n   658→    seamlessly and efficiently, particularly minimizing latency in the\n   659→    retrieval step, can be technically challenging.\n   660→\n   661→-   **Challenge: Contextual Synthesis and Understanding:** Even with\n   662→    relevant information retrieved, the LLM generator must effectively\n   663→    synthesize this external context with the user\\'s prompt and its own\n   664→    internal knowledge to produce a coherent and helpful response.\n   665→    Relying solely on semantic similarity during retrieval might not\n   666→    capture the deeper conceptual relationships often required for\n   667→    effective pedagogical explanations.[^70] Approaches like KG-RAG\n   668→    attempt to address this by incorporating structured knowledge.[^70]\n   669→\n   670→The distinct capabilities and limitations of fine-tuning and RAG suggest\n   671→they are complementary approaches. Fine-tuning primarily addresses *how*\n   672→the LLM interacts---shaping its pedagogical style, tone, and adherence\n   673→to specific teaching strategies (Section 3). RAG, on the other hand,\n   674→primarily addresses *what* the LLM knows---providing it with accurate,\n   675→up-to-date, and context-specific information from external sources.[^62]\n   676→The proposal\\'s strategy of combining both techniques (Proposal Section\n   677→6) leverages this synergy. Fine-tuning can equip the LLM with the\n   678→desired tutoring behaviors (e.g., asking guiding questions, providing\n   679→feedback in a certain format), while RAG ensures the content discussed\n   680→during these interactions is accurate, aligned with the curriculum, and\n   681→culturally appropriate. This integrated approach holds the potential to\n   682→overcome the limitations encountered when using either technique in\n   683→isolation---mitigating the accuracy concerns of fine-tuning while adding\n   684→pedagogical intelligence to the factual grounding provided by RAG.\n   685→\n   686→## 5. Local LLM Deployment in Educational Settings (Ollama)\n   687→\n   688→### 5.1. Rationale: Privacy, Control, and Cost\n   689→\n   690→The deployment model for LLMs---whether cloud-based or local---has\n   691→significant implications, particularly in sensitive domains like\n   692→education. Running LLMs locally, meaning on hardware controlled by the\n   693→institution (on-premises servers, institutional clusters, or even\n   694→individual machines) rather than relying on third-party cloud providers,\n   695→offers several compelling advantages:\n   696→\n   697→-   **Privacy & Security:** This is arguably the most critical driver\n   698→    for local deployment in education.[^71] Student interactions with\n   699→    tutoring systems generate sensitive data, potentially including\n   700→    performance metrics, learning patterns, and even personally\n   701→    identifiable information (PII). Local deployment keeps this data\n   702→    within the institution\\'s controlled environment, mitigating risks\n   703→    associated with transmitting data to external servers and helping\n   704→    comply with stringent data privacy regulations like FERPA in the US\n   705→    or GDPR in Europe.[^10] The proposal explicitly identifies data\n   706→    privacy risks with commercial cloud providers as a key issue to\n   707→    address (Proposal Sections 5, 6).\n   708→\n   709→-   **Control:** Local deployment grants institutions greater autonomy\n   710→    and control over the AI models they use.[^71] This includes selecting\n   711→    specific open-source models, configuring them according to\n   712→    institutional policies, managing update cycles, and ensuring\n   713→    alignment with educational goals without being subject to the terms,\n   714→    conditions, or potential changes of external service providers.\n   715→\n   716→-   **Cost-Effectiveness:** While initial hardware setup or utilization\n   717→    might involve costs, local deployment can be more cost-effective in\n   718→    the long run compared to the potentially high and recurring API call\n   719→    fees charged by commercial cloud LLM providers.[^71] This is\n   720→    particularly true for institutions that can leverage existing\n   721→    computing infrastructure, such as the DEAC cluster mentioned in the\n   722→    proposal (Proposal Sections 3, 8). Using open-source models locally\n   723→    avoids licensing fees.[^17]\n   724→\n   725→-   **Offline Access & Reduced Latency:** Local models can function\n   726→    without a constant internet connection, ensuring reliability even\n   727→    with intermittent network access.[^71] Processing queries locally can\n   728→    also potentially reduce network latency compared to sending requests\n   729→    to remote servers, leading to faster response times.[^71]\n   730→\n   731→-   **Customization:** Having direct access to the model facilitates\n   732→    easier experimentation with fine-tuning and other customizations to\n   733→    tailor the LLM\\'s behavior to specific pedagogical needs or\n   734→    institutional requirements.[^74]\n   735→\n   736→### 5.2. Ollama as a Deployment Framework\n   737→\n   738→Frameworks have emerged to simplify the often complex process of setting\n   739→up and managing LLMs locally. Ollama is highlighted in the proposal and\n   740→several sources as one such tool [^71] (Proposal Sections 2, 3, 6). It is\n   741→presented as an open-source platform designed to streamline the local\n   742→deployment of various popular open-access LLMs, such as those from the\n   743→Llama or Mistral families.[^72]\n   744→\n   745→Key features attributed to Ollama include:\n   746→\n   747→-   **Ease of Use:** Ollama aims to simplify the process through\n   748→    user-friendly interfaces, primarily a command-line interface (CLI),\n   749→    allowing users to download (pull), run, and interact with LLMs using\n   750→    simple commands.[^72]\n   751→\n   752→-   **Model Management:** It helps manage different models and their\n   753→    versions automatically.[^78]\n   754→\n   755→-   **Configuration:** Ollama allows users to set model parameters (like\n   756→    temperature or top_p) during runtime and define custom model\n   757→    configurations and system prompts using a \\\"Modelfile\\\".[^74]\n   758→\n   759→-   **Integration:** It provides ways to interact with the running\n   760→    models programmatically, for instance, through APIs or libraries for\n   761→    languages like Python and Javascript, enabling integration into\n   762→    larger applications like the proposed web-based tutoring\n   763→    interface.[^74]\n   764→\n   765→### 5.3. Resource Requirements and Performance Trade-offs\n   766→\n   767→Deploying LLMs locally, even with tools like Ollama, imposes significant\n   768→demands on hardware resources.\n   769→\n   770→-   **Hardware Requirements:** A reasonably modern system is generally\n   771→    required. This includes a multi-core 64-bit CPU (support for\n   772→    instruction sets like AVX2 or AVX512 is often beneficial or required\n   773→    [^73]), adequate RAM (minimums are often cited around 8GB, but 16GB\n   774→    or even 32GB+ is recommended for larger models [^71]), and sufficient\n   775→    fast storage (SSD recommended) for the models themselves, which can\n   776→    range from a few gigabytes to tens or hundreds of gigabytes.[^74]\n   777→\n   778→-   **GPU Acceleration:** While LLMs *can* run on the CPU alone,\n   779→    performance (inference speed, measured in tokens per second) is\n   780→    typically very slow.[^75] A dedicated GPU, particularly an NVIDIA GPU\n   781→    with sufficient Video RAM (VRAM) and CUDA support, dramatically\n   782→    accelerates processing.[^71] The amount of VRAM is often the primary\n   783→    limiting factor determining which models can be run efficiently, as\n   784→    the model\\'s parameters need to fit into the GPU memory.[^79] Ollama\n   785→    is designed to utilize available GPU resources.[^74]\n   786→\n   787→-   **Model Size vs. Performance:** There is a direct trade-off between\n   788→    model size (number of parameters, e.g., 1B, 7B, 13B, 70B) and\n   789→    performance/resource requirements.[^74] Smaller models (e.g., 1B-7B)\n   790→    are less demanding on RAM/VRAM and run faster on lower-end hardware\n   791→    but generally possess less knowledge and reasoning capability.[^75]\n   792→    Larger models offer potentially better performance and more nuanced\n   793→    capabilities but require substantially more powerful hardware.[^74]\n   794→    Techniques like model quantization (e.g., using 4-bit precision\n   795→    instead of 16-bit or 32-bit) can significantly reduce the memory\n   796→    footprint and computational cost of models, making it feasible to\n   797→    run larger models on less powerful hardware, albeit sometimes with a\n   798→    slight reduction in output quality.[^78]\n   799→\n   800→-   **Scalability Limitations:** Unlike cloud platforms that offer\n   801→    virtually limitless scalability (at a cost), local deployment is\n   802→    constrained by the available hardware resources.[^42] Supporting a\n   803→    large number of concurrent users might require significant\n   804→    investment in local infrastructure or sophisticated load balancing\n   805→    across multiple instances.[^75] The proposal leverages the\n   806→    university\\'s DEAC cluster, which likely provides access to more\n   807→    substantial resources than a typical desktop machine, potentially\n   808→    mitigating some scalability concerns for a pilot phase (Proposal\n   809→    Sections 3, 6).\n   810→\n   811→-   **Maintenance Overhead:** Running LLMs locally necessitates\n   812→    technical expertise for initial setup, configuration, software\n   813→    updates (Ollama, drivers, models), performance monitoring, and\n   814→    troubleshooting.[^71] The proposal acknowledges this by including\n   815→    support from an HPC Systems Administrator (Proposal Section 3).\n   816→\n   817→### 5.4. Local Deployment vs. Cloud-Based Solutions\n   818→\n   819→The decision between local and cloud deployment involves weighing\n   820→distinct advantages and disadvantages. Local deployment, facilitated by\n   821→tools like Ollama, excels in scenarios where **data privacy, security,\n   822→and control** are paramount.[^71] It offers potential **cost savings** by\n   823→utilizing existing hardware and avoiding recurring API fees [^71],\n   824→enables **offline functionality** [^74], and can provide **low\n   825→latency**.[^71] However, it is fundamentally limited by **available\n   826→hardware resources**, posing challenges for **scalability** and running\n   827→the largest, most capable models.[^72] It also requires **technical\n   828→expertise for maintenance**.[^71]\n   829→\n   830→Conversely, cloud-based solutions offer easy **access to\n   831→state-of-the-art models**, immense **scalability**, and reduced\n   832→**maintenance burden** for the end-user.[^72] However, they introduce\n   833→significant **data privacy risks** due to data transmission to third\n   834→parties [^72], incur **ongoing operational costs** based on usage [^72],\n   835→and depend on **stable internet connectivity**.[^75]\n   836→\n   837→The choice is therefore highly dependent on the specific context and\n   838→priorities. For educational institutions, the heightened sensitivity\n   839→surrounding student data [^11] often makes the privacy guarantees of\n   840→local deployment particularly attractive, if not essential for\n   841→compliance.[^10] When coupled with the availability of institutional\n   842→computing resources, such as a university HPC cluster, the hardware\n   843→limitations can be partially overcome. In this light, the proposal\\'s\n   844→decision to pursue local deployment using Ollama appears as a strategic\n   845→alignment with the specific constraints and priorities of its\n   846→educational setting, prioritizing privacy and leveraging available\n   847→resources, rather than merely a technical preference.\n   848→\n   849→## 6. Identifying Research Gaps and Opportunities\n   850→\n   851→Synthesizing the findings from the literature reveals several key gaps\n   852→and challenges in the current landscape of LLM-based language tutoring,\n   853→alongside corresponding opportunities for innovation.\n   854→\n   855→### 6.1. Synthesis of Limitations from Literature\n   856→\n   857→-   **Gap 1: Deep Pedagogical Integration and Adaptivity:** Despite\n   858→    progress, a significant gap exists between current LLM capabilities\n   859→    and truly effective, pedagogically grounded tutoring.[^19] Many\n   860→    systems mimic conversation but lack deep instructional logic or the\n   861→    ability to adapt based on robust models of student cognition and\n   862→    learning progression, as seen in traditional Intelligent Tutoring\n   863→    Systems (ITS).[^28] There is a need for LLMs that can reliably\n   864→    implement specific, evidence-based teaching strategies (e.g.,\n   865→    mastery learning, cognitive apprenticeship, productive failure) and\n   866→    adapt their guidance based on nuanced assessments of student\n   867→    understanding, not just surface-level correctness.[^42]\n   868→\n   869→-   **Gap 2: Curriculum Specificity and Dynamic Content Adaptation:**\n   870→    Generic LLMs are inherently unaware of the specific content,\n   871→    sequencing, and objectives of a particular course curriculum\n   872→    (Proposal Sections 4, 5). While RAG offers a solution for retrieving\n   873→    relevant information [^44], challenges remain in seamlessly\n   874→    integrating this information, dynamically adapting to real-time\n   875→    classroom activities or evolving lesson plans, and structuring\n   876→    knowledge bases optimally for educational retrieval.[^65] How to best\n   877→    represent and query complex curricular knowledge remains an open\n   878→    question.\n   879→\n   880→-   **Gap 3: Nuanced Cultural Integration and Sensitivity:** Providing\n   881→    culturally relevant language education goes beyond retrieving\n   882→    factual cultural notes. It involves understanding and generating\n   883→    content that reflects subtle cultural nuances, communication styles,\n   884→    and diverse perspectives appropriately. Current approaches,\n   885→    including basic RAG, may struggle to achieve this level of depth and\n   886→    sensitivity dynamically across varied learner backgrounds (Proposal\n   887→    Section 4). Research is needed on how to imbue LLMs with genuine\n   888→    intercultural competence.\n   889→\n   890→-   **Gap 4: Balancing Pedagogy, Accuracy, Efficiency, and Knowledge\n   891→    Integrity:** As highlighted previously, there are inherent tensions\n   892→    between optimizing LLMs for pedagogical alignment, maintaining\n   893→    factual accuracy, ensuring computational efficiency (especially for\n   894→    local deployment), and preserving the integrity of the model\\'s\n   895→    knowledge base (avoiding degradation from fine-tuning trade-offs or\n   896→    the Student Data Paradox).[^48] Finding solutions that effectively\n   897→    balance these competing demands is a critical research challenge.\n   898→\n   899→-   **Gap 5: Robust and Standardized Evaluation Frameworks:** The field\n   900→    currently lacks widely accepted, standardized methodologies and\n   901→    metrics for rigorously evaluating the pedagogical effectiveness,\n   902→    adaptivity, and actual impact on student learning outcomes of\n   903→    LLM-based tutors.[^24] Current evaluations often rely on subjective\n   904→    measures, limited benchmarks, or focus on technical performance\n   905→    rather than educational impact.[^61] Developing reliable ways to\n   906→    measure and compare AI tutor efficacy is essential for progress.\n   907→\n   908→-   **Gap 6: Privacy-Preserving Personalization and Data Minimization:**\n   909→    Achieving deep personalization typically relies on collecting and\n   910→    analyzing substantial amounts of student interaction data.[^13] This\n   911→    creates a direct conflict with the increasing need for stringent\n   912→    data privacy and security in education.[^10] Developing AI tutoring\n   913→    systems that can provide meaningful personalization while adhering\n   914→    to strict privacy constraints, potentially through local deployment\n   915→    and data minimization techniques, remains a significant research and\n   916→    engineering challenge.\n   917→\n   918→### 6.2. Opportunities for Innovation\n   919→\n   920→These gaps point towards several promising avenues for future research\n   921→and development:\n   922→\n   923→-   **Advanced Pedagogical Alignment Techniques:** Developing novel\n   924→    fine-tuning methods (beyond basic SFT or DPO) or prompting\n   925→    strategies specifically designed to instill complex pedagogical\n   926→    behaviors while minimizing negative impacts on accuracy and\n   927→    knowledge integrity.\n   928→\n   929→-   **Sophisticated Educational RAG:** Creating more advanced RAG\n   930→    frameworks tailored for educational content, potentially\n   931→    incorporating structured knowledge representations like knowledge\n   932→    graphs (KG-RAG) [^70], hierarchical summarization (RAPTOR) [^68], or\n   933→    improved retrieval and fusion mechanisms to better handle curriculum\n   934→    complexity and conceptual relationships.\n   935→\n   936→-   **Hybrid Human-AI Tutoring Models:** Designing and evaluating\n   937→    systems that effectively combine the strengths of AI tutors\n   938→    (scalability, availability, practice) with the irreplaceable skills\n   939→    of human educators (empathy, deep understanding, mentorship),\n   940→    defining optimal roles and workflows for each.\n   941→\n   942→-   **Privacy-Enhancing Architectures:** Building robust, secure, and\n   943→    effective AI tutoring systems based on local deployment models (like\n   944→    Ollama) or exploring other privacy-preserving techniques (e.g.,\n   945→    federated learning, differential privacy) suitable for educational\n   946→    data.\n   947→\n   948→-   **Comprehensive Evaluation Methodologies:** Establishing\n   949→    standardized benchmarks, metrics, and protocols for evaluating AI\n   950→    tutors across multiple dimensions, including pedagogical alignment,\n   951→    adaptivity, learning gains, user experience, and ethical\n   952→    considerations.[^61]\n   953→\n   954→-   **Multimodal and Multilingual Integration:** Exploring the\n   955→    integration of multimodal capabilities (processing text, image,\n   956→    audio, video) for richer language learning interactions [^14] and\n   957→    improving the performance and fairness of LLMs across diverse\n   958→    languages, especially lower-resource ones.[^14]\n   959→\n   960→## 7. Positioning the Proposed Project\n   961→\n   962→The research proposal \\\"Adaptive Second Language Tutoring with\n   963→Fine-Tuned and RAG-Enhanced local LLMs\\\" positions itself strategically\n   964→within the current landscape by directly addressing several of the\n   965→identified research gaps through a specific combination of emerging\n   966→technologies.\n   967→\n   968→### 7.1. Addressing Identified Gaps\n   969→\n   970→The project\\'s design incorporates elements aimed at tackling key\n   971→limitations:\n   972→\n   973→-   **Addressing Gap 1 (Pedagogy):** The proposal explicitly includes\n   974→    the **fine-tuning** of open-access LLMs using frameworks like\n   975→    Unsloth or MLX-LM (Proposal Section 2). The intention is to train\n   976→    these models on pedagogical datasets to move beyond generic\n   977→    conversation and towards structured, effective tutoring interactions\n   978→    aligned with language learning principles (Proposal Section 6).\n   979→\n   980→-   **Addressing Gap 2 & 3 (Curriculum/Culture):** The integration of\n   981→    **Retrieval-Augmented Generation (RAG)** is proposed to dynamically\n   982→    inject course-specific materials (vocabulary, grammar) and relevant\n   983→    cultural content into the tutor\\'s knowledge base (Proposal Sections\n   984→    2, 6). This aims to make the tutor contextually aware, aligned with\n   985→    existing curricula, and more culturally responsive, overcoming the\n   986→    limitations of generic LLM knowledge (Proposal Section 4).\n   987→\n   988→-   **Addressing Gap 4 (Balance):** The project attempts to navigate the\n   989→    complex balance between pedagogy, accuracy, and efficiency by\n   990→    **combining fine-tuning and RAG**. As discussed (Section 4.3),\n   991→    fine-tuning can shape the pedagogical interaction style, while RAG\n   992→    provides a mechanism to ground the content in accurate, relevant\n   993→    external knowledge. This synergy potentially mitigates the accuracy\n   994→    degradation risks associated with fine-tuning alone and adds\n   995→    pedagogical structure to RAG\\'s factual grounding.\n   996→\n   997→-   **Addressing Gap 5 (Evaluation):** While the initial phase described\n   998→    in the proposal focuses on establishing technical feasibility and\n   999→    preliminary educator evaluation as a proof of concept (Proposal\n  1000→    Section 7), this foundational work is a necessary prerequisite for\n  1001→    future, more rigorous evaluations involving student learning\n  1002→    outcomes, potentially through larger grants sought based on the\n  1003→    initial success.\n  1004→\n  1005→-   **Addressing Gap 6 (Privacy):** The project tackles privacy concerns\n  1006→    head-on by opting for **local deployment using Ollama** on\n  1007→    university-controlled infrastructure (the DEAC cluster) (Proposal\n  1008→    Sections 3, 6, 8). This architectural choice is explicitly motivated\n  1009→    by the desire to keep sensitive learner data on-premises and avoid\n  1010→    reliance on external commercial APIs, aligning with institutional\n  1011→    needs for data security and control (Proposal Section 5, 6).\n  1012→\n  1013→### 7.2. Novelty and Potential Contribution\n  1014→\n  1015→The primary novelty of the proposed project lies not necessarily in the\n  1016→individual components themselves, but in their **synergistic\n  1017→integration** applied specifically to the challenge of adaptive second\n  1018→language tutoring within an institutional context:\n  1019→\n  1020→1.  **Pedagogical Fine-Tuning:** Adapting the LLM\\'s conversational\n  1021→    style and interaction patterns specifically for language tutoring\n  1022→    goals.\n  1023→\n  1024→2.  **RAG Enhancement:** Dynamically grounding the tutor\\'s knowledge in\n  1025→    specific curriculum requirements and relevant cultural information,\n  1026→    enhancing accuracy and contextual relevance.\n  1027→\n  1028→3.  **Local, Open-Source Deployment (Ollama):** Ensuring data privacy,\n  1029→    institutional control, and potential cost-effectiveness by\n  1030→    leveraging open-source models and tools on local infrastructure.\n  1031→\n  1032→While research exists on fine-tuning for pedagogy [^29], RAG for\n  1033→knowledge grounding [^66], and local LLM deployment [^71], the *combined*\n  1034→application of these three elements to create an adaptive,\n  1035→curriculum-aware, culturally relevant, *and* privacy-preserving second\n  1036→language tutor appears to be a relatively underexplored configuration\n  1037→based on the reviewed literature.\n  1038→\n  1039→Furthermore, the project\\'s commitment to using open-access LLMs (from\n  1040→HuggingFace) and open-source tools for fine-tuning (Unsloth/MLX-LM) and\n  1041→deployment (Ollama) promotes transparency, reproducibility, and\n  1042→accessibility for other researchers and institutions facing similar\n  1043→challenges (Proposal Sections 2, 8). The initial focus on developing a\n  1044→proof of concept (Proposal Section 7) represents a pragmatic approach to\n  1045→validating the feasibility and potential of this specific technological\n  1046→combination before committing to larger-scale implementation and\n  1047→evaluation.\n  1048→\n  1049→Table 2 provides a summary of how each core technique contributes to the\n  1050→project\\'s objectives, linking them to the benefits sought and\n  1051→challenges identified in the literature.\n  1052→\n  1053→**Table 2: Overview of LLM Techniques in the Proposed Project**\n  1054→\n  1055→  ----------------------------------------------------------------------------------------------------------\n  1056→  **Technique**     **Purpose in Project  **Key Benefits        **Potential                   **Relevant\n  1057→                    (from Proposal)**     Addressed**           Challenges/Considerations**   Literature\n  1058→                                                                                              Snippets\n  1059→                                                                                              (Examples)**\n  1060→  ----------------- --------------------- --------------------- ----------------------------- --------------\n  1061→  **Fine-Tuning**   Adapt LLM for         Pedagogical           Accuracy Trade-off, Data      [^29]\n  1062→                    pedagogical goals;    Alignment, Structured Needs, Cost, Evaluation       \n  1063→                    anchor in pedagogical Tutoring Interaction                                \n  1064→                    datasets (Sec 2, 6)                                                       \n  1065→\n  1066→  **RAG             Inject                Curriculum Alignment, Retrieval Quality, Knowledge  [^44]\n  1067→  Integration**     course-specific       Cultural Relevance,   Base Creation/Maintenance     \n  1068→                    materials (vocab,     Factual Accuracy                                    \n  1069→                    grammar, culture);                                                        \n  1070→                    enhance relevance                                                         \n  1071→                    (Sec 2, 6)                                                                \n  1072→\n  1073→  **Local           Ensure privacy;       Data Privacy,         Hardware Requirements,        [^71]\n  1074→  Deployment        leverage              Control,              Scalability Limits,           \n  1075→  (Ollama)**        institutional         Cost-Effectiveness,   Maintenance                   \n  1076→                    resources; balance    Offline Use                                         \n  1077→                    latency/scalability                                                       \n  1078→                    (Sec 2, 3, 5, 6, 8)                                                       \n  1079→  ----------------------------------------------------------------------------------------------------------\n  1080→\n  1081→## 8. Conclusion\n  1082→\n  1083→### 8.1. Summary of Key Findings and Gaps\n  1084→\n  1085→The integration of Large Language Models into second language education\n  1086→holds considerable promise, offering potential pathways to more\n  1087→personalized, accessible, and engaging learning experiences.[^5] Benefits\n  1088→such as adaptive learning paths, immediate feedback, 24/7 availability,\n  1089→and reduced learner anxiety are frequently highlighted in the\n  1090→literature.[^20] However, realizing this potential is hindered by\n  1091→significant challenges inherent in current LLM technology and its\n  1092→application in educational contexts.\n  1093→\n  1094→Key limitations include a prevalent lack of deep pedagogical grounding,\n  1095→with models often prioritizing fluent conversation over structured\n  1096→teaching [^19]; issues with factual accuracy and the generation of\n  1097→\\\"hallucinations\\\" [^17]; the provision of generic or ineffective\n  1098→feedback [^24]; difficulties in dynamically integrating specific\n  1099→curriculum content and nuanced cultural information [^25]; and critical\n  1100→concerns regarding student data privacy and security, particularly with\n  1101→cloud-based deployments.^27^\n  1102→\n  1103→Consequently, major research gaps persist. These include the need for:\n  1104→(1) robust methods for achieving deep pedagogical alignment and\n  1105→adaptivity in LLM tutors; (2) effective techniques for dynamic\n  1106→curriculum and cultural integration; (3) strategies to balance the\n  1107→competing demands of pedagogical effectiveness, factual accuracy,\n  1108→knowledge integrity, and computational efficiency; (4) standardized and\n  1109→reliable frameworks for evaluating the educational impact of AI tutors;\n  1110→and (5) architectures that enable meaningful personalization while\n  1111→rigorously preserving student privacy.\n  1112→\n  1113→### 8.2. Significance of the Proposed Project\n  1114→\n  1115→The proposed project, \\\"Adaptive Second Language Tutoring with\n  1116→Fine-Tuned and RAG-Enhanced local LLMs,\\\" is significant because it\n  1117→directly confronts several of these critical gaps through a novel and\n  1118→synergistic combination of techniques. By integrating pedagogical\n  1119→fine-tuning (to shape *how* the tutor interacts) with RAG (to inform\n  1120→*what* the tutor discusses, grounding it in specific curriculum and\n  1121→cultural context) and deploying this system locally via Ollama (to\n  1122→ensure data privacy and institutional control), the project aims to\n  1123→create a more holistic and effective AI tutoring solution.\n  1124→\n  1125→This specific configuration---fine-tuning for pedagogy, RAG for\n  1126→context/accuracy, and local deployment for privacy---addresses the\n  1127→limitations of using these techniques in isolation and represents a\n  1128→promising direction for developing practical, responsible, and\n  1129→educationally relevant AI tools. The focus on open-source models and\n  1130→frameworks further enhances its potential value to the wider academic\n  1131→community. While presented as an initial proof-of-concept, the\n  1132→successful demonstration of this integrated approach could make a\n  1133→valuable contribution to the field of AI-enhanced language education,\n  1134→paving the way for more sophisticated, adaptive, and trustworthy AI\n  1135→tutors that can genuinely support second language learners within\n  1136→institutional settings.\n  1137→\n  1138→#### Works cited\n  1139→\n  1140→1.  \\[2501.10326\\] Large language models for automated scholarly paper\n  1141→    review: A survey - arXiv, accessed April 18, 2025,\n  1142→    [[https://arxiv.org/abs/2501.10326]{.underline}](https://arxiv.org/abs/2501.10326)\n  1143→\n  1144→2.  \\[2403.18105\\] Large Language Models for Education: A Survey and\n  1145→    Outlook - arXiv, accessed April 18, 2025,\n  1146→    [[https://arxiv.org/abs/2403.18105]{.underline}](https://arxiv.org/abs/2403.18105)\n  1147→\n  1148→3.  A Comprehensive Overview of Large Language Models - arXiv, accessed\n  1149→    April 18, 2025,\n  1150→    [[http://arxiv.org/pdf/2307.06435]{.underline}](http://arxiv.org/pdf/2307.06435)\n  1151→\n  1152→4.  What Are Large Language Models and Multimodal Models? - AI and\n  1153→    Higher Education, accessed April 18, 2025,\n  1154→    [[https://ctrl.carlow.edu/ai/whatare]{.underline}](https://ctrl.carlow.edu/ai/whatare)\n  1155→\n  1156→5.  Large Language Models for Education: A Survey and Outlook - arXiv,\n  1157→    accessed April 18, 2025,\n  1158→    [[https://arxiv.org/pdf/2403.18105]{.underline}](https://arxiv.org/pdf/2403.18105)\n  1159→\n  1160→6.  Large Language Models in Education: Empower Success - Maxiom\n  1161→    Technology, accessed April 18, 2025,\n  1162→    [[https://www.maxiomtech.com/large-language-models-in-education/]{.underline}](https://www.maxiomtech.com/large-language-models-in-education/)\n  1163→\n  1164→7.  The impact of large language models on higher education: exploring\n  1165→    the connection between AI and Education 4.0 - Frontiers, accessed\n  1166→    April 18, 2025,\n  1167→    [[https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1392091/full]{.underline}](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1392091/full)\n  1168→\n  1169→8.  \\[2311.13160\\] Large Language Models in Education: Vision and\n  1170→    Opportunities - arXiv, accessed April 18, 2025,\n  1171→    [[https://arxiv.org/abs/2311.13160]{.underline}](https://arxiv.org/abs/2311.13160)\n  1172→\n  1173→9.  Students are using large language models and AI detectors can often\n  1174→    detect their use, accessed April 18, 2025,\n  1175→    [[https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1374889/full]{.underline}](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1374889/full)\n  1176→\n  1177→10. The promise and challenges of generative AI in education - Taylor &\n  1178→    Francis Online, accessed April 18, 2025,\n  1179→    [[https://www.tandfonline.com/doi/full/10.1080/0144929X.2024.2394886]{.underline}](https://www.tandfonline.com/doi/full/10.1080/0144929X.2024.2394886)\n  1180→\n  1181→11. The Impact of Large Language Models on Education: Simplifying AI for\n  1182→    Better Learning, accessed April 18, 2025,\n  1183→    [[https://integranxt.com/blog/the-impact-of-large-language-models-on-education-simplifying-ai-for-better-learning/]{.underline}](https://integranxt.com/blog/the-impact-of-large-language-models-on-education-simplifying-ai-for-better-learning/)\n  1184→\n  1185→12. How AI and Language Model Technology Can Accelerate Educational\n  1186→    Excellence, accessed April 18, 2025,\n  1187→    [[https://evolllution.com/technology/tech-tools-and-resources/how-ai-and-language-model-technology-can-accelerate-educational-excellence]{.underline}](https://evolllution.com/technology/tech-tools-and-resources/how-ai-and-language-model-technology-can-accelerate-educational-excellence)\n  1188→\n  1189→13. Pedagogical Alignment of Large Language Models (LLM) for\n  1190→    Personalized Learning - Scientific Research Publishing, accessed\n  1191→    April 18, 2025,\n  1192→    [[https://www.scirp.org/pdf/jilsa2024164_79601651.pdf]{.underline}](https://www.scirp.org/pdf/jilsa2024164_79601651.pdf)\n  1193→\n  1194→14. Pedagogical Alignment of Large Language Models (LLM) for\n  1195→    Personalized Learning: A Survey, Trends and Challenges - Scientific\n  1196→    Research Publishing, accessed April 18, 2025,\n  1197→    [[https://www.scirp.org/journal/paperinformation?paperid=137833]{.underline}](https://www.scirp.org/journal/paperinformation?paperid=137833)\n  1198→\n  1199→15. (PDF) \\\"Would You Want an AI Tutor?\\\" Understanding Stakeholder\n  1200→    Perceptions of LLM-based Chatbots in the Classroom - ResearchGate,\n  1201→    accessed April 18, 2025,\n  1202→    [[https://www.researchgate.net/publication/389617012_Would_You_Want_an_AI_Tutor_Understanding_Stakeholder_Perceptions_of_LLM-based_Chatbots_in_the_Classroom]{.underline}](https://www.researchgate.net/publication/389617012_Would_You_Want_an_AI_Tutor_Understanding_Stakeholder_Perceptions_of_LLM-based_Chatbots_in_the_Classroom)\n  1203→\n  1204→16. AI in Education - Education Next, accessed April 18, 2025,\n  1205→    [[https://www.educationnext.org/a-i-in-education-leap-into-new-era-machine-intelligence-carries-risks-challenges-promises/]{.underline}](https://www.educationnext.org/a-i-in-education-leap-into-new-era-machine-intelligence-carries-risks-challenges-promises/)\n  1206→\n  1207→17. Benefits And Limitations Of LLM - AiThority, accessed April 18,\n  1208→    2025,\n  1209→    [[https://aithority.com/machine-learning/benefits-and-limitations-of-llm/]{.underline}](https://aithority.com/machine-learning/benefits-and-limitations-of-llm/)\n  1210→\n  1211→18. What Is A Large Language Model? \\[use cases, benefits,\n  1212→    limitations\\] - Spot Intelligence, accessed April 18, 2025,\n  1213→    [[https://spotintelligence.com/2023/08/02/what-is-a-large-language-model-use-cases-benefits-limitations-what-does-the-future-hold/]{.underline}](https://spotintelligence.com/2023/08/02/what-is-a-large-language-model-use-cases-benefits-limitations-what-does-the-future-hold/)\n  1214→\n  1215→19. Position: LLMs Can be Good Tutors in Foreign Language Education -\n  1216→    arXiv, accessed April 18, 2025,\n  1217→    [[https://arxiv.org/html/2502.05467v1]{.underline}](https://arxiv.org/html/2502.05467v1) \n  1218→\n  1219→20. Full article: Integrating AI Technology Into Language Teacher\n  1220→    Education: Challenges, Potentials, and Assumptions - Taylor &\n  1221→    Francis Online, accessed April 18, 2025,\n  1222→    [[https://www.tandfonline.com/doi/full/10.1080/07380569.2025.2458950]{.underline}](https://www.tandfonline.com/doi/full/10.1080/07380569.2025.2458950)\n  1223→\n  1224→21. EJ1383526 - Large Language Model-Based Artificial Intelligence in\n  1225→    the Language Classroom: Practical Ideas for Teaching, Teaching\n  1226→    English with Technology, 2023 - ERIC, accessed April 18, 2025,\n  1227→    [[https://eric.ed.gov/?id=EJ1383526]{.underline}](https://eric.ed.gov/?id=EJ1383526)\n  1228→\n  1229→22. Position: LLMs Can be Good Tutors in Foreign Language Education -\n  1230→    ResearchGate, accessed April 18, 2025,\n  1231→    [[https://www.researchgate.net/publication/388883004_Position_LLMs_Can_be_Good_Tutors_in_Foreign_Language_Education]{.underline}](https://www.researchgate.net/publication/388883004_Position_LLMs_Can_be_Good_Tutors_in_Foreign_Language_Education)\n  1232→\n  1233→23. Unlock Your Language Potential: How to Use AI for Second Language\n  1234→    Learning - Italki, accessed April 18, 2025,\n  1235→    [[https://www.italki.com/en/article/XYOyOOSC9mfWXP01UxZMMd/unlock-your-language-potential-how-to-use-ai-for-second-language-learning]{.underline}](https://www.italki.com/en/article/XYOyOOSC9mfWXP01UxZMMd/unlock-your-language-potential-how-to-use-ai-for-second-language-learning)\n  1236→\n  1237→24. aclanthology.org, accessed April 18, 2025,\n  1238→    [[https://aclanthology.org/2024.customnlp4u-1.21.pdf]{.underline}](https://aclanthology.org/2024.customnlp4u-1.21.pdf)\n  1239→\n  1240→25. Traditional vs. AI-Language Learning: Which Is Better? - Saima AI,\n  1241→    accessed April 18, 2025,\n  1242→    [[https://saima.ai/blog/traditional-vs-ai-language-learning]{.underline}](https://saima.ai/blog/traditional-vs-ai-language-learning)\n  1243→\n  1244→26. AI Tutoring vs. Traditional Tutoring: Key Differences - Dialzara,\n  1245→    accessed April 18, 2025,\n  1246→    [[https://dialzara.com/blog/ai-tutoring-vs-traditional-tutoring-key-differences/]{.underline}](https://dialzara.com/blog/ai-tutoring-vs-traditional-tutoring-key-differences/)\n  1247→\n  1248→27. AI Tutors: Bridging the Gap Between Teachers and Students \\|\n  1249→    OpenGrowth, accessed April 18, 2025,\n  1250→    [[https://www.blogs.opengrowth.com/ai-tutors-bridging-the-gap-between-teachers-and-students]{.underline}](https://www.blogs.opengrowth.com/ai-tutors-bridging-the-gap-between-teachers-and-students)\n  1251→\n  1252→28. Can Large Language Models Match Tutoring System Adaptivity? A\n  1253→    Benchmarking Study, accessed April 18, 2025,\n  1254→    [[https://arxiv.org/html/2504.05570v1]{.underline}](https://arxiv.org/html/2504.05570v1)\n  1255→\n  1256→29. \\[2402.05000\\] Pedagogical Alignment of Large Language Models -\n  1257→    arXiv, accessed April 18, 2025,\n  1258→    [[https://arxiv.org/abs/2402.05000]{.underline}](https://arxiv.org/abs/2402.05000)\n  1259→\n  1260→30. \\[2310.19736\\] Evaluating Large Language Models: A Comprehensive\n  1261→    Survey - arXiv, accessed April 18, 2025,\n  1262→    [[https://arxiv.org/abs/2310.19736]{.underline}](https://arxiv.org/abs/2310.19736)\n  1263→\n  1264→31. Full article: Artificial intelligence pedagogical chatbots as L2\n  1265→    conversational agents, accessed April 18, 2025,\n  1266→    [[https://www.tandfonline.com/doi/full/10.1080/2331186X.2024.2327789]{.underline}](https://www.tandfonline.com/doi/full/10.1080/2331186X.2024.2327789)\n  1267→\n  1268→32. The impact of chatbots based on large language models on second\n  1269→    language vocabulary acquisition - PMC, accessed April 18, 2025,\n  1270→    [[https://pmc.ncbi.nlm.nih.gov/articles/PMC10850600/]{.underline}](https://pmc.ncbi.nlm.nih.gov/articles/PMC10850600/)\n  1271→\n  1272→33. (PDF) AI-driven Technology and Chatbots as Tools for Enhancing\n  1273→    English Language Learning in the Context of Second Language\n  1274→    Acquisition: A Review Study - ResearchGate, accessed April 18, 2025,\n  1275→    [[https://www.researchgate.net/publication/375011638_AI-driven_Technology_and_Chatbots_as_Tools_for_Enhancing_English_Language_Learning_in_the_Context_of_Second_Language_Acquisition_A_Review_Study]{.underline}](https://www.researchgate.net/publication/375011638_AI-driven_Technology_and_Chatbots_as_Tools_for_Enhancing_English_Language_Learning_in_the_Context_of_Second_Language_Acquisition_A_Review_Study)\n  1276→\n  1277→34. LLM-as-a-tutor in EFL Writing Education: Focusing on Evaluation of\n  1278→    Student-LLM Interaction, accessed April 18, 2025,\n  1279→    [[https://aclanthology.org/2024.customnlp4u-1.21/]{.underline}](https://aclanthology.org/2024.customnlp4u-1.21/)\n  1280→\n  1281→35. Balancing the Benefits and Risks of AI Large Language Models in K12\n  1282→    Public Schools - VCU Scholars Compass, accessed April 18, 2025,\n  1283→    [[https://scholarscompass.vcu.edu/cgi/viewcontent.cgi?article=1133&context=merc_pubs]{.underline}](https://scholarscompass.vcu.edu/cgi/viewcontent.cgi?article=1133&context=merc_pubs)\n  1284→\n  1285→36. (PDF) Transforming Education with Large Language Models:\n  1286→    Opportunities, Challenges, and Ethical Considerations -\n  1287→    ResearchGate, accessed April 18, 2025,\n  1288→    [[https://www.researchgate.net/publication/382825702_Transforming_Education_with_Large_Language_Models_Opportunities_Challenges_and_Ethical_Considerations]{.underline}](https://www.researchgate.net/publication/382825702_Transforming_Education_with_Large_Language_Models_Opportunities_Challenges_and_Ethical_Considerations)\n  1289→\n  1290→37. Language Learning through AI Chatbots: Effectiveness and Cognitive\n  1291→    Load Analysis, accessed April 18, 2025,\n  1292→    [[https://www.journal.ypidathu.or.id/index.php/jssut/article/view/1346]{.underline}](https://www.journal.ypidathu.or.id/index.php/jssut/article/view/1346)\n  1293→\n  1294→38. The use of chatbots in university EFL settings: Research trends and\n  1295→    pedagogical implications - Frontiers, accessed April 18, 2025,\n  1296→    [[https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1131506/full]{.underline}](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1131506/full)\n  1297→\n  1298→39. The promises and challenges of AI-based chatbots in language\n  1299→    education through the lens of learner emotions - PubMed Central,\n  1300→    accessed April 18, 2025,\n  1301→    [[https://pmc.ncbi.nlm.nih.gov/articles/PMC11416278/]{.underline}](https://pmc.ncbi.nlm.nih.gov/articles/PMC11416278/)\n  1302→\n  1303→40. (PDF) Chatbots for language learning-Are they really useful? A\n  1304→    systematic review of chatbot-supported language learning -\n  1305→    ResearchGate, accessed April 18, 2025,\n  1306→    [[https://www.researchgate.net/publication/354813647_Chatbots_for_language_learning-Are_they_really_useful_A_systematic_review_of_chatbot-supported_language_learning]{.underline}](https://www.researchgate.net/publication/354813647_Chatbots_for_language_learning-Are_they_really_useful_A_systematic_review_of_chatbot-supported_language_learning)\n  1307→\n  1308→41. AI Tutors: Bridging Skill Gaps for Personalized Learning - Jotverse,\n  1309→    accessed April 18, 2025,\n  1310→    [[https://www.jotverse.com/ai-tutors-bridging-skill-gaps-for-personalized-learning/]{.underline}](https://www.jotverse.com/ai-tutors-bridging-skill-gaps-for-personalized-learning/)\n  1311→\n  1312→42. Advancing Education through Tutoring Systems - arXiv, accessed April\n  1313→    18, 2025,\n  1314→    [[https://arxiv.org/pdf/2503.09748]{.underline}](https://arxiv.org/pdf/2503.09748)\n  1315→\n  1316→43. How AI-Language Practice Stacks Up Against Online Tutor Services: An\n  1317→    In-Depth Comparison \\| Talkio AI, accessed April 18, 2025,\n  1318→    [[https://www.talkio.ai/blog/posts/how-ai-stacks-up-against-online-tutor-services]{.underline}](https://www.talkio.ai/blog/posts/how-ai-stacks-up-against-online-tutor-services)\n  1319→\n  1320→44. Using your own content in LLM\\'s - Retrieval Augmented Generation\n  1321→    (RAG) - AI-for-Education.org, accessed April 18, 2025,\n  1322→    [[https://ai-for-education.org/wp-content/uploads/2024/03/AI-for-Education-RAG.pdf]{.underline}](https://ai-for-education.org/wp-content/uploads/2024/03/AI-for-Education-RAG.pdf)\n  1323→\n  1324→45. ChatGPT Promises and Challenges in Education: Computational and\n  1325→    Ethical Perspectives, accessed April 18, 2025,\n  1326→    [[https://www.mdpi.com/2227-7102/14/8/814]{.underline}](https://www.mdpi.com/2227-7102/14/8/814)\n  1327→\n  1328→46. Language Models in the Classroom: Bridging the Gap Between\n  1329→    Technology and Teaching, accessed April 18, 2025,\n  1330→    [[https://hai.stanford.edu/news/language-models-in-the-classroom-bridging-the-gap-between-technology-and-teaching]{.underline}](https://hai.stanford.edu/news/language-models-in-the-classroom-bridging-the-gap-between-technology-and-teaching)\n  1331→\n  1332→47. (PDF) Towards the Pedagogical Steering of Large Language Models for\n  1333→    Tutoring: A Case Study with Modeling Productive Failure -\n  1334→    ResearchGate, accessed April 18, 2025,\n  1335→    [[https://www.researchgate.net/publication/384699353_Towards_the_Pedagogical_Steering_of_Large_Language_Models_for_Tutoring_A_Case_Study_with_Modeling_Productive_Failure]{.underline}](https://www.researchgate.net/publication/384699353_Towards_the_Pedagogical_Steering_of_Large_Language_Models_for_Tutoring_A_Case_Study_with_Modeling_Productive_Failure)\n  1336→\n  1337→48. Supervised Fine-Tuning LLMs to Behave as Pedagogical Agents in\n  1338→    Programming Education, accessed April 18, 2025,\n  1339→    [[https://arxiv.org/html/2502.20527v1]{.underline}](https://arxiv.org/html/2502.20527v1)\n  1340→\n  1341→49. EULER: Fine Tuning a Large Language Model for Socratic\n  1342→    Interactions - CEUR-WS.org, accessed April 18, 2025,\n  1343→    [[https://ceur-ws.org/Vol-3879/AIxEDU2024_paper_26.pdf]{.underline}](https://ceur-ws.org/Vol-3879/AIxEDU2024_paper_26.pdf)\n  1344→\n  1345→50. Unveiling the power and limitations of large language models -\n  1346→    6Clicks, accessed April 18, 2025,\n  1347→    [[https://www.6clicks.com/resources/blog/unveiling-the-power-of-large-language-models]{.underline}](https://www.6clicks.com/resources/blog/unveiling-the-power-of-large-language-models)\n  1348→\n  1349→51. Large Language Models (LLMs): Challenges, Predictions, Tutorial - V7\n  1350→    Labs, accessed April 18, 2025,\n  1351→    [[https://www.v7labs.com/blog/large-language-models-llms]{.underline}](https://www.v7labs.com/blog/large-language-models-llms)\n  1352→\n  1353→52. The future of language learning: Human vs AI tutors - Lingoda,\n  1354→    accessed April 18, 2025,\n  1355→    [[https://www.lingoda.com/en/p/research/future-language-learning-human-ai/]{.underline}](https://www.lingoda.com/en/p/research/future-language-learning-human-ai/)\n  1356→\n  1357→53. AI Tutoring Comparison of Language Tutors \\| Restackio, accessed\n  1358→    April 18, 2025,\n  1359→    [[https://www.restack.io/p/ai-tutoring-answer-comparison-language-tutors-cat-ai]{.underline}](https://www.restack.io/p/ai-tutoring-answer-comparison-language-tutors-cat-ai)\n  1360→\n  1361→54. Are there advantages to training LLM in Chinese? : r/singularity -\n  1362→    Reddit, accessed April 18, 2025,\n  1363→    [[https://www.reddit.com/r/singularity/comments/1idfx8u/are_there_advantages_to_training_llm_in_chinese/]{.underline}](https://www.reddit.com/r/singularity/comments/1idfx8u/are_there_advantages_to_training_llm_in_chinese/)\n  1364→\n  1365→55. AI versus human learning: The importance of human interaction -\n  1366→    Preply, accessed April 18, 2025,\n  1367→    [[https://preply.com/en/blog/ia-vs-human-learning/]{.underline}](https://preply.com/en/blog/ia-vs-human-learning/)\n  1368→\n  1369→56. Comments - Five Differences Between Human and AI Tutors, accessed\n  1370→    April 18, 2025,\n  1371→    [[https://danmeyer.substack.com/p/five-differences-between-human-and/comments]{.underline}](https://danmeyer.substack.com/p/five-differences-between-human-and/comments)\n  1372→\n  1373→57. Fine-tuning large language models (LLMs) in 2025 - SuperAnnotate,\n  1374→    accessed April 18, 2025,\n  1375→    [[https://www.superannotate.com/blog/llm-fine-tuning]{.underline}](https://www.superannotate.com/blog/llm-fine-tuning)\n  1376→\n  1377→58. Learning Dynamics of LLM Finetuning - OpenReview, accessed April 18,\n  1378→    2025,\n  1379→    [[https://openreview.net/forum?id=tPNHOoZFl9]{.underline}](https://openreview.net/forum?id=tPNHOoZFl9)\n  1380→\n  1381→59. Student Data Paradox and Curious Case of Single Student-Tutor \\...,\n  1382→    accessed April 18, 2025,\n  1383→    [[https://aclanthology.org/2024.findings-emnlp.912/]{.underline}](https://aclanthology.org/2024.findings-emnlp.912/)\n  1384→\n  1385→60. Fine-tuning LLM on research papers : r/LanguageTechnology - Reddit,\n  1386→    accessed April 18, 2025,\n  1387→    [[https://www.reddit.com/r/LanguageTechnology/comments/179aid1/finetuning_llm_on_research_papers/]{.underline}](https://www.reddit.com/r/LanguageTechnology/comments/179aid1/finetuning_llm_on_research_papers/)\n  1388→\n  1389→61. An Evaluation Taxonomy for Pedagogical Ability Assessment of\n  1390→    LLM-Powered AI Tutors, accessed April 18, 2025,\n  1391→    [[https://arxiv.org/html/2412.09416v2]{.underline}](https://arxiv.org/html/2412.09416v2)\n  1392→\n  1393→62. RAG, or Retrieval Augmented Generation: Revolutionizing AI in 2025 -\n  1394→    Glean, accessed April 18, 2025,\n  1395→    [[https://www.glean.com/blog/rag-retrieval-augmented-generation]{.underline}](https://www.glean.com/blog/rag-retrieval-augmented-generation)\n  1396→\n  1397→63. Retrieval Augmented Generation (RAG): What It Is and How It Prevents\n  1398→    AI Errors, accessed April 18, 2025,\n  1399→    [[https://www.intersystems.com/resources/retrieval-augmented-generation/]{.underline}](https://www.intersystems.com/resources/retrieval-augmented-generation/)\n  1400→\n  1401→64. What is RAG? - Retrieval-Augmented Generation AI Explained - AWS,\n  1402→    accessed April 18, 2025,\n  1403→    [[https://aws.amazon.com/what-is/retrieval-augmented-generation/]{.underline}](https://aws.amazon.com/what-is/retrieval-augmented-generation/)\n  1404→\n  1405→65. What is Retrieval-Augmented Generation (RAG)? A Practical Guide -\n  1406→    K2view, accessed April 18, 2025,\n  1407→    [[https://www.k2view.com/what-is-retrieval-augmented-generation]{.underline}](https://www.k2view.com/what-is-retrieval-augmented-generation)\n  1408→\n  1409→66. Retrieval-Augmented Generation (RAG) Chatbots for Education: A\n  1410→    Survey of Applications, accessed April 18, 2025,\n  1411→    [[https://www.mdpi.com/2076-3417/15/8/4234]{.underline}](https://www.mdpi.com/2076-3417/15/8/4234)\n  1412→\n  1413→67. Retrieval Augmented Generation: Everything You Need to Know About\n  1414→    RAG in AI - WEKA, accessed April 18, 2025,\n  1415→    [[https://www.weka.io/learn/guide/ai-ml/retrieval-augmented-generation/]{.underline}](https://www.weka.io/learn/guide/ai-ml/retrieval-augmented-generation/)\n  1416→\n  1417→68. Retrieval Augmented Generation (RAG) for LLMs - Prompt Engineering\n  1418→    Guide, accessed April 18, 2025,\n  1419→    [[https://www.promptingguide.ai/research/rag]{.underline}](https://www.promptingguide.ai/research/rag)\n  1420→\n  1421→69. The Impact of Generative AI and RAG on Personalized Learning -\n  1422→    MAKEBOT.AI, accessed April 18, 2025,\n  1423→    [[https://www.makebot.ai/blog-en/the-impact-of-generative-ai-and-rag-on-personalized-learning]{.underline}](https://www.makebot.ai/blog-en/the-impact-of-generative-ai-and-rag-on-personalized-learning)\n  1424→\n  1425→70. \\[2311.17696\\] How to Build an Adaptive AI Tutor for Any Course\n  1426→    Using Knowledge Graph-Enhanced Retrieval-Augmented Generation\n  1427→    (KG-RAG) - arXiv, accessed April 18, 2025,\n  1428→    [[https://arxiv.org/abs/2311.17696]{.underline}](https://arxiv.org/abs/2311.17696)\n  1429→\n  1430→71. Your private LLM: deploying LLMs locally and offline using Ollama,\n  1431→    accessed April 18, 2025,\n  1432→    [[https://agathon.ai/insights/your-private-llm:-deploying-llms-locally-and-offline-using-ollama]{.underline}](https://agathon.ai/insights/your-private-llm:-deploying-llms-locally-and-offline-using-ollama)\n  1433→\n  1434→72. Ollama vs Hugging Face: Choosing the Right AI/ML Platform -\n  1435→    PromptLayer, accessed April 18, 2025,\n  1436→    [[https://blog.promptlayer.com/ollama-vs-huggingface/]{.underline}](https://blog.promptlayer.com/ollama-vs-huggingface/)\n  1437→\n  1438→73. The 6 Best LLM Tools To Run Models Locally - GetStream.io, accessed\n  1439→    April 18, 2025,\n  1440→    [[https://getstream.io/blog/best-local-llm-tools/]{.underline}](https://getstream.io/blog/best-local-llm-tools/)\n  1441→\n  1442→74. Ollama Tutorial: Run LLMs Locally - BytePlus, accessed April 18,\n  1443→    2025,\n  1444→    [[https://www.byteplus.com/en/topic/497086]{.underline}](https://www.byteplus.com/en/topic/497086)\n  1445→\n  1446→75. Deploy LLMs Locally Using Ollama: The Ultimate Guide to Local AI\n  1447→    Development - Apidog, accessed April 18, 2025,\n  1448→    [[https://apidog.com/blog/deploy-local-ai-llms/]{.underline}](https://apidog.com/blog/deploy-local-ai-llms/)\n  1449→\n  1450→76. Easy Setup for Local LLM with Llama Index and Ollama - QuickCreator,\n  1451→    accessed April 18, 2025,\n  1452→    [[https://quickcreator.io/quthor_blog/beginners-guide-setting-up-local-llm-ollama-llama-2/]{.underline}](https://quickcreator.io/quthor_blog/beginners-guide-setting-up-local-llm-ollama-llama-2/)\n  1453→\n  1454→77. Setting Up Ollama & Running DeepSeek R1 Locally for a Powerful RAG\n  1455→    System, accessed April 18, 2025,\n  1456→    [[https://dev.to/ajmal_hasan/setting-up-ollama-running-deepseek-r1-locally-for-a-powerful-rag-system-4pd4]{.underline}](https://dev.to/ajmal_hasan/setting-up-ollama-running-deepseek-r1-locally-for-a-powerful-rag-system-4pd4)\n  1457→\n  1458→78. Top 10 LLM tools to run models locally: A comprehensive guide for\n  1459→    2025 - BytePlus, accessed April 18, 2025,\n  1460→    [[https://www.byteplus.com/en/topic/398242]{.underline}](https://www.byteplus.com/en/topic/398242)\n  1461→\n  1462→79. What are the minimum hardware requirements to run an ollama model? -\n  1463→    Reddit, accessed April 18, 2025,\n  1464→    [[https://www.reddit.com/r/ollama/comments/1gwbl0k/what_are_the_minimum_hardware_requirements_to_run/]{.underline}](https://www.reddit.com/r/ollama/comments/1gwbl0k/what_are_the_minimum_hardware_requirements_to_run/)\n  1465→\n  1466→80. A Guide to Running LLMs Locally with No-Code Framework Dify,\n  1467→    accessed April 18, 2025,\n  1468→    [[https://adasci.org/a-guide-to-running-llms-locally-with-no-code-framework-dify/]{.underline}](https://adasci.org/a-guide-to-running-llms-locally-with-no-code-framework-dify/)\n  1469→\n  1470→81. Large language models for whole-learner support: opportunities and\n  1471→    challenges - Frontiers, accessed April 18, 2025,\n  1472→    [[https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1460364/full]{.underline}](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1460364/full)\n  1473→\n  1474→82. Superagency in the workplace: Empowering people to unlock AI\\'s full\n  1475→    potential - McKinsey, accessed April 18, 2025,\n  1476→    [[https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work]{.underline}](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)\n  1477→\n  1478→83. LLMs for Low Resource Languages in Multilingual, Multimodal and\n  1479→    Dialectal Settings, accessed April 18, 2025,\n  1480→    [[https://aclanthology.org/2024.eacl-tutorials.5/]{.underline}](https://aclanthology.org/2024.eacl-tutorials.5/)\n  1481→"}]},"uuid":"769ef15f-8fe6-4639-be3e-178ae94e035d","timestamp":"2025-06-18T13:42:10.232Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/francojc/Documents/GitHub/francojc/its/docs/literature/literature_review.qmd","content":"---\ntitle: Literature Review \n---\n\n> Adaptive Second Language Tutoring with Fine-Tuned and RAG-Enhanced Local LLMs\n\n## 1. Introduction\n\n### 1.1. Context: The Rise of LLMs in Education and Second Language Acquisition (SLA)\n\nThe rapid development and proliferation of Large Language Models (LLMs)\nrepresent a significant technological advancement, impacting numerous\ndomains including academia and education.[^1] These sophisticated\nartificial intelligence (AI) systems, often built upon deep learning\narchitectures like transformers, demonstrate remarkable capabilities in\nprocessing, understanding, and generating human-like text based on\npatterns learned from massive datasets.[^3] This proficiency enables a\nwide array of applications, from text summarization and translation to\ncomplex question answering and content creation.[^4]\n\nWithin the educational sector, LLMs present novel opportunities for\nenhancing learning experiences and administrative efficiency.[^5] Their\npotential to simulate human interaction and provide tailored content has\nsparked particular interest in the field of Second Language Acquisition\n(SLA) and Foreign Language Education (FLE).[^19] The perennial challenges\nof providing personalized, scalable, and interactive language practice,\noften constrained by the limitations of traditional classroom settings\nor the high cost of human tutoring, appear addressable through AI-driven\nsolutions.[^24] LLMs offer the possibility of creating dynamic learning\nenvironments that can adapt to individual learner needs and provide\nimmediate feedback.[^21]\n\nHowever, the integration of LLMs into language education is not without\nits complexities. While their potential is widely acknowledged, current\napplications often rely on general-purpose models that may lack the\nspecific pedagogical grounding and adaptability required for effective\nlanguage learning.[^19] Many existing LLM-based tools prioritize\nconversational fluency over structured pedagogical progression,\npotentially failing to guide learners systematically through the\ncomplexities of acquiring a new language.[^19] Furthermore, concerns\nregarding factual accuracy, contextual appropriateness, cultural\nsensitivity, and data privacy persist.[^12] The research proposal\nunderpinning this review, \\\"Adaptive Second Language Tutoring with\nFine-Tuned and RAG-Enhanced local LLMs,\\\" aims precisely at addressing\nthese shortcomings by developing a system tailored for pedagogical\neffectiveness, curriculum alignment, cultural relevance, and privacy.\n\n### 1.2. Purpose and Scope of the Report\n\nThe primary objective of this report is to conduct a comprehensive\nbackground literature review based on the aforementioned research\nproposal and a curated set of research materials. The review focuses\nspecifically on the intersection of LLMs, SLA, and AI-driven tutoring.\nIt examines the current state of research concerning the use of LLMs in\nlanguage learning applications, delving into specific techniques central\nto the proposal: fine-tuning LLMs for pedagogical objectives, employing\nRetrieval-Augmented Generation (RAG) for curriculum and cultural content\nintegration, and leveraging local deployment frameworks like Ollama for\nenhanced privacy and control. Furthermore, the report analyzes existing\nlanguage learning methods in comparison to LLM-based tutors and\nidentifies critical gaps in the current research landscape.\n\nThis analysis synthesizes findings from the provided research snippets\nto evaluate how the proposed project, through its unique combination of\nfine-tuning, RAG, and local deployment, aims to address these identified\ngaps and contribute meaningfully to the field of AI-enhanced language\neducation. The report structure follows a logical progression, starting\nwith an overview of the current landscape, followed by detailed\nexaminations of fine-tuning, RAG, and local deployment strategies. It\nthen synthesizes these findings to pinpoint research gaps and concludes\nby positioning the proposed project within this context, highlighting\nits novelty and potential impact.\n\n## 2. Current Landscape of LLMs in Second Language Acquisition (SLA) and Tutoring\n\n### 2.1. Overview of LLM Roles and Applications in Language Education\n\nThe integration of LLMs into language education is rapidly evolving,\nwith researchers exploring diverse roles and applications for these\npowerful AI tools. LLMs are envisioned to function in several key\ncapacities within educational settings, particularly in FLE. They can\nserve as **data enhancers**, assisting in the creation and refinement of\nlearning materials or simulating student interactions for training\npurposes; as **task predictors**, enabling learner assessment or\noptimizing individual learning pathways; and as **agents**, facilitating\npersonalized and inclusive educational experiences, including\ntutoring.[^19]\n\nSpecific applications leveraging these roles are numerous and growing. A\nprimary use case is **conversation practice**, where LLMs act as\ninteractive partners, allowing learners to engage in dialogue, practice\nspeaking and writing, and build fluency in a low-pressure\nenvironment.[^23] They are also employed for targeted skill development,\nsuch as **grammar and vocabulary acquisition**, providing explanations,\nexamples, exercises, and corrective feedback.[^20] LLMs can function as\nsophisticated **writing assistants**, offering feedback on essays\nregarding content, organization, and language use [^5], and similarly\nsupport **reading comprehension**.[^5]\n\nBeyond direct student interaction, LLMs assist educators by **generating\nlearner-centric materials**, such as customized exercises, lesson plans,\nworksheets, and assessments, potentially alleviating teacher workload\nand allowing for more focus on individual student needs.[^11] Their\nability to simulate human-like interaction [^20] and provide detailed\nexplanations [^5] makes them suitable for creating interactive practice\nenvironments that go beyond static exercises.[^31]\n\n### 2.2. Reported Benefits of LLM-Based Language Tutoring\n\nThe burgeoning research on LLMs in language education highlights several\npotential benefits that drive their adoption and investigation.\n\n-   **Personalization & Adaptivity:** A frequently cited advantage is\n    the potential for LLMs to deliver highly personalized learning\n    experiences.[^2] Unlike traditional one-size-fits-all approaches, AI\n    tutors can theoretically adapt learning paths, content difficulty,\n    and interaction styles based on individual student proficiency\n    levels, learning pace, preferences, and real-time performance.[^11]\n    This adaptability aims to keep learners optimally challenged and\n    engaged, fostering more effective language acquisition. The proposal\n    explicitly targets this potential for personalization (Proposal\n    Sections 2, 4, 6).\n\n-   **Immediate Feedback:** LLMs can provide instant feedback on various\n    aspects of language use, including grammar, vocabulary, spelling,\n    and potentially pronunciation when integrated with speech\n    recognition technology.[^20] This real-time feedback loop allows\n    learners to identify and correct errors quickly, reinforcing correct\n    usage and potentially accelerating the learning process.[^26]\n    Immediate reinforcement can also build learner confidence.[^43]\n\n-   **Accessibility & Scalability:** AI-powered tutors offer\n    unparalleled accessibility, being available 24/7 from potentially\n    any location with an internet connection (or offline, in the case of\n    local deployment).[^15] This overcomes the scheduling and\n    geographical limitations inherent in human tutoring. Furthermore, AI\n    solutions can scale to serve a large number of learners\n    simultaneously, a significant advantage over human tutors whose\n    capacity is inherently limited.[^6] The proposal acknowledges the\n    scalability limits of human tutoring as a motivating factor\n    (Proposal Section 5).\n\n-   **Reduced Anxiety & Increased Motivation:** Many language learners\n    experience anxiety when speaking or writing in a foreign language,\n    particularly in front of peers or instructors. Interacting with an\n    AI tutor can provide a non-judgmental, safe environment for\n    practice, reducing this language anxiety or \\\"affective\n    filter\\\".[^31] This lower-pressure environment may encourage learners\n    to take more risks, practice more frequently, and consequently\n    increase their motivation and engagement.[^31]\n\n-   **Content Generation & Teacher Support:** LLMs can significantly\n    reduce the burden on educators by automating the creation of diverse\n    educational materials, including lesson plans, exercises, quizzes,\n    and assessments.[^11] This allows teachers to dedicate more time to\n    higher-level instructional activities, such as providing\n    personalized guidance and fostering deeper student\n    understanding.[^20]\n\n### 2.3. Limitations and Challenges of Current LLM Approaches\n\nDespite the enthusiasm surrounding LLMs in language education, numerous\nlimitations and challenges temper their immediate applicability and\neffectiveness.\n\n-   **Lack of Pedagogical Soundness:** A critical shortcoming is that\n    standard LLMs, primarily trained on vast amounts of general text\n    data, often lack inherent pedagogical understanding.[^19] They may\n    excel at generating fluent and coherent text but fail to employ\n    effective teaching strategies grounded in learning sciences.[^19] For\n    instance, they might provide direct answers rather than scaffolding\n    student learning through guided questioning or hints [^29],\n    potentially hindering deeper understanding and critical\n    thinking.[^13] The proposal\\'s focus on fine-tuning directly targets\n    this limitation (Proposal Sections 4, 6).\n\n-   **Factual Inaccuracy & Hallucinations:** LLMs are known to\n    \\\"hallucinate,\\\" generating information that sounds plausible but is\n    factually incorrect or nonsensical.^12^ This is particularly\n    problematic in education where accuracy is paramount. Outdated\n    training data can exacerbate this issue, leading to the\n    dissemination of obsolete information.[^13] Retrieval-Augmented\n    Generation (RAG) is proposed as a technique to mitigate this by\n    grounding responses in external, verified knowledge sources\n    (Proposal Section 6).\n\n-   **Limited Contextual/Cultural Understanding:** While LLMs process\n    language statistically, they often lack the deep, nuanced\n    understanding of context, idioms, slang, humor, and cultural\n    subtleties that human communicators possess.[^25] This limitation can\n    hinder their ability to provide culturally appropriate explanations\n    or engage in truly authentic communicative interactions. The\n    proposal aims to enhance cultural relevance via RAG (Proposal\n    Sections 2, 4, 6).\n\n-   **Generic or Ineffective Feedback:** LLM-generated feedback can\n    sometimes be too generic, overly positive, or indirect, failing to\n    provide the specific, constructive guidance learners need to\n    improve.[^24] LLMs may struggle to accurately identify the root cause\n    of a learner\\'s error or tailor feedback effectively to their\n    specific needs.\n\n-   **Technological Limitations:** Current chatbot technologies,\n    including those powered by LLMs, face inherent limitations. They may\n    struggle with non-linear conversations where context needs to be\n    recalled and integrated dynamically [^31], offer limited depth in\n    interaction [^31], be overly sensitive to typos or grammatical errors\n    in user input [^40], or be constrained by context window size,\n    limiting the amount of previous interaction they can consider.[^51]\n\n-   **Bias and Ethical Concerns:** LLMs can inherit and amplify societal\n    biases present in their vast training data, leading to potentially\n    unfair, stereotyped, or discriminatory outputs.[^6] Broader ethical\n    concerns in educational AI include student data privacy and security\n    (especially with cloud-based models), the potential for misuse\n    (e.g., cheating on assignments), ensuring equitable access (the\n    digital divide), and the lack of transparency in AI\n    decision-making.[^9] The proposal\\'s emphasis on local deployment\n    aims to mitigate privacy risks specifically (Proposal Sections 5,\n    6).\n\n-   **Over-reliance & Novelty Effect:** There is a risk that students\n    may become overly reliant on AI tutors, potentially hindering the\n    development of independent problem-solving skills and deeper\n    conceptual understanding.[^15] Additionally, the initial high\n    engagement observed with new AI tools might diminish over time as\n    the novelty wears off.[^40]\n\n### 2.4. Comparative Analysis: LLM Tutors vs. Other Language Learning Methods\n\nEvaluating the potential of LLM-based tutors requires comparing them\nagainst existing language learning approaches, particularly in light of\nfoundational educational research on tutoring effectiveness and scalability.\n\n#### 2.4.1. Bloom's 2 Sigma Problem and the Promise of AI Tutoring\n\nThe theoretical foundation for AI tutoring is deeply rooted in Benjamin Bloom's seminal 1984 research on educational effectiveness, which identified what became known as the \"2 Sigma Problem.\" Bloom's study demonstrated that students receiving one-on-one tutoring performed two standard deviations better (at the 98th percentile) than students in conventional classroom instruction (at the 50th percentile). This remarkable finding suggested that personalized tutoring could move the average student from the median to the top 2% of conventional classroom performance.\n\nHowever, Bloom's research also highlighted a fundamental scalability challenge: while one-on-one tutoring produced exceptional learning gains, it was economically and logistically impractical to provide individual human tutors for all students. This limitation led Bloom to propose \"Mastery Learning\" as a scalable alternative—a pedagogical approach where students must demonstrate competency in foundational concepts before progressing to more advanced material, combined with corrective instruction and enrichment activities tailored to individual needs.\n\nThe emergence of LLM-based tutoring systems represents a potential solution to Bloom's 2 Sigma Problem by offering the personalization benefits of one-on-one tutoring at the scale of traditional classroom instruction. AI tutors can theoretically provide individualized attention, immediate feedback, and adaptive pacing—key characteristics of effective human tutoring—while serving unlimited numbers of students simultaneously. This positions AI tutoring as a bridge between the effectiveness of human tutoring and the scalability requirements of modern education.\n\n#### 2.4.2. Mastery Learning and Its Connection to the Current Project\n\nMastery Learning principles align closely with the objectives of the proposed AI tutoring system for second language acquisition. Core tenets of Mastery Learning include:\n\n- **Criterion-Referenced Assessment:** Students must demonstrate proficiency at predetermined competency levels before advancing, rather than competing against peers or following fixed time schedules.\n- **Corrective Instruction:** When students fail to achieve mastery, they receive additional instruction tailored to their specific learning gaps.\n- **Enrichment Activities:** Students who achieve mastery quickly engage in extension activities that deepen or broaden their understanding.\n- **Individualized Pacing:** Learning progression is determined by individual competency rather than calendar constraints.\n\nThe proposed RAG-enhanced, fine-tuned LLM system embodies these principles through several mechanisms. The fine-tuning component can be designed to implement mastery-based pedagogical strategies, ensuring students demonstrate competency in fundamental language structures before introducing more complex concepts. The RAG system can dynamically retrieve appropriate corrective materials or enrichment content based on individual student performance, effectively personalizing the learning path. Furthermore, the 24/7 availability of the AI tutor supports individualized pacing, allowing students to progress through mastery checkpoints at their own rate.\n\n#### 2.4.3. Comparative Analysis of Learning Approaches\n\n-   **LLM Tutors vs. Static Apps (e.g., Duolingo, Babbel):** Compared to\n    popular language learning apps characterized by fixed progression\n    paths and limited feedback mechanisms, LLMs offer the potential for\n    much more dynamic, interactive, and personalized learning\n    experiences (Proposal Section 5). LLMs can engage in more natural\n    conversations and potentially adapt content more fluidly. However,\n    static apps often provide a clear, structured curriculum that might\n    be beneficial for absolute beginners, whereas the pedagogical\n    structure of basic AI chat interfaces can be lacking (Proposal\n    Section 5). Notably, most static apps lack true mastery learning implementation, advancing students based on time-based metrics rather than demonstrated competency.\n\n-   **LLM Tutors vs. Human Tutors:** This comparison directly addresses Bloom's findings about tutoring effectiveness.\n\n    -   *Human Strengths:* Human tutors possess deep understanding of\n        linguistic nuance, cultural context, and learner emotions. They\n        can adapt their teaching strategies flexibly based on subtle\n        cues, build rapport, provide empathetic support, and excel at\n        explaining complex or creative concepts.[^25] Their ability to\n        engage in spontaneous, unpredictable conversation fosters\n        real-life communication skills.[^52] Human tutors naturally implement many mastery learning principles through responsive instruction and adaptive pacing.\n\n    -   *AI Strengths:* LLM tutors offer significant advantages in\n        scalability, 24/7 availability, and potentially lower cost.[^20]\n        They provide consistent, immediate feedback, particularly for\n        foundational skills like grammar and vocabulary, and can create\n        a less intimidating practice environment, reducing learner\n        anxiety.[^32] AI tutors can implement systematic mastery learning protocols more consistently than human tutors, ensuring all students receive equivalent opportunities for corrective instruction and competency demonstration.\n\n    -   *Human Weaknesses:* Human tutoring is expensive, difficult to\n        scale, and subject to scheduling and geographical constraints\n        [^25] (Proposal Section 5). These limitations prevent widespread implementation of the tutoring model that Bloom demonstrated to be most effective.\n\n    -   *AI Weaknesses:* LLMs lack genuine understanding, emotional\n        intelligence, and cultural depth. They can be factually\n        inaccurate, provide generic feedback, and raise privacy concerns\n        when deployed via cloud services. Their pedagogical capabilities\n        are often limited without specific tuning.[^19] Additionally, current AI tutors may struggle to implement the nuanced diagnostic assessments that effective mastery learning requires.\n\n-   **LLM Tutors vs. Traditional Classroom:** Traditional classrooms\n    provide valuable social interaction and peer learning opportunities.\n    However, they often struggle to cater to individual learning paces\n    and needs due to their inherent one-size-fits-all nature, offering\n    limited opportunities for personalized feedback [^25] (Proposal\n    Section 4). This is precisely the limitation that Bloom's 2 Sigma Problem identified. LLM tutors promise personalization at scale but cannot\n    replicate the rich social dynamics of a classroom. Interestingly, classroom implementations of Mastery Learning have shown significant improvements over traditional instruction, though still falling short of one-on-one tutoring effectiveness.\n\n-   **LLM Tutors vs. Mastery Learning Systems:** Traditional computer-based mastery learning systems have existed for decades, showing moderate effectiveness improvements over conventional instruction. However, these systems typically lack the natural language interaction capabilities and adaptive content generation that LLMs provide. The proposed system represents an evolution of mastery learning technologies, potentially combining the structured competency progression of traditional mastery systems with the conversational flexibility and content adaptability of modern LLMs.\n\n#### 2.4.4. Synthesis and Implications for the Current Project\n\nThe distinct profiles of AI and human tutors strongly suggest that an\noptimal approach may involve combining their strengths while addressing Bloom's scalability challenge. AI systems\nappear well-suited for providing scalable practice, instant feedback on\ndiscrete language points, and accessible learning opportunities. Human\ntutors, conversely, remain indispensable for fostering deep\nunderstanding, navigating cultural and emotional nuances, developing\nadvanced communicative competence, and providing mentorship.[^26] This\nrecognition stems from observing that AI\\'s advantages in cost,\navailability, and consistency [^25] are counterbalanced by human\nsuperiority in adaptability, empathy, and nuanced understanding.[^25]\nDirect comparisons consistently highlight this complementarity.[^26]\n\nThe proposed project's integration of fine-tuning, RAG, and local deployment addresses key limitations identified in this comparative analysis. Fine-tuning can instill mastery learning pedagogical principles, ensuring the AI tutor implements competency-based progression and appropriate corrective instruction strategies. RAG integration enables dynamic retrieval of curriculum-aligned content and culturally relevant materials, supporting both the corrective instruction and enrichment components of mastery learning. Local deployment addresses privacy concerns while enabling institutional control over the learning environment.\n\nConsequently, rather than viewing AI as a replacement for human\nteachers, a more productive path forward involves exploring hybrid\nmodels where AI tools augment human instruction, handle specific\ndrill-and-practice components, or provide supplementary support.[^26] The proposed system could serve as the scalable component of such a hybrid model, providing mastery-based skill building and practice while human instructors focus on higher-order language skills, cultural competency development, and motivational support. This approach potentially addresses Bloom's 2 Sigma Problem by combining the scalability of technology-mediated instruction with the effectiveness principles identified in one-on-one tutoring research.\n\nTo summarize these comparisons, Table 1 provides a qualitative\nassessment of different language learning approaches based on key\nfeatures identified in the literature and the proposal\\'s aims.\n\n**Table 1: Comparison of Language Learning Approaches**\n\n  ----------------------------------------------------------------------------------------------\n  **Feature**           **Human        **Static Apps  **Basic AI      **Proposed System\n                        Tutors**       (e.g.,         Chatbots        (Fine-tuned+RAG+Local)**\n                                       Duolingo)**    (Generic        \n                                                      LLMs)**         \n  --------------------- -------------- -------------- --------------- --------------------------\n  **Personalization**   High           Low            Medium          High (Targeted)\n                                                      (potential)     \n\n  **Feedback Quality**  High (Nuanced) Low (Basic     Variable (Often High (Targeted &\n                                       Correction)    Generic)        Pedagogical)\n\n  **Curriculum          Variable       High (Fixed    Low (Generic    High (Dynamic via RAG)\n  Integration**                        Curriculum)    Knowledge)      \n\n  **Scalability**       Low            High           High            High\n\n  **Cost**              High           Low/Freemium   Variable (API   Low (Operational, after\n                                                      costs)          setup)\n\n  **Cultural Nuance**   High           Low            Low/Variable    Medium/High (via RAG)\n\n  **Privacy (Learner    Variable       Medium (App    Low             High (Local Deployment)\n  Data)**                              Policies)      (Cloud-based)   \n\n  **Human Interaction** High           None           Low (Simulated) Low (Simulated)\n  ----------------------------------------------------------------------------------------------\n\n*Note: Assessments for the \\\"Proposed System\\\" reflect the project\\'s\nintended goals and potential based on its design.*\n\n## 3. Fine-Tuning LLMs for Pedagogical Goals in Language Education\n\n### 3.1. Rationale and Methodologies\n\nWhile pre-trained LLMs possess broad language understanding capabilities\nderived from vast datasets [^3], they are essentially generalists.\nFine-tuning is a critical process for adapting these models to perform\nspecific tasks or excel within particular domains.[^57] It involves\nfurther training a pre-trained model on a smaller, more specialized\ndataset to refine its capabilities and align its behavior with desired\noutcomes.[^57] In the context of education, and specifically language\ntutoring, the rationale for fine-tuning is to move beyond generic\nconversational ability and instill specific pedagogical\ncompetencies.[^29] The goal is \\\"pedagogical alignment\\\"---training LLMs\nto emulate effective teaching strategies, such as providing guided\ndiscovery rather than direct answers, offering constructive feedback,\nand adapting to learner progress.[^29] This contrasts with standard LLMs\noften optimized for simply providing the most plausible or preferred\nresponse to a prompt.[^47] The proposal explicitly aims for\ncurriculum-anchored fine-tuning to achieve this pedagogical focus\n(Proposal Section 6).\n\nSeveral methodologies exist for fine-tuning LLMs:\n\n-   **Supervised Fine-Tuning (SFT):** This is a common approach where\n    the model is trained on a dataset of labeled examples, typically\n    prompt-response pairs that demonstrate the desired behavior.[^29] For\n    pedagogical fine-tuning, this dataset might consist of examples of\n    effective tutor-student interactions, Socratic questioning\n    sequences, or well-structured feedback. The process involves\n    defining the target task clearly, selecting an appropriate\n    pre-trained base model, choosing relevant hyperparameters (like\n    learning rate and batch size), and training the model to minimize\n    the difference between its predictions and the target labels.[^57]\n\n-   **Instruction Fine-Tuning:** A variant of SFT, this involves\n    training the model specifically on examples that show how it should\n    respond to various instructional prompts or queries.[^57] This helps\n    the model learn to follow specific pedagogical instructions.\n\n-   **Parameter-Efficient Fine-Tuning (PEFT):** Recognizing that\n    fine-tuning all parameters of a large LLM is computationally\n    intensive and requires significant memory [^13], PEFT methods have\n    emerged. Techniques like Low-Rank Adaptation (LoRA) (though not\n    explicitly named in the snippets, frameworks like Unsloth mentioned\n    in the proposal often use them) involve updating only a small\n    fraction of the model\\'s parameters. This significantly reduces the\n    computational resources and time required for fine-tuning, making it\n    more feasible.[^57]\n\n-   **Preference Optimization (e.g., DPO):** Methods like Direct\n    Preference Optimization (DPO) align LLMs based on preferences\n    between pairs of possible responses.[^29] For instance, given a\n    student query, one response might be a direct answer, while another\n    might be a guiding question. A human or AI judge labels the guiding\n    question as preferred. The model is then trained to increase the\n    likelihood of generating preferred responses over rejected ones.[^29]\n    This technique has shown promise for steering LLMs towards Socratic\n    behavior.[^49]\n\n### 3.2. Applications in Language Pedagogy\n\nFine-tuning enables the customization of LLMs to serve specific\npedagogical functions within language education. Researchers are\napplying these techniques to develop tutors capable of:\n\n-   **Implementing Specific Teaching Strategies:** Fine-tuning can train\n    LLMs to adopt particular pedagogical approaches, such as the\n    Socratic method, where the tutor guides the student towards\n    discovering answers through carefully crafted questions rather than\n    providing them directly.[^29] It can also be used to encourage\n    scaffolded guidance, providing hints or breaking down problems.[^29]\n\n-   **Improving Feedback Quality and Characteristics:** Fine-tuning can\n    target the generation of more effective feedback. This includes\n    improving dimensions like the level of detail, accuracy, relevance\n    to learning objectives, and overall helpfulness.[^13] Furthermore, it\n    can shape the *characteristics* of the feedback, such as its tone\n    (positive vs. negative), directness (direct vs. indirect), and\n    specificity (general vs. specific), aligning it with pedagogical\n    best practices or learner preferences.[^24] For example, score-based\n    prompting, which guides feedback generation based on rubric scores,\n    improved feedback quality in EFL writing tutoring.[^24]\n\n-   **Curriculum Alignment:** As mentioned in the proposal, fine-tuning\n    can be used to anchor the LLM\\'s knowledge and responses within a\n    specific curriculum, ensuring its interactions are relevant to the\n    course content (Proposal Section 6).\n\nExamples from recent studies illustrate these applications. GuideLM, an\nLLM fine-tuned for programming education using SFT, demonstrated\nimproved Socratic guidance and economy of words compared to the base\nmodel.[^48] Another study successfully used DPO to fine-tune an LLM for\nSocratic interactions, showing significant improvement over prompting\nalone.[^49] Research investigating Learning from Human Preferences (LHP)\nalgorithms (which include methods like DPO) found they outperformed SFT\nin achieving pedagogical alignment for tutoring tasks.[^29]\n\n### 3.3. Effectiveness, Challenges, and Trade-offs\n\nWhile fine-tuning holds considerable promise for creating pedagogically\neffective LLM tutors, it also presents significant challenges and\ninherent trade-offs.\n\n-   **Effectiveness:** Studies confirm that fine-tuning can successfully\n    steer LLMs towards desired pedagogical behaviors, resulting in\n    interactions that are perceived as more educationally valuable than\n    those from generic models or prompted base models.[^24] Expert raters\n    have shown preference for fine-tuned models specifically for\n    educational purposes, even when acknowledging certain\n    trade-offs.[^48]\n\n-   **Challenge: Pedagogical Alignment vs. Accuracy Trade-off:** A major\n    challenge is the observed trade-off between optimizing for\n    pedagogical goals and maintaining the model\\'s general knowledge and\n    accuracy.[^48] Fine-tuning an LLM to be more Socratic, concise, or to\n    avoid giving direct answers might inadvertently reduce its ability\n    to provide factually correct information or solve problems\n    accurately when needed.[^48] This suggests a potential conflict\n    between specialized pedagogical behavior and broad knowledge\n    retention.\n\n-   **Challenge: The \\\"Student Data Paradox\\\":** A related but distinct\n    challenge arises when fine-tuning involves datasets containing\n    authentic student-tutor interactions. Such data inevitably includes\n    student errors, misconceptions, and non-standard language. Research\n    has uncovered the \\\"Student Data Paradox\\\": training LLMs on this\n    data to better understand and model learner behavior can\n    paradoxically degrade the LLM\\'s own factual knowledge base and\n    reasoning capabilities.[^59] This creates a fundamental difficulty:\n    making the tutor better at understanding students might make it\n    worse at providing accurate guidance.\n\n-   **Challenge: Data Requirements, Cost, and Maintenance:** Effective\n    fine-tuning hinges on the availability of large, high-quality,\n    task-specific datasets.[^49] Creating datasets that accurately\n    represent complex pedagogical strategies is a non-trivial task,\n    requiring significant pedagogical expertise and effort.[^49]\n    Furthermore, the process of fine-tuning, especially full\n    fine-tuning, is computationally expensive, requiring substantial\n    hardware resources.[^13] While PEFT methods alleviate this burden\n    [^57], costs remain. Additionally, as underlying foundation models\n    are frequently updated, fine-tuned versions need to be maintained\n    and potentially retrained, adding ongoing costs and effort.[^48]\n\n-   **Challenge: Evaluation Complexity:** Assessing the true pedagogical\n    effectiveness of fine-tuned LLM tutors is inherently difficult.\n    Current evaluation methods often rely on subjective judgments or\n    lack standardized metrics, particularly for measuring\n    adaptivity---how well the tutor adjusts to the learner\\'s evolving\n    state.[^24] The development of robust evaluation taxonomies and\n    benchmarks is an active area of research.[^61]\n\nThe interplay between the pedagogical alignment vs. accuracy trade-off\n[^48] and the Student Data Paradox [^59] highlights a significant hurdle.\nAttempting to make an LLM behave more like an effective tutor through\nfine-tuning risks compromising its knowledge integrity from two\ndirections: the inherent trade-offs of specialization and the potential\n\\\"contamination\\\" from learning student errors. This suggests that\nfine-tuning, while valuable for shaping interaction style, might be\ninsufficient on its own for building reliable and knowledgeable AI\ntutors. It points towards the need for complementary techniques, such as\nRAG, to ensure the tutor has access to accurate, up-to-date, and\ncurriculum-specific information, mitigating the knowledge degradation\nrisks associated with fine-tuning.\n\n## 4. Retrieval-Augmented Generation (RAG) for Curriculum and Cultural Integration\n\n### 4.1. RAG Explained: Bridging Internal Knowledge and External Data\n\nRetrieval-Augmented Generation (RAG) represents a powerful architectural\napproach designed to enhance the capabilities of LLMs by dynamically\nintegrating external knowledge into the generation process.[^62] Unlike\nstandard LLMs that rely solely on the information encoded within their\nparameters during training (parametric knowledge), RAG systems first\nretrieve relevant information from an external, often domain-specific or\nup-to-date, knowledge base before generating a response.[^64]\n\nThe typical RAG architecture consists of two main components [^62]:\n\n1.  **Retriever:** This component takes the user\\'s input query and\n    searches an external corpus (e.g., a collection of documents,\n    database records, web pages) to find the most relevant pieces of\n    information. This retrieval process often employs techniques like\n    dense vector retrieval, where text is converted into numerical\n    embeddings, and similarity searches (e.g., cosine similarity) are\n    performed within a vector database to find contextually related data\n    chunks.[^62]\n\n2.  **Generator:** This component is typically a standard LLM. It\n    receives the original user prompt *augmented* with the relevant\n    context retrieved by the retriever. The LLM then synthesizes this\n    combined information to generate a final, more informed, accurate,\n    and contextually relevant response.[^62]\n\nThe core advantage of RAG is its ability to ground LLM outputs in\nspecific, verifiable, and potentially real-time external data\nsources.[^63] This allows LLMs to access knowledge beyond their static\ntraining cut-off dates and incorporate domain-specific or proprietary\ninformation without the need for expensive and time-consuming retraining\nof the entire model.[^62] Consequently, RAG is a key technique for\naddressing common LLM limitations such as generating factually incorrect\ninformation (hallucinations) and relying on outdated knowledge.[^63]\n\n### 4.2. Applications of RAG in Educational AI\n\nThe ability of RAG to connect LLMs with external knowledge sources makes\nit particularly promising for educational applications, where accuracy,\nrelevance, and alignment with specific learning contexts are crucial.\n\n-   **Curriculum Integration:** A major challenge for generic LLMs in\n    tutoring is their lack of awareness of specific course curricula.\n    RAG provides a mechanism to overcome this by allowing the system to\n    retrieve information directly from course materials---such as\n    textbooks, lecture notes, syllabi, specific vocabulary lists, or\n    grammar rules---stored in an external knowledge base.[^44] When a\n    student asks a question or engages in an activity, the RAG system\n    can retrieve the relevant sections of the curriculum and use them to\n    generate a response that is directly aligned with what is being\n    taught in the course (Proposal Sections 2, 6). This ensures the\n    tutoring is relevant and reinforces classroom learning.[^44]\n\n-   **Cultural Relevance:** Similar to curriculum integration, RAG can\n    be used to enhance the cultural relevance of language tutoring. By\n    creating knowledge bases containing culturally specific information,\n    examples, social norms, or relevant media pertaining to the target\n    language culture, the RAG system can retrieve and incorporate this\n    context into its interactions (Proposal Sections 2, 4, 6). This can\n    help learners develop not just linguistic competence but also\n    intercultural understanding.\n\n-   **Factual Grounding and Accuracy:** Education demands a high degree\n    of factual accuracy. RAG significantly improves the reliability of\n    LLM outputs by grounding them in authoritative external sources.[^44]\n    For language learning, this means the tutor can provide verified\n    definitions, accurate grammar explanations, and reliable cultural\n    information, citing sources if necessary.[^63] Studies specifically\n    investigating RAG in educational contexts confirm its effectiveness\n    in reducing hallucinations and improving the trustworthiness of AI\n    responses.[^69]\n\n-   **Personalization and Context-Awareness:** RAG can enhance\n    personalization by retrieving information tailored to a specific\n    student\\'s query, previous interactions, or identified knowledge\n    gaps.[^65] This allows for more context-aware tutoring that adapts to\n    the immediate learning need.\n\n-   **Specific Educational Implementations:** RAG is being actively\n    explored in various educational tools. Surveys are identifying\n    numerous uses for RAG chatbots in education.[^66] Advanced forms like\n    Knowledge Graph-enhanced RAG (KG-RAG), which leverages structured\n    knowledge representations, have shown promise in improving learning\n    outcomes in AI tutoring systems by enabling more effective\n    context-aware retrieval.[^70] RAG can also serve as a tool for\n    educators, streamlining their access to relevant curricular\n    resources and supporting materials.[^44]\n\n### 4.3. Potential and Challenges of RAG in Language Tutoring\n\nRAG offers significant potential to transform LLM-based language tutors\ninto more effective, reliable, and contextually relevant educational\ntools.\n\n-   **Potential:** By dynamically injecting curriculum-specific content,\n    cultural nuances, and verified factual information, RAG directly\n    addresses key weaknesses of standalone LLMs, namely their lack of\n    specific knowledge, potential for inaccuracy, and generic\n    nature.[^44] It enables the creation of tutors that are adaptable to\n    specific courses and learner contexts without requiring constant\n    retraining of the base LLM, making personalized and relevant AI\n    tutoring more feasible.\n\n-   **Challenge: Retrieval Quality:** The effectiveness of RAG is\n    fundamentally dependent on the retriever\\'s ability to find truly\n    relevant and high-quality information from the knowledge base.[^68]\n    If the retrieved documents are irrelevant, noisy, or inaccurate, the\n    generator\\'s output will likely be compromised, regardless of the\n    LLM\\'s capabilities. Ensuring high-quality retrieval is a major\n    focus of ongoing RAG research, leading to techniques like reranking\n    retrieved results [^63] or implementing self-correction mechanisms\n    within the retrieval process (e.g., CRAG).[^68]\n\n-   **Challenge: Knowledge Base Creation and Maintenance:** Implementing\n    RAG requires the creation and ongoing maintenance of the external\n    knowledge bases.[^64] For educational applications, this involves\n    curating, structuring, preprocessing (e.g., chunking, embedding),\n    and indexing relevant curriculum materials, cultural information,\n    and factual resources. This requires significant upfront effort,\n    subject matter expertise, and processes for keeping the knowledge\n    base updated as curricula or information changes.[^44] Ensuring the\n    quality and accessibility of this data is critical.[^65]\n\n-   **Challenge: Integration Complexity and Latency:** Setting up a\n    functional RAG pipeline involves integrating multiple components:\n    the retriever, the vector database/knowledge store, and the\n    generator LLM.[^62] Ensuring these components work together\n    seamlessly and efficiently, particularly minimizing latency in the\n    retrieval step, can be technically challenging.\n\n-   **Challenge: Contextual Synthesis and Understanding:** Even with\n    relevant information retrieved, the LLM generator must effectively\n    synthesize this external context with the user\\'s prompt and its own\n    internal knowledge to produce a coherent and helpful response.\n    Relying solely on semantic similarity during retrieval might not\n    capture the deeper conceptual relationships often required for\n    effective pedagogical explanations.[^70] Approaches like KG-RAG\n    attempt to address this by incorporating structured knowledge.[^70]\n\nThe distinct capabilities and limitations of fine-tuning and RAG suggest\nthey are complementary approaches. Fine-tuning primarily addresses *how*\nthe LLM interacts---shaping its pedagogical style, tone, and adherence\nto specific teaching strategies (Section 3). RAG, on the other hand,\nprimarily addresses *what* the LLM knows---providing it with accurate,\nup-to-date, and context-specific information from external sources.[^62]\nThe proposal\\'s strategy of combining both techniques (Proposal Section\n6) leverages this synergy. Fine-tuning can equip the LLM with the\ndesired tutoring behaviors (e.g., asking guiding questions, providing\nfeedback in a certain format), while RAG ensures the content discussed\nduring these interactions is accurate, aligned with the curriculum, and\nculturally appropriate. This integrated approach holds the potential to\novercome the limitations encountered when using either technique in\nisolation---mitigating the accuracy concerns of fine-tuning while adding\npedagogical intelligence to the factual grounding provided by RAG.\n\n## 5. Local LLM Deployment in Educational Settings (Ollama)\n\n### 5.1. Rationale: Privacy, Control, and Cost\n\nThe deployment model for LLMs---whether cloud-based or local---has\nsignificant implications, particularly in sensitive domains like\neducation. Running LLMs locally, meaning on hardware controlled by the\ninstitution (on-premises servers, institutional clusters, or even\nindividual machines) rather than relying on third-party cloud providers,\noffers several compelling advantages:\n\n-   **Privacy & Security:** This is arguably the most critical driver\n    for local deployment in education.[^71] Student interactions with\n    tutoring systems generate sensitive data, potentially including\n    performance metrics, learning patterns, and even personally\n    identifiable information (PII). Local deployment keeps this data\n    within the institution\\'s controlled environment, mitigating risks\n    associated with transmitting data to external servers and helping\n    comply with stringent data privacy regulations like FERPA in the US\n    or GDPR in Europe.[^10] The proposal explicitly identifies data\n    privacy risks with commercial cloud providers as a key issue to\n    address (Proposal Sections 5, 6).\n\n-   **Control:** Local deployment grants institutions greater autonomy\n    and control over the AI models they use.[^71] This includes selecting\n    specific open-source models, configuring them according to\n    institutional policies, managing update cycles, and ensuring\n    alignment with educational goals without being subject to the terms,\n    conditions, or potential changes of external service providers.\n\n-   **Cost-Effectiveness:** While initial hardware setup or utilization\n    might involve costs, local deployment can be more cost-effective in\n    the long run compared to the potentially high and recurring API call\n    fees charged by commercial cloud LLM providers.[^71] This is\n    particularly true for institutions that can leverage existing\n    computing infrastructure, such as the DEAC cluster mentioned in the\n    proposal (Proposal Sections 3, 8). Using open-source models locally\n    avoids licensing fees.[^17]\n\n-   **Offline Access & Reduced Latency:** Local models can function\n    without a constant internet connection, ensuring reliability even\n    with intermittent network access.[^71] Processing queries locally can\n    also potentially reduce network latency compared to sending requests\n    to remote servers, leading to faster response times.[^71]\n\n-   **Customization:** Having direct access to the model facilitates\n    easier experimentation with fine-tuning and other customizations to\n    tailor the LLM\\'s behavior to specific pedagogical needs or\n    institutional requirements.[^74]\n\n### 5.2. Ollama as a Deployment Framework\n\nFrameworks have emerged to simplify the often complex process of setting\nup and managing LLMs locally. Ollama is highlighted in the proposal and\nseveral sources as one such tool [^71] (Proposal Sections 2, 3, 6). It is\npresented as an open-source platform designed to streamline the local\ndeployment of various popular open-access LLMs, such as those from the\nLlama or Mistral families.[^72]\n\nKey features attributed to Ollama include:\n\n-   **Ease of Use:** Ollama aims to simplify the process through\n    user-friendly interfaces, primarily a command-line interface (CLI),\n    allowing users to download (pull), run, and interact with LLMs using\n    simple commands.[^72]\n\n-   **Model Management:** It helps manage different models and their\n    versions automatically.[^78]\n\n-   **Configuration:** Ollama allows users to set model parameters (like\n    temperature or top_p) during runtime and define custom model\n    configurations and system prompts using a \\\"Modelfile\\\".[^74]\n\n-   **Integration:** It provides ways to interact with the running\n    models programmatically, for instance, through APIs or libraries for\n    languages like Python and Javascript, enabling integration into\n    larger applications like the proposed web-based tutoring\n    interface.[^74]\n\n### 5.3. Resource Requirements and Performance Trade-offs\n\nDeploying LLMs locally, even with tools like Ollama, imposes significant\ndemands on hardware resources.\n\n-   **Hardware Requirements:** A reasonably modern system is generally\n    required. This includes a multi-core 64-bit CPU (support for\n    instruction sets like AVX2 or AVX512 is often beneficial or required\n    [^73]), adequate RAM (minimums are often cited around 8GB, but 16GB\n    or even 32GB+ is recommended for larger models [^71]), and sufficient\n    fast storage (SSD recommended) for the models themselves, which can\n    range from a few gigabytes to tens or hundreds of gigabytes.[^74]\n\n-   **GPU Acceleration:** While LLMs *can* run on the CPU alone,\n    performance (inference speed, measured in tokens per second) is\n    typically very slow.[^75] A dedicated GPU, particularly an NVIDIA GPU\n    with sufficient Video RAM (VRAM) and CUDA support, dramatically\n    accelerates processing.[^71] The amount of VRAM is often the primary\n    limiting factor determining which models can be run efficiently, as\n    the model\\'s parameters need to fit into the GPU memory.[^79] Ollama\n    is designed to utilize available GPU resources.[^74]\n\n-   **Model Size vs. Performance:** There is a direct trade-off between\n    model size (number of parameters, e.g., 1B, 7B, 13B, 70B) and\n    performance/resource requirements.[^74] Smaller models (e.g., 1B-7B)\n    are less demanding on RAM/VRAM and run faster on lower-end hardware\n    but generally possess less knowledge and reasoning capability.[^75]\n    Larger models offer potentially better performance and more nuanced\n    capabilities but require substantially more powerful hardware.[^74]\n    Techniques like model quantization (e.g., using 4-bit precision\n    instead of 16-bit or 32-bit) can significantly reduce the memory\n    footprint and computational cost of models, making it feasible to\n    run larger models on less powerful hardware, albeit sometimes with a\n    slight reduction in output quality.[^78]\n\n-   **Scalability Limitations:** Unlike cloud platforms that offer\n    virtually limitless scalability (at a cost), local deployment is\n    constrained by the available hardware resources.[^42] Supporting a\n    large number of concurrent users might require significant\n    investment in local infrastructure or sophisticated load balancing\n    across multiple instances.[^75] The proposal leverages the\n    university\\'s DEAC cluster, which likely provides access to more\n    substantial resources than a typical desktop machine, potentially\n    mitigating some scalability concerns for a pilot phase (Proposal\n    Sections 3, 6).\n\n-   **Maintenance Overhead:** Running LLMs locally necessitates\n    technical expertise for initial setup, configuration, software\n    updates (Ollama, drivers, models), performance monitoring, and\n    troubleshooting.[^71] The proposal acknowledges this by including\n    support from an HPC Systems Administrator (Proposal Section 3).\n\n### 5.4. Local Deployment vs. Cloud-Based Solutions\n\nThe decision between local and cloud deployment involves weighing\ndistinct advantages and disadvantages. Local deployment, facilitated by\ntools like Ollama, excels in scenarios where **data privacy, security,\nand control** are paramount.[^71] It offers potential **cost savings** by\nutilizing existing hardware and avoiding recurring API fees [^71],\nenables **offline functionality** [^74], and can provide **low\nlatency**.[^71] However, it is fundamentally limited by **available\nhardware resources**, posing challenges for **scalability** and running\nthe largest, most capable models.[^72] It also requires **technical\nexpertise for maintenance**.[^71]\n\nConversely, cloud-based solutions offer easy **access to\nstate-of-the-art models**, immense **scalability**, and reduced\n**maintenance burden** for the end-user.[^72] However, they introduce\nsignificant **data privacy risks** due to data transmission to third\nparties [^72], incur **ongoing operational costs** based on usage [^72],\nand depend on **stable internet connectivity**.[^75]\n\nThe choice is therefore highly dependent on the specific context and\npriorities. For educational institutions, the heightened sensitivity\nsurrounding student data [^11] often makes the privacy guarantees of\nlocal deployment particularly attractive, if not essential for\ncompliance.[^10] When coupled with the availability of institutional\ncomputing resources, such as a university HPC cluster, the hardware\nlimitations can be partially overcome. In this light, the proposal\\'s\ndecision to pursue local deployment using Ollama appears as a strategic\nalignment with the specific constraints and priorities of its\neducational setting, prioritizing privacy and leveraging available\nresources, rather than merely a technical preference.\n\n## 6. Identifying Research Gaps and Opportunities\n\nSynthesizing the findings from the literature reveals several key gaps\nand challenges in the current landscape of LLM-based language tutoring,\nalongside corresponding opportunities for innovation.\n\n### 6.1. Synthesis of Limitations from Literature\n\n-   **Gap 1: Deep Pedagogical Integration and Adaptivity:** Despite\n    progress, a significant gap exists between current LLM capabilities\n    and truly effective, pedagogically grounded tutoring.[^19] Many\n    systems mimic conversation but lack deep instructional logic or the\n    ability to adapt based on robust models of student cognition and\n    learning progression, as seen in traditional Intelligent Tutoring\n    Systems (ITS).[^28] There is a need for LLMs that can reliably\n    implement specific, evidence-based teaching strategies (e.g.,\n    mastery learning, cognitive apprenticeship, productive failure) and\n    adapt their guidance based on nuanced assessments of student\n    understanding, not just surface-level correctness.[^42]\n\n-   **Gap 2: Curriculum Specificity and Dynamic Content Adaptation:**\n    Generic LLMs are inherently unaware of the specific content,\n    sequencing, and objectives of a particular course curriculum\n    (Proposal Sections 4, 5). While RAG offers a solution for retrieving\n    relevant information [^44], challenges remain in seamlessly\n    integrating this information, dynamically adapting to real-time\n    classroom activities or evolving lesson plans, and structuring\n    knowledge bases optimally for educational retrieval.[^65] How to best\n    represent and query complex curricular knowledge remains an open\n    question.\n\n-   **Gap 3: Nuanced Cultural Integration and Sensitivity:** Providing\n    culturally relevant language education goes beyond retrieving\n    factual cultural notes. It involves understanding and generating\n    content that reflects subtle cultural nuances, communication styles,\n    and diverse perspectives appropriately. Current approaches,\n    including basic RAG, may struggle to achieve this level of depth and\n    sensitivity dynamically across varied learner backgrounds (Proposal\n    Section 4). Research is needed on how to imbue LLMs with genuine\n    intercultural competence.\n\n-   **Gap 4: Balancing Pedagogy, Accuracy, Efficiency, and Knowledge\n    Integrity:** As highlighted previously, there are inherent tensions\n    between optimizing LLMs for pedagogical alignment, maintaining\n    factual accuracy, ensuring computational efficiency (especially for\n    local deployment), and preserving the integrity of the model\\'s\n    knowledge base (avoiding degradation from fine-tuning trade-offs or\n    the Student Data Paradox).[^48] Finding solutions that effectively\n    balance these competing demands is a critical research challenge.\n\n-   **Gap 5: Robust and Standardized Evaluation Frameworks:** The field\n    currently lacks widely accepted, standardized methodologies and\n    metrics for rigorously evaluating the pedagogical effectiveness,\n    adaptivity, and actual impact on student learning outcomes of\n    LLM-based tutors.[^24] Current evaluations often rely on subjective\n    measures, limited benchmarks, or focus on technical performance\n    rather than educational impact.[^61] Developing reliable ways to\n    measure and compare AI tutor efficacy is essential for progress.\n\n-   **Gap 6: Privacy-Preserving Personalization and Data Minimization:**\n    Achieving deep personalization typically relies on collecting and\n    analyzing substantial amounts of student interaction data.[^13] This\n    creates a direct conflict with the increasing need for stringent\n    data privacy and security in education.[^10] Developing AI tutoring\n    systems that can provide meaningful personalization while adhering\n    to strict privacy constraints, potentially through local deployment\n    and data minimization techniques, remains a significant research and\n    engineering challenge.\n\n### 6.2. Opportunities for Innovation\n\nThese gaps point towards several promising avenues for future research\nand development:\n\n-   **Advanced Pedagogical Alignment Techniques:** Developing novel\n    fine-tuning methods (beyond basic SFT or DPO) or prompting\n    strategies specifically designed to instill complex pedagogical\n    behaviors while minimizing negative impacts on accuracy and\n    knowledge integrity.\n\n-   **Sophisticated Educational RAG:** Creating more advanced RAG\n    frameworks tailored for educational content, potentially\n    incorporating structured knowledge representations like knowledge\n    graphs (KG-RAG) [^70], hierarchical summarization (RAPTOR) [^68], or\n    improved retrieval and fusion mechanisms to better handle curriculum\n    complexity and conceptual relationships.\n\n-   **Hybrid Human-AI Tutoring Models:** Designing and evaluating\n    systems that effectively combine the strengths of AI tutors\n    (scalability, availability, practice) with the irreplaceable skills\n    of human educators (empathy, deep understanding, mentorship),\n    defining optimal roles and workflows for each.\n\n-   **Privacy-Enhancing Architectures:** Building robust, secure, and\n    effective AI tutoring systems based on local deployment models (like\n    Ollama) or exploring other privacy-preserving techniques (e.g.,\n    federated learning, differential privacy) suitable for educational\n    data.\n\n-   **Comprehensive Evaluation Methodologies:** Establishing\n    standardized benchmarks, metrics, and protocols for evaluating AI\n    tutors across multiple dimensions, including pedagogical alignment,\n    adaptivity, learning gains, user experience, and ethical\n    considerations.[^61]\n\n-   **Multimodal and Multilingual Integration:** Exploring the\n    integration of multimodal capabilities (processing text, image,\n    audio, video) for richer language learning interactions [^14] and\n    improving the performance and fairness of LLMs across diverse\n    languages, especially lower-resource ones.[^14]\n\n## 7. Positioning the Proposed Project\n\nThe research proposal \\\"Adaptive Second Language Tutoring with\nFine-Tuned and RAG-Enhanced local LLMs\\\" positions itself strategically\nwithin the current landscape by directly addressing several of the\nidentified research gaps through a specific combination of emerging\ntechnologies.\n\n### 7.1. Addressing Identified Gaps\n\nThe project\\'s design incorporates elements aimed at tackling key\nlimitations:\n\n-   **Addressing Gap 1 (Pedagogy):** The proposal explicitly includes\n    the **fine-tuning** of open-access LLMs using frameworks like\n    Unsloth or MLX-LM (Proposal Section 2). The intention is to train\n    these models on pedagogical datasets to move beyond generic\n    conversation and towards structured, effective tutoring interactions\n    aligned with language learning principles (Proposal Section 6).\n\n-   **Addressing Gap 2 & 3 (Curriculum/Culture):** The integration of\n    **Retrieval-Augmented Generation (RAG)** is proposed to dynamically\n    inject course-specific materials (vocabulary, grammar) and relevant\n    cultural content into the tutor\\'s knowledge base (Proposal Sections\n    2, 6). This aims to make the tutor contextually aware, aligned with\n    existing curricula, and more culturally responsive, overcoming the\n    limitations of generic LLM knowledge (Proposal Section 4).\n\n-   **Addressing Gap 4 (Balance):** The project attempts to navigate the\n    complex balance between pedagogy, accuracy, and efficiency by\n    **combining fine-tuning and RAG**. As discussed (Section 4.3),\n    fine-tuning can shape the pedagogical interaction style, while RAG\n    provides a mechanism to ground the content in accurate, relevant\n    external knowledge. This synergy potentially mitigates the accuracy\n    degradation risks associated with fine-tuning alone and adds\n    pedagogical structure to RAG\\'s factual grounding.\n\n-   **Addressing Gap 5 (Evaluation):** While the initial phase described\n    in the proposal focuses on establishing technical feasibility and\n    preliminary educator evaluation as a proof of concept (Proposal\n    Section 7), this foundational work is a necessary prerequisite for\n    future, more rigorous evaluations involving student learning\n    outcomes, potentially through larger grants sought based on the\n    initial success.\n\n-   **Addressing Gap 6 (Privacy):** The project tackles privacy concerns\n    head-on by opting for **local deployment using Ollama** on\n    university-controlled infrastructure (the DEAC cluster) (Proposal\n    Sections 3, 6, 8). This architectural choice is explicitly motivated\n    by the desire to keep sensitive learner data on-premises and avoid\n    reliance on external commercial APIs, aligning with institutional\n    needs for data security and control (Proposal Section 5, 6).\n\n### 7.2. Novelty and Potential Contribution\n\nThe primary novelty of the proposed project lies not necessarily in the\nindividual components themselves, but in their **synergistic\nintegration** applied specifically to the challenge of adaptive second\nlanguage tutoring within an institutional context:\n\n1.  **Pedagogical Fine-Tuning:** Adapting the LLM\\'s conversational\n    style and interaction patterns specifically for language tutoring\n    goals.\n\n2.  **RAG Enhancement:** Dynamically grounding the tutor\\'s knowledge in\n    specific curriculum requirements and relevant cultural information,\n    enhancing accuracy and contextual relevance.\n\n3.  **Local, Open-Source Deployment (Ollama):** Ensuring data privacy,\n    institutional control, and potential cost-effectiveness by\n    leveraging open-source models and tools on local infrastructure.\n\nWhile research exists on fine-tuning for pedagogy [^29], RAG for\nknowledge grounding [^66], and local LLM deployment [^71], the *combined*\napplication of these three elements to create an adaptive,\ncurriculum-aware, culturally relevant, *and* privacy-preserving second\nlanguage tutor appears to be a relatively underexplored configuration\nbased on the reviewed literature.\n\nFurthermore, the project\\'s commitment to using open-access LLMs (from\nHuggingFace) and open-source tools for fine-tuning (Unsloth/MLX-LM) and\ndeployment (Ollama) promotes transparency, reproducibility, and\naccessibility for other researchers and institutions facing similar\nchallenges (Proposal Sections 2, 8). The initial focus on developing a\nproof of concept (Proposal Section 7) represents a pragmatic approach to\nvalidating the feasibility and potential of this specific technological\ncombination before committing to larger-scale implementation and\nevaluation.\n\nTable 2 provides a summary of how each core technique contributes to the\nproject\\'s objectives, linking them to the benefits sought and\nchallenges identified in the literature.\n\n**Table 2: Overview of LLM Techniques in the Proposed Project**\n\n  ----------------------------------------------------------------------------------------------------------\n  **Technique**     **Purpose in Project  **Key Benefits        **Potential                   **Relevant\n                    (from Proposal)**     Addressed**           Challenges/Considerations**   Literature\n                                                                                              Snippets\n                                                                                              (Examples)**\n  ----------------- --------------------- --------------------- ----------------------------- --------------\n  **Fine-Tuning**   Adapt LLM for         Pedagogical           Accuracy Trade-off, Data      [^29]\n                    pedagogical goals;    Alignment, Structured Needs, Cost, Evaluation       \n                    anchor in pedagogical Tutoring Interaction                                \n                    datasets (Sec 2, 6)                                                       \n\n  **RAG             Inject                Curriculum Alignment, Retrieval Quality, Knowledge  [^44]\n  Integration**     course-specific       Cultural Relevance,   Base Creation/Maintenance     \n                    materials (vocab,     Factual Accuracy                                    \n                    grammar, culture);                                                        \n                    enhance relevance                                                         \n                    (Sec 2, 6)                                                                \n\n  **Local           Ensure privacy;       Data Privacy,         Hardware Requirements,        [^71]\n  Deployment        leverage              Control,              Scalability Limits,           \n  (Ollama)**        institutional         Cost-Effectiveness,   Maintenance                   \n                    resources; balance    Offline Use                                         \n                    latency/scalability                                                       \n                    (Sec 2, 3, 5, 6, 8)                                                       \n  ----------------------------------------------------------------------------------------------------------\n\n## 8. Conclusion\n\n### 8.1. Summary of Key Findings and Gaps\n\nThe integration of Large Language Models into second language education\nholds considerable promise, offering potential pathways to more\npersonalized, accessible, and engaging learning experiences.[^5] Benefits\nsuch as adaptive learning paths, immediate feedback, 24/7 availability,\nand reduced learner anxiety are frequently highlighted in the\nliterature.[^20] However, realizing this potential is hindered by\nsignificant challenges inherent in current LLM technology and its\napplication in educational contexts.\n\nKey limitations include a prevalent lack of deep pedagogical grounding,\nwith models often prioritizing fluent conversation over structured\nteaching [^19]; issues with factual accuracy and the generation of\n\\\"hallucinations\\\" [^17]; the provision of generic or ineffective\nfeedback [^24]; difficulties in dynamically integrating specific\ncurriculum content and nuanced cultural information [^25]; and critical\nconcerns regarding student data privacy and security, particularly with\ncloud-based deployments.^27^\n\nConsequently, major research gaps persist. These include the need for:\n(1) robust methods for achieving deep pedagogical alignment and\nadaptivity in LLM tutors; (2) effective techniques for dynamic\ncurriculum and cultural integration; (3) strategies to balance the\ncompeting demands of pedagogical effectiveness, factual accuracy,\nknowledge integrity, and computational efficiency; (4) standardized and\nreliable frameworks for evaluating the educational impact of AI tutors;\nand (5) architectures that enable meaningful personalization while\nrigorously preserving student privacy.\n\n### 8.2. Significance of the Proposed Project\n\nThe proposed project, \\\"Adaptive Second Language Tutoring with\nFine-Tuned and RAG-Enhanced local LLMs,\\\" is significant because it\ndirectly confronts several of these critical gaps through a novel and\nsynergistic combination of techniques. By integrating pedagogical\nfine-tuning (to shape *how* the tutor interacts) with RAG (to inform\n*what* the tutor discusses, grounding it in specific curriculum and\ncultural context) and deploying this system locally via Ollama (to\nensure data privacy and institutional control), the project aims to\ncreate a more holistic and effective AI tutoring solution.\n\nThis specific configuration---fine-tuning for pedagogy, RAG for\ncontext/accuracy, and local deployment for privacy---addresses the\nlimitations of using these techniques in isolation and represents a\npromising direction for developing practical, responsible, and\neducationally relevant AI tools. The focus on open-source models and\nframeworks further enhances its potential value to the wider academic\ncommunity. While presented as an initial proof-of-concept, the\nsuccessful demonstration of this integrated approach could make a\nvaluable contribution to the field of AI-enhanced language education,\npaving the way for more sophisticated, adaptive, and trustworthy AI\ntutors that can genuinely support second language learners within\ninstitutional settings.\n\n#### Works cited\n\n1.  \\[2501.10326\\] Large language models for automated scholarly paper\n    review: A survey - arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/abs/2501.10326]{.underline}](https://arxiv.org/abs/2501.10326)\n\n2.  \\[2403.18105\\] Large Language Models for Education: A Survey and\n    Outlook - arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/abs/2403.18105]{.underline}](https://arxiv.org/abs/2403.18105)\n\n3.  A Comprehensive Overview of Large Language Models - arXiv, accessed\n    April 18, 2025,\n    [[http://arxiv.org/pdf/2307.06435]{.underline}](http://arxiv.org/pdf/2307.06435)\n\n4.  What Are Large Language Models and Multimodal Models? - AI and\n    Higher Education, accessed April 18, 2025,\n    [[https://ctrl.carlow.edu/ai/whatare]{.underline}](https://ctrl.carlow.edu/ai/whatare)\n\n5.  Large Language Models for Education: A Survey and Outlook - arXiv,\n    accessed April 18, 2025,\n    [[https://arxiv.org/pdf/2403.18105]{.underline}](https://arxiv.org/pdf/2403.18105)\n\n6.  Large Language Models in Education: Empower Success - Maxiom\n    Technology, accessed April 18, 2025,\n    [[https://www.maxiomtech.com/large-language-models-in-education/]{.underline}](https://www.maxiomtech.com/large-language-models-in-education/)\n\n7.  The impact of large language models on higher education: exploring\n    the connection between AI and Education 4.0 - Frontiers, accessed\n    April 18, 2025,\n    [[https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1392091/full]{.underline}](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1392091/full)\n\n8.  \\[2311.13160\\] Large Language Models in Education: Vision and\n    Opportunities - arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/abs/2311.13160]{.underline}](https://arxiv.org/abs/2311.13160)\n\n9.  Students are using large language models and AI detectors can often\n    detect their use, accessed April 18, 2025,\n    [[https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1374889/full]{.underline}](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1374889/full)\n\n10. The promise and challenges of generative AI in education - Taylor &\n    Francis Online, accessed April 18, 2025,\n    [[https://www.tandfonline.com/doi/full/10.1080/0144929X.2024.2394886]{.underline}](https://www.tandfonline.com/doi/full/10.1080/0144929X.2024.2394886)\n\n11. The Impact of Large Language Models on Education: Simplifying AI for\n    Better Learning, accessed April 18, 2025,\n    [[https://integranxt.com/blog/the-impact-of-large-language-models-on-education-simplifying-ai-for-better-learning/]{.underline}](https://integranxt.com/blog/the-impact-of-large-language-models-on-education-simplifying-ai-for-better-learning/)\n\n12. How AI and Language Model Technology Can Accelerate Educational\n    Excellence, accessed April 18, 2025,\n    [[https://evolllution.com/technology/tech-tools-and-resources/how-ai-and-language-model-technology-can-accelerate-educational-excellence]{.underline}](https://evolllution.com/technology/tech-tools-and-resources/how-ai-and-language-model-technology-can-accelerate-educational-excellence)\n\n13. Pedagogical Alignment of Large Language Models (LLM) for\n    Personalized Learning - Scientific Research Publishing, accessed\n    April 18, 2025,\n    [[https://www.scirp.org/pdf/jilsa2024164_79601651.pdf]{.underline}](https://www.scirp.org/pdf/jilsa2024164_79601651.pdf)\n\n14. Pedagogical Alignment of Large Language Models (LLM) for\n    Personalized Learning: A Survey, Trends and Challenges - Scientific\n    Research Publishing, accessed April 18, 2025,\n    [[https://www.scirp.org/journal/paperinformation?paperid=137833]{.underline}](https://www.scirp.org/journal/paperinformation?paperid=137833)\n\n15. (PDF) \\\"Would You Want an AI Tutor?\\\" Understanding Stakeholder\n    Perceptions of LLM-based Chatbots in the Classroom - ResearchGate,\n    accessed April 18, 2025,\n    [[https://www.researchgate.net/publication/389617012_Would_You_Want_an_AI_Tutor_Understanding_Stakeholder_Perceptions_of_LLM-based_Chatbots_in_the_Classroom]{.underline}](https://www.researchgate.net/publication/389617012_Would_You_Want_an_AI_Tutor_Understanding_Stakeholder_Perceptions_of_LLM-based_Chatbots_in_the_Classroom)\n\n16. AI in Education - Education Next, accessed April 18, 2025,\n    [[https://www.educationnext.org/a-i-in-education-leap-into-new-era-machine-intelligence-carries-risks-challenges-promises/]{.underline}](https://www.educationnext.org/a-i-in-education-leap-into-new-era-machine-intelligence-carries-risks-challenges-promises/)\n\n17. Benefits And Limitations Of LLM - AiThority, accessed April 18,\n    2025,\n    [[https://aithority.com/machine-learning/benefits-and-limitations-of-llm/]{.underline}](https://aithority.com/machine-learning/benefits-and-limitations-of-llm/)\n\n18. What Is A Large Language Model? \\[use cases, benefits,\n    limitations\\] - Spot Intelligence, accessed April 18, 2025,\n    [[https://spotintelligence.com/2023/08/02/what-is-a-large-language-model-use-cases-benefits-limitations-what-does-the-future-hold/]{.underline}](https://spotintelligence.com/2023/08/02/what-is-a-large-language-model-use-cases-benefits-limitations-what-does-the-future-hold/)\n\n19. Position: LLMs Can be Good Tutors in Foreign Language Education -\n    arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/html/2502.05467v1]{.underline}](https://arxiv.org/html/2502.05467v1) \n\n20. Full article: Integrating AI Technology Into Language Teacher\n    Education: Challenges, Potentials, and Assumptions - Taylor &\n    Francis Online, accessed April 18, 2025,\n    [[https://www.tandfonline.com/doi/full/10.1080/07380569.2025.2458950]{.underline}](https://www.tandfonline.com/doi/full/10.1080/07380569.2025.2458950)\n\n21. EJ1383526 - Large Language Model-Based Artificial Intelligence in\n    the Language Classroom: Practical Ideas for Teaching, Teaching\n    English with Technology, 2023 - ERIC, accessed April 18, 2025,\n    [[https://eric.ed.gov/?id=EJ1383526]{.underline}](https://eric.ed.gov/?id=EJ1383526)\n\n22. Position: LLMs Can be Good Tutors in Foreign Language Education -\n    ResearchGate, accessed April 18, 2025,\n    [[https://www.researchgate.net/publication/388883004_Position_LLMs_Can_be_Good_Tutors_in_Foreign_Language_Education]{.underline}](https://www.researchgate.net/publication/388883004_Position_LLMs_Can_be_Good_Tutors_in_Foreign_Language_Education)\n\n23. Unlock Your Language Potential: How to Use AI for Second Language\n    Learning - Italki, accessed April 18, 2025,\n    [[https://www.italki.com/en/article/XYOyOOSC9mfWXP01UxZMMd/unlock-your-language-potential-how-to-use-ai-for-second-language-learning]{.underline}](https://www.italki.com/en/article/XYOyOOSC9mfWXP01UxZMMd/unlock-your-language-potential-how-to-use-ai-for-second-language-learning)\n\n24. aclanthology.org, accessed April 18, 2025,\n    [[https://aclanthology.org/2024.customnlp4u-1.21.pdf]{.underline}](https://aclanthology.org/2024.customnlp4u-1.21.pdf)\n\n25. Traditional vs. AI-Language Learning: Which Is Better? - Saima AI,\n    accessed April 18, 2025,\n    [[https://saima.ai/blog/traditional-vs-ai-language-learning]{.underline}](https://saima.ai/blog/traditional-vs-ai-language-learning)\n\n26. AI Tutoring vs. Traditional Tutoring: Key Differences - Dialzara,\n    accessed April 18, 2025,\n    [[https://dialzara.com/blog/ai-tutoring-vs-traditional-tutoring-key-differences/]{.underline}](https://dialzara.com/blog/ai-tutoring-vs-traditional-tutoring-key-differences/)\n\n27. AI Tutors: Bridging the Gap Between Teachers and Students \\|\n    OpenGrowth, accessed April 18, 2025,\n    [[https://www.blogs.opengrowth.com/ai-tutors-bridging-the-gap-between-teachers-and-students]{.underline}](https://www.blogs.opengrowth.com/ai-tutors-bridging-the-gap-between-teachers-and-students)\n\n28. Can Large Language Models Match Tutoring System Adaptivity? A\n    Benchmarking Study, accessed April 18, 2025,\n    [[https://arxiv.org/html/2504.05570v1]{.underline}](https://arxiv.org/html/2504.05570v1)\n\n29. \\[2402.05000\\] Pedagogical Alignment of Large Language Models -\n    arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/abs/2402.05000]{.underline}](https://arxiv.org/abs/2402.05000)\n\n30. \\[2310.19736\\] Evaluating Large Language Models: A Comprehensive\n    Survey - arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/abs/2310.19736]{.underline}](https://arxiv.org/abs/2310.19736)\n\n31. Full article: Artificial intelligence pedagogical chatbots as L2\n    conversational agents, accessed April 18, 2025,\n    [[https://www.tandfonline.com/doi/full/10.1080/2331186X.2024.2327789]{.underline}](https://www.tandfonline.com/doi/full/10.1080/2331186X.2024.2327789)\n\n32. The impact of chatbots based on large language models on second\n    language vocabulary acquisition - PMC, accessed April 18, 2025,\n    [[https://pmc.ncbi.nlm.nih.gov/articles/PMC10850600/]{.underline}](https://pmc.ncbi.nlm.nih.gov/articles/PMC10850600/)\n\n33. (PDF) AI-driven Technology and Chatbots as Tools for Enhancing\n    English Language Learning in the Context of Second Language\n    Acquisition: A Review Study - ResearchGate, accessed April 18, 2025,\n    [[https://www.researchgate.net/publication/375011638_AI-driven_Technology_and_Chatbots_as_Tools_for_Enhancing_English_Language_Learning_in_the_Context_of_Second_Language_Acquisition_A_Review_Study]{.underline}](https://www.researchgate.net/publication/375011638_AI-driven_Technology_and_Chatbots_as_Tools_for_Enhancing_English_Language_Learning_in_the_Context_of_Second_Language_Acquisition_A_Review_Study)\n\n34. LLM-as-a-tutor in EFL Writing Education: Focusing on Evaluation of\n    Student-LLM Interaction, accessed April 18, 2025,\n    [[https://aclanthology.org/2024.customnlp4u-1.21/]{.underline}](https://aclanthology.org/2024.customnlp4u-1.21/)\n\n35. Balancing the Benefits and Risks of AI Large Language Models in K12\n    Public Schools - VCU Scholars Compass, accessed April 18, 2025,\n    [[https://scholarscompass.vcu.edu/cgi/viewcontent.cgi?article=1133&context=merc_pubs]{.underline}](https://scholarscompass.vcu.edu/cgi/viewcontent.cgi?article=1133&context=merc_pubs)\n\n36. (PDF) Transforming Education with Large Language Models:\n    Opportunities, Challenges, and Ethical Considerations -\n    ResearchGate, accessed April 18, 2025,\n    [[https://www.researchgate.net/publication/382825702_Transforming_Education_with_Large_Language_Models_Opportunities_Challenges_and_Ethical_Considerations]{.underline}](https://www.researchgate.net/publication/382825702_Transforming_Education_with_Large_Language_Models_Opportunities_Challenges_and_Ethical_Considerations)\n\n37. Language Learning through AI Chatbots: Effectiveness and Cognitive\n    Load Analysis, accessed April 18, 2025,\n    [[https://www.journal.ypidathu.or.id/index.php/jssut/article/view/1346]{.underline}](https://www.journal.ypidathu.or.id/index.php/jssut/article/view/1346)\n\n38. The use of chatbots in university EFL settings: Research trends and\n    pedagogical implications - Frontiers, accessed April 18, 2025,\n    [[https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1131506/full]{.underline}](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1131506/full)\n\n39. The promises and challenges of AI-based chatbots in language\n    education through the lens of learner emotions - PubMed Central,\n    accessed April 18, 2025,\n    [[https://pmc.ncbi.nlm.nih.gov/articles/PMC11416278/]{.underline}](https://pmc.ncbi.nlm.nih.gov/articles/PMC11416278/)\n\n40. (PDF) Chatbots for language learning-Are they really useful? A\n    systematic review of chatbot-supported language learning -\n    ResearchGate, accessed April 18, 2025,\n    [[https://www.researchgate.net/publication/354813647_Chatbots_for_language_learning-Are_they_really_useful_A_systematic_review_of_chatbot-supported_language_learning]{.underline}](https://www.researchgate.net/publication/354813647_Chatbots_for_language_learning-Are_they_really_useful_A_systematic_review_of_chatbot-supported_language_learning)\n\n41. AI Tutors: Bridging Skill Gaps for Personalized Learning - Jotverse,\n    accessed April 18, 2025,\n    [[https://www.jotverse.com/ai-tutors-bridging-skill-gaps-for-personalized-learning/]{.underline}](https://www.jotverse.com/ai-tutors-bridging-skill-gaps-for-personalized-learning/)\n\n42. Advancing Education through Tutoring Systems - arXiv, accessed April\n    18, 2025,\n    [[https://arxiv.org/pdf/2503.09748]{.underline}](https://arxiv.org/pdf/2503.09748)\n\n43. How AI-Language Practice Stacks Up Against Online Tutor Services: An\n    In-Depth Comparison \\| Talkio AI, accessed April 18, 2025,\n    [[https://www.talkio.ai/blog/posts/how-ai-stacks-up-against-online-tutor-services]{.underline}](https://www.talkio.ai/blog/posts/how-ai-stacks-up-against-online-tutor-services)\n\n44. Using your own content in LLM\\'s - Retrieval Augmented Generation\n    (RAG) - AI-for-Education.org, accessed April 18, 2025,\n    [[https://ai-for-education.org/wp-content/uploads/2024/03/AI-for-Education-RAG.pdf]{.underline}](https://ai-for-education.org/wp-content/uploads/2024/03/AI-for-Education-RAG.pdf)\n\n45. ChatGPT Promises and Challenges in Education: Computational and\n    Ethical Perspectives, accessed April 18, 2025,\n    [[https://www.mdpi.com/2227-7102/14/8/814]{.underline}](https://www.mdpi.com/2227-7102/14/8/814)\n\n46. Language Models in the Classroom: Bridging the Gap Between\n    Technology and Teaching, accessed April 18, 2025,\n    [[https://hai.stanford.edu/news/language-models-in-the-classroom-bridging-the-gap-between-technology-and-teaching]{.underline}](https://hai.stanford.edu/news/language-models-in-the-classroom-bridging-the-gap-between-technology-and-teaching)\n\n47. (PDF) Towards the Pedagogical Steering of Large Language Models for\n    Tutoring: A Case Study with Modeling Productive Failure -\n    ResearchGate, accessed April 18, 2025,\n    [[https://www.researchgate.net/publication/384699353_Towards_the_Pedagogical_Steering_of_Large_Language_Models_for_Tutoring_A_Case_Study_with_Modeling_Productive_Failure]{.underline}](https://www.researchgate.net/publication/384699353_Towards_the_Pedagogical_Steering_of_Large_Language_Models_for_Tutoring_A_Case_Study_with_Modeling_Productive_Failure)\n\n48. Supervised Fine-Tuning LLMs to Behave as Pedagogical Agents in\n    Programming Education, accessed April 18, 2025,\n    [[https://arxiv.org/html/2502.20527v1]{.underline}](https://arxiv.org/html/2502.20527v1)\n\n49. EULER: Fine Tuning a Large Language Model for Socratic\n    Interactions - CEUR-WS.org, accessed April 18, 2025,\n    [[https://ceur-ws.org/Vol-3879/AIxEDU2024_paper_26.pdf]{.underline}](https://ceur-ws.org/Vol-3879/AIxEDU2024_paper_26.pdf)\n\n50. Unveiling the power and limitations of large language models -\n    6Clicks, accessed April 18, 2025,\n    [[https://www.6clicks.com/resources/blog/unveiling-the-power-of-large-language-models]{.underline}](https://www.6clicks.com/resources/blog/unveiling-the-power-of-large-language-models)\n\n51. Large Language Models (LLMs): Challenges, Predictions, Tutorial - V7\n    Labs, accessed April 18, 2025,\n    [[https://www.v7labs.com/blog/large-language-models-llms]{.underline}](https://www.v7labs.com/blog/large-language-models-llms)\n\n52. The future of language learning: Human vs AI tutors - Lingoda,\n    accessed April 18, 2025,\n    [[https://www.lingoda.com/en/p/research/future-language-learning-human-ai/]{.underline}](https://www.lingoda.com/en/p/research/future-language-learning-human-ai/)\n\n53. AI Tutoring Comparison of Language Tutors \\| Restackio, accessed\n    April 18, 2025,\n    [[https://www.restack.io/p/ai-tutoring-answer-comparison-language-tutors-cat-ai]{.underline}](https://www.restack.io/p/ai-tutoring-answer-comparison-language-tutors-cat-ai)\n\n54. Are there advantages to training LLM in Chinese? : r/singularity -\n    Reddit, accessed April 18, 2025,\n    [[https://www.reddit.com/r/singularity/comments/1idfx8u/are_there_advantages_to_training_llm_in_chinese/]{.underline}](https://www.reddit.com/r/singularity/comments/1idfx8u/are_there_advantages_to_training_llm_in_chinese/)\n\n55. AI versus human learning: The importance of human interaction -\n    Preply, accessed April 18, 2025,\n    [[https://preply.com/en/blog/ia-vs-human-learning/]{.underline}](https://preply.com/en/blog/ia-vs-human-learning/)\n\n56. Comments - Five Differences Between Human and AI Tutors, accessed\n    April 18, 2025,\n    [[https://danmeyer.substack.com/p/five-differences-between-human-and/comments]{.underline}](https://danmeyer.substack.com/p/five-differences-between-human-and/comments)\n\n57. Fine-tuning large language models (LLMs) in 2025 - SuperAnnotate,\n    accessed April 18, 2025,\n    [[https://www.superannotate.com/blog/llm-fine-tuning]{.underline}](https://www.superannotate.com/blog/llm-fine-tuning)\n\n58. Learning Dynamics of LLM Finetuning - OpenReview, accessed April 18,\n    2025,\n    [[https://openreview.net/forum?id=tPNHOoZFl9]{.underline}](https://openreview.net/forum?id=tPNHOoZFl9)\n\n59. Student Data Paradox and Curious Case of Single Student-Tutor \\...,\n    accessed April 18, 2025,\n    [[https://aclanthology.org/2024.findings-emnlp.912/]{.underline}](https://aclanthology.org/2024.findings-emnlp.912/)\n\n60. Fine-tuning LLM on research papers : r/LanguageTechnology - Reddit,\n    accessed April 18, 2025,\n    [[https://www.reddit.com/r/LanguageTechnology/comments/179aid1/finetuning_llm_on_research_papers/]{.underline}](https://www.reddit.com/r/LanguageTechnology/comments/179aid1/finetuning_llm_on_research_papers/)\n\n61. An Evaluation Taxonomy for Pedagogical Ability Assessment of\n    LLM-Powered AI Tutors, accessed April 18, 2025,\n    [[https://arxiv.org/html/2412.09416v2]{.underline}](https://arxiv.org/html/2412.09416v2)\n\n62. RAG, or Retrieval Augmented Generation: Revolutionizing AI in 2025 -\n    Glean, accessed April 18, 2025,\n    [[https://www.glean.com/blog/rag-retrieval-augmented-generation]{.underline}](https://www.glean.com/blog/rag-retrieval-augmented-generation)\n\n63. Retrieval Augmented Generation (RAG): What It Is and How It Prevents\n    AI Errors, accessed April 18, 2025,\n    [[https://www.intersystems.com/resources/retrieval-augmented-generation/]{.underline}](https://www.intersystems.com/resources/retrieval-augmented-generation/)\n\n64. What is RAG? - Retrieval-Augmented Generation AI Explained - AWS,\n    accessed April 18, 2025,\n    [[https://aws.amazon.com/what-is/retrieval-augmented-generation/]{.underline}](https://aws.amazon.com/what-is/retrieval-augmented-generation/)\n\n65. What is Retrieval-Augmented Generation (RAG)? A Practical Guide -\n    K2view, accessed April 18, 2025,\n    [[https://www.k2view.com/what-is-retrieval-augmented-generation]{.underline}](https://www.k2view.com/what-is-retrieval-augmented-generation)\n\n66. Retrieval-Augmented Generation (RAG) Chatbots for Education: A\n    Survey of Applications, accessed April 18, 2025,\n    [[https://www.mdpi.com/2076-3417/15/8/4234]{.underline}](https://www.mdpi.com/2076-3417/15/8/4234)\n\n67. Retrieval Augmented Generation: Everything You Need to Know About\n    RAG in AI - WEKA, accessed April 18, 2025,\n    [[https://www.weka.io/learn/guide/ai-ml/retrieval-augmented-generation/]{.underline}](https://www.weka.io/learn/guide/ai-ml/retrieval-augmented-generation/)\n\n68. Retrieval Augmented Generation (RAG) for LLMs - Prompt Engineering\n    Guide, accessed April 18, 2025,\n    [[https://www.promptingguide.ai/research/rag]{.underline}](https://www.promptingguide.ai/research/rag)\n\n69. The Impact of Generative AI and RAG on Personalized Learning -\n    MAKEBOT.AI, accessed April 18, 2025,\n    [[https://www.makebot.ai/blog-en/the-impact-of-generative-ai-and-rag-on-personalized-learning]{.underline}](https://www.makebot.ai/blog-en/the-impact-of-generative-ai-and-rag-on-personalized-learning)\n\n70. \\[2311.17696\\] How to Build an Adaptive AI Tutor for Any Course\n    Using Knowledge Graph-Enhanced Retrieval-Augmented Generation\n    (KG-RAG) - arXiv, accessed April 18, 2025,\n    [[https://arxiv.org/abs/2311.17696]{.underline}](https://arxiv.org/abs/2311.17696)\n\n71. Your private LLM: deploying LLMs locally and offline using Ollama,\n    accessed April 18, 2025,\n    [[https://agathon.ai/insights/your-private-llm:-deploying-llms-locally-and-offline-using-ollama]{.underline}](https://agathon.ai/insights/your-private-llm:-deploying-llms-locally-and-offline-using-ollama)\n\n72. Ollama vs Hugging Face: Choosing the Right AI/ML Platform -\n    PromptLayer, accessed April 18, 2025,\n    [[https://blog.promptlayer.com/ollama-vs-huggingface/]{.underline}](https://blog.promptlayer.com/ollama-vs-huggingface/)\n\n73. The 6 Best LLM Tools To Run Models Locally - GetStream.io, accessed\n    April 18, 2025,\n    [[https://getstream.io/blog/best-local-llm-tools/]{.underline}](https://getstream.io/blog/best-local-llm-tools/)\n\n74. Ollama Tutorial: Run LLMs Locally - BytePlus, accessed April 18,\n    2025,\n    [[https://www.byteplus.com/en/topic/497086]{.underline}](https://www.byteplus.com/en/topic/497086)\n\n75. Deploy LLMs Locally Using Ollama: The Ultimate Guide to Local AI\n    Development - Apidog, accessed April 18, 2025,\n    [[https://apidog.com/blog/deploy-local-ai-llms/]{.underline}](https://apidog.com/blog/deploy-local-ai-llms/)\n\n76. Easy Setup for Local LLM with Llama Index and Ollama - QuickCreator,\n    accessed April 18, 2025,\n    [[https://quickcreator.io/quthor_blog/beginners-guide-setting-up-local-llm-ollama-llama-2/]{.underline}](https://quickcreator.io/quthor_blog/beginners-guide-setting-up-local-llm-ollama-llama-2/)\n\n77. Setting Up Ollama & Running DeepSeek R1 Locally for a Powerful RAG\n    System, accessed April 18, 2025,\n    [[https://dev.to/ajmal_hasan/setting-up-ollama-running-deepseek-r1-locally-for-a-powerful-rag-system-4pd4]{.underline}](https://dev.to/ajmal_hasan/setting-up-ollama-running-deepseek-r1-locally-for-a-powerful-rag-system-4pd4)\n\n78. Top 10 LLM tools to run models locally: A comprehensive guide for\n    2025 - BytePlus, accessed April 18, 2025,\n    [[https://www.byteplus.com/en/topic/398242]{.underline}](https://www.byteplus.com/en/topic/398242)\n\n79. What are the minimum hardware requirements to run an ollama model? -\n    Reddit, accessed April 18, 2025,\n    [[https://www.reddit.com/r/ollama/comments/1gwbl0k/what_are_the_minimum_hardware_requirements_to_run/]{.underline}](https://www.reddit.com/r/ollama/comments/1gwbl0k/what_are_the_minimum_hardware_requirements_to_run/)\n\n80. A Guide to Running LLMs Locally with No-Code Framework Dify,\n    accessed April 18, 2025,\n    [[https://adasci.org/a-guide-to-running-llms-locally-with-no-code-framework-dify/]{.underline}](https://adasci.org/a-guide-to-running-llms-locally-with-no-code-framework-dify/)\n\n81. Large language models for whole-learner support: opportunities and\n    challenges - Frontiers, accessed April 18, 2025,\n    [[https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1460364/full]{.underline}](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1460364/full)\n\n82. Superagency in the workplace: Empowering people to unlock AI\\'s full\n    potential - McKinsey, accessed April 18, 2025,\n    [[https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work]{.underline}](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)\n\n83. LLMs for Low Resource Languages in Multilingual, Multimodal and\n    Dialectal Settings, accessed April 18, 2025,\n    [[https://aclanthology.org/2024.eacl-tutorials.5/]{.underline}](https://aclanthology.org/2024.eacl-tutorials.5/)\n","numLines":1481,"startLine":1,"totalLines":1481}}}
{"parentUuid":"769ef15f-8fe6-4639-be3e-178ae94e035d","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01PzzWRGawzrnYTY5Ldm9cc7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Based on my analysis of your research leave proposal and the existing documentation in your repository, I can help you identify which sections are well-supported by your current research and which need additional development."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7964,"cache_creation_input_tokens":28956,"cache_read_input_tokens":16684,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnQ81vorNxMb1NQyy8r","type":"assistant","uuid":"852f9117-df9c-4eed-b548-067568c87b2a","timestamp":"2025-06-18T13:42:18.299Z"}
{"parentUuid":"852f9117-df9c-4eed-b548-067568c87b2a","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01PzzWRGawzrnYTY5Ldm9cc7","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Bx3DCqo2PnDLoH8eGT45o7","name":"exit_plan_mode","input":{"plan":"## Research Leave Proposal Analysis and Development Plan\n\n### Already Well-Supported Sections\n\n**✅ Project Description and Significance:**\n- **The Question/Problem:** Your literature review provides comprehensive background on LLM limitations in education and the need for pedagogically grounded AI tutors\n- **Technical Implementation:** Your technical plan details the RAG system architecture, fine-tuning methodologies, and Ollama deployment\n- **Field Significance:** Literature review demonstrates thorough understanding of current CALL research gaps\n\n**✅ Research Methods and Plan:**\n- **Technical Implementation:** Detailed architecture with Gemma 3 models, RAG pipeline, and local deployment strategy\n- **Demonstrable Competency:** STEP proposal shows prior technical planning and HPC collaboration experience\n\n**✅ Timeline and Deliverables:**\n- **Technical Timeline:** 8-week implementation phases clearly defined in technical plan\n- **Publication Strategy:** Target journals identified (Computer Assisted Language Learning, Language Learning & Technology)\n\n**✅ Funding and Resources:**\n- **Current Resources:** DEAC cluster infrastructure and HPC support documented\n- **Budget Considerations:** STEP proposal demonstrates cost-effective approach using open-source tools\n\n### Sections Needing Development\n\n**🔶 Project Description - Significance Subsections:**\n- **Significance for Wake Forest University:** Need specific examples of how this aligns with WFU's strategic priorities and educational technology initiatives\n- **Significance for Faculty Development:** Requires personal scholarly trajectory narrative and how this advances your research program\n\n**🔶 Research Methods and Plan:**\n- **Experimental Design:** Need detailed protocols for testing system effectiveness with students\n- **IRB Requirements:** Ethical considerations and human subjects research protocols\n- **Participant Recruitment:** Specific plans for student/instructor involvement\n\n**🔶 Justification for Leave Timing:**\n- **Research Momentum:** Need narrative connecting current preliminary work to leave necessity\n- **Field Competitiveness:** More specific positioning relative to competing research groups\n\n**🔶 Previous Leave Record:**\n- **Prior Sabbatical History:** Documentation of any previous leaves and their outcomes\n- **Scholarly Productivity Pattern:** Evidence of publication record justifying leave investment\n\n**🔶 Evaluation Frameworks:**\n- **Student Learning Assessment:** Specific metrics for measuring tutoring effectiveness\n- **Pedagogical Evaluation:** Detailed rubrics for assessing educational value\n\n### Development Tasks\n\n1. **Institutional Alignment Research:** Investigate WFU's educational technology strategic plan and recent initiatives\n2. **Personal Academic Narrative:** Develop scholarly trajectory statement linking computational linguistics to educational technology\n3. **Evaluation Framework Design:** Create specific assessment protocols for student learning outcomes\n4. **IRB Preparation:** Develop human subjects research protocols and ethical considerations\n5. **Competitive Analysis:** Research other institutions' similar initiatives for positioning context\n6. **Leave History Documentation:** Compile record of previous sabbaticals and their scholarly outcomes"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7964,"cache_creation_input_tokens":28956,"cache_read_input_tokens":16684,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnQ81vorNxMb1NQyy8r","type":"assistant","uuid":"22d1dbbe-926b-4c43-8b15-ab9e3526bc30","timestamp":"2025-06-18T13:42:37.608Z"}
{"parentUuid":"22d1dbbe-926b-4c43-8b15-ab9e3526bc30","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"User has approved your plan. You can now start coding.","tool_use_id":"toolu_01Bx3DCqo2PnDLoH8eGT45o7"}]},"uuid":"1b1d5c0f-e096-4456-9ecc-82d204f4946a","timestamp":"2025-06-18T13:44:06.607Z","toolUseResult":{"plan":"## Research Leave Proposal Analysis and Development Plan\n\n### Already Well-Supported Sections\n\n**✅ Project Description and Significance:**\n- **The Question/Problem:** Your literature review provides comprehensive background on LLM limitations in education and the need for pedagogically grounded AI tutors\n- **Technical Implementation:** Your technical plan details the RAG system architecture, fine-tuning methodologies, and Ollama deployment\n- **Field Significance:** Literature review demonstrates thorough understanding of current CALL research gaps\n\n**✅ Research Methods and Plan:**\n- **Technical Implementation:** Detailed architecture with Gemma 3 models, RAG pipeline, and local deployment strategy\n- **Demonstrable Competency:** STEP proposal shows prior technical planning and HPC collaboration experience\n\n**✅ Timeline and Deliverables:**\n- **Technical Timeline:** 8-week implementation phases clearly defined in technical plan\n- **Publication Strategy:** Target journals identified (Computer Assisted Language Learning, Language Learning & Technology)\n\n**✅ Funding and Resources:**\n- **Current Resources:** DEAC cluster infrastructure and HPC support documented\n- **Budget Considerations:** STEP proposal demonstrates cost-effective approach using open-source tools\n\n### Sections Needing Development\n\n**🔶 Project Description - Significance Subsections:**\n- **Significance for Wake Forest University:** Need specific examples of how this aligns with WFU's strategic priorities and educational technology initiatives\n- **Significance for Faculty Development:** Requires personal scholarly trajectory narrative and how this advances your research program\n\n**🔶 Research Methods and Plan:**\n- **Experimental Design:** Need detailed protocols for testing system effectiveness with students\n- **IRB Requirements:** Ethical considerations and human subjects research protocols\n- **Participant Recruitment:** Specific plans for student/instructor involvement\n\n**🔶 Justification for Leave Timing:**\n- **Research Momentum:** Need narrative connecting current preliminary work to leave necessity\n- **Field Competitiveness:** More specific positioning relative to competing research groups\n\n**🔶 Previous Leave Record:**\n- **Prior Sabbatical History:** Documentation of any previous leaves and their outcomes\n- **Scholarly Productivity Pattern:** Evidence of publication record justifying leave investment\n\n**🔶 Evaluation Frameworks:**\n- **Student Learning Assessment:** Specific metrics for measuring tutoring effectiveness\n- **Pedagogical Evaluation:** Detailed rubrics for assessing educational value\n\n### Development Tasks\n\n1. **Institutional Alignment Research:** Investigate WFU's educational technology strategic plan and recent initiatives\n2. **Personal Academic Narrative:** Develop scholarly trajectory statement linking computational linguistics to educational technology\n3. **Evaluation Framework Design:** Create specific assessment protocols for student learning outcomes\n4. **IRB Preparation:** Develop human subjects research protocols and ethical considerations\n5. **Competitive Analysis:** Research other institutions' similar initiatives for positioning context\n6. **Leave History Documentation:** Compile record of previous sabbaticals and their scholarly outcomes"}}
{"parentUuid":"1b1d5c0f-e096-4456-9ecc-82d204f4946a","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01JypLQdYchb2uTUnhMcDtKB","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_016EEbFmxFK8MRpugi4QTCSw","name":"TodoWrite","input":{"todos":[{"id":"analysis_complete","content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high"},{"id":"wfu_alignment","content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high"},{"id":"personal_narrative","content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high"},{"id":"evaluation_framework","content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high"},{"id":"irb_planning","content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium"},{"id":"timing_justification","content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium"},{"id":"leave_history","content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":8723,"cache_read_input_tokens":45640,"output_tokens":393,"service_tier":"standard"}},"requestId":"req_011CQFnYhzopyGMRNS1wtcEL","type":"assistant","uuid":"05afb7f3-2d16-46ba-8e6c-07e868a5e02c","timestamp":"2025-06-18T13:44:17.265Z"}
{"parentUuid":"05afb7f3-2d16-46ba-8e6c-07e868a5e02c","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016EEbFmxFK8MRpugi4QTCSw","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"c95ce84d-8fcb-4709-a988-bb5f83771975","timestamp":"2025-06-18T13:44:17.285Z","toolUseResult":{"oldTodos":[],"newTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}]}}
{"parentUuid":"c95ce84d-8fcb-4709-a988-bb5f83771975","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_0155w7n2ryQieJkbXvs3F4Mv","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Based on my analysis of your research leave proposal and existing documentation, here's what I found:\n\n## Well-Supported Sections ✅\n\nYour repository provides strong foundation for:\n\n**Project Description & Technical Approach** - Your literature review comprehensively covers LLM limitations in education and CALL research gaps. The technical plan details RAG architecture, Gemma 3 integration, and Ollama deployment strategy.\n\n**Research Methods** - Technical implementation is thoroughly documented with 8-week development phases, specific frameworks (Unsloth, RAG pipeline), and DEAC cluster deployment plans.\n\n**Timeline & Publication Strategy** - Clear implementation phases and target journals identified (Computer Assisted Language Learning, Language Learning & Technology).\n\n**Resources & Budget** - STEP proposal demonstrates cost-effective approach leveraging existing infrastructure.\n\n## Sections Needing Development 🔶\n\n**Significance for Wake Forest University** - Need specific alignment with WFU's strategic priorities and educational technology initiatives.\n\n**Faculty Development** - Requires personal scholarly trajectory narrative connecting computational linguistics to educational technology.\n\n**Experimental Design & IRB** - Missing detailed protocols for student testing, participant recruitment, and ethical considerations.\n\n**Leave Timing Justification** - Need stronger narrative connecting current work to leave necessity and competitive positioning.\n\n**Previous Leave Record** - Documentation of prior sabbaticals and scholarly productivity pattern.\n\n**Evaluation Frameworks** - Specific metrics for measuring student learning outcomes and pedagogical effectiveness.\n\nI've created a todo list to systematically address these gaps. Would you like me to start with any particular section, such as researching WFU's strategic priorities or developing the evaluation frameworks?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":609,"cache_read_input_tokens":54363,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnZWRZi7X1mPB9ThCj9","type":"assistant","uuid":"45603562-c139-47a7-8a40-4daa75f3cf9a","timestamp":"2025-06-18T13:44:29.951Z"}
{"parentUuid":"45603562-c139-47a7-8a40-4daa75f3cf9a","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"I would like you to now create a framework to keep my planning documents. Let's create a directory in the root of the project called `specs/`. Add this plan to the `specs/` directory so that we can refer back to it when necessary to keep our work on track."},"uuid":"fa5fd48f-73a3-4d7e-a83b-9f1772c7ca36","timestamp":"2025-06-18T13:46:06.092Z"}
{"parentUuid":"fa5fd48f-73a3-4d7e-a83b-9f1772c7ca36","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_017QAGbeXjd8ci786PxVc5jL","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01AQjQbnHH3stNDaWVd4B6ye","name":"TodoWrite","input":{"todos":[{"id":"analysis_complete","content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high"},{"id":"create_specs_dir","content":"Create specs/ directory and add research leave proposal analysis","status":"in_progress","priority":"high"},{"id":"wfu_alignment","content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high"},{"id":"personal_narrative","content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high"},{"id":"evaluation_framework","content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high"},{"id":"irb_planning","content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium"},{"id":"timing_justification","content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium"},{"id":"leave_history","content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":426,"cache_read_input_tokens":54972,"output_tokens":340,"service_tier":"standard"}},"requestId":"req_011CQFnhWqbQUiWAhzzuacKs","type":"assistant","uuid":"b311e1cd-2a5d-42f1-a9c9-b871c2882b59","timestamp":"2025-06-18T13:46:16.066Z"}
{"parentUuid":"b311e1cd-2a5d-42f1-a9c9-b871c2882b59","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AQjQbnHH3stNDaWVd4B6ye","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"9e0d304a-def1-4151-b192-59e9d25a04f7","timestamp":"2025-06-18T13:46:16.087Z","toolUseResult":{"oldTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}],"newTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"in_progress","priority":"high","id":"create_specs_dir"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}]}}
{"parentUuid":"9e0d304a-def1-4151-b192-59e9d25a04f7","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01CcQBYvx1bTzVgwxx4Pp3S5","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_015DPDSBue34AsCy96KZTPZv","name":"Bash","input":{"command":"mkdir -p specs","description":"Create specs directory for planning documents"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":679,"cache_read_input_tokens":55398,"output_tokens":27,"service_tier":"standard"}},"requestId":"req_011CQFniFbM56sDX8VbF5TMg","type":"assistant","uuid":"ea71ee69-3fc4-41ef-89fb-3f93931a6cfa","timestamp":"2025-06-18T13:46:19.963Z"}
{"parentUuid":"ea71ee69-3fc4-41ef-89fb-3f93931a6cfa","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015DPDSBue34AsCy96KZTPZv","type":"tool_result","content":"","is_error":false}]},"uuid":"3ec58534-48e2-4083-8c65-1b3c285fd2c3","timestamp":"2025-06-18T13:46:20.041Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"3ec58534-48e2-4083-8c65-1b3c285fd2c3","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_011XwcLyp3kPuL4W1iDtJ6fD","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_014Kr9LgoN68wf5cqwE4yYqM","name":"Write","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/specs/research_leave_analysis.md","content":"# Research Leave Proposal Development Analysis\n\n**Document Type:** Planning Framework  \n**Created:** December 18, 2024  \n**Purpose:** Track progress on research leave proposal development for ITS4LL project\n\n## Executive Summary\n\nThis analysis identifies which sections of the research leave proposal are well-supported by existing repository documentation and which require additional development. The proposal leverages substantial existing research (literature review, technical plan, STEP grant) but needs enhancement in institutional alignment, personal narrative, and evaluation frameworks.\n\n## Current Repository Assets\n\n### Strong Foundation Documents\n- **Literature Review** (`docs/literature/literature_review.qmd`) - Comprehensive 1,400+ line analysis\n- **Technical Plan** (`docs/research/technical-plan.qmd`) - Detailed implementation roadmap\n- **STEP Proposal** (`docs/grants/step_proposal.qmd`) - Proof of technical feasibility\n- **Project Overview** (`index.qmd`) - Clear project vision and architecture\n\n## Section-by-Section Analysis\n\n### ✅ Well-Supported Sections\n\n#### Project Description and Significance\n- **The Question/Problem** ✅\n  - Literature review provides comprehensive background on LLM limitations in CALL\n  - Clear articulation of pedagogical gaps in current AI tutoring systems\n  - Evidence-based positioning of research needs\n\n- **Technical Implementation** ✅\n  - Detailed RAG system architecture with Gemma 3 models\n  - Fine-tuning methodologies thoroughly documented\n  - Local deployment strategy with Ollama clearly specified\n\n- **Field Significance** ✅\n  - Thorough analysis of current CALL research landscape\n  - Identification of specific gaps in existing literature\n  - Clear positioning relative to competing approaches\n\n#### Research Methods and Plan\n- **Technical Implementation** ✅\n  - 8-week implementation phases with specific deliverables\n  - Clear technology stack (Python, FastAPI, ChromaDB/Qdrant)\n  - Resource requirements and DEAC cluster integration plan\n\n- **Demonstrable Competency** ✅\n  - STEP proposal demonstrates technical planning ability\n  - HPC collaboration experience documented\n  - Open-source approach shows technical sophistication\n\n#### Timeline and Deliverables\n- **Academic Year Schedule** ✅\n  - Fall 2027: System development and pilot testing\n  - Spring 2028: Scaled testing and manuscript preparation\n  - Clear milestone progression from prototype to publication\n\n- **Publication Strategy** ✅\n  - Target journals identified with impact considerations\n  - Conference presentation plans (CALICO, EUROCALL)\n  - Open-source code release commitment\n\n#### Funding and Resources\n- **Current Resources** ✅\n  - DEAC cluster infrastructure documented\n  - HPC Systems Administrator support confirmed\n  - Open-source tools minimize licensing costs\n\n- **Budget Approach** ✅\n  - STEP proposal demonstrates cost-effective methodology\n  - Leverage existing institutional resources\n  - No external API dependencies reduce ongoing costs\n\n### 🔶 Sections Needing Development\n\n#### Project Description - Institutional Significance\n- **Significance for Wake Forest University** 🔶\n  - **Missing:** Specific alignment with WFU strategic priorities\n  - **Missing:** Connection to university's educational technology initiatives\n  - **Missing:** Examples of how project enhances WFU's research reputation\n  - **Action:** Research WFU's Pro Humanitate mission alignment\n  - **Action:** Investigate recent educational technology investments\n\n- **Significance for Faculty Development** 🔶\n  - **Missing:** Personal scholarly trajectory narrative\n  - **Missing:** Connection between computational linguistics and educational technology\n  - **Missing:** Career advancement rationale\n  - **Action:** Develop research program evolution story\n  - **Action:** Connect to tenure/promotion goals\n\n#### Research Methods - Human Subjects Components\n- **Experimental Design** 🔶\n  - **Missing:** Detailed protocols for student effectiveness testing\n  - **Missing:** Control group methodology\n  - **Missing:** Quantitative and qualitative assessment methods\n  - **Action:** Design pre/post assessment protocols\n  - **Action:** Develop user experience evaluation framework\n\n- **IRB Requirements** 🔶\n  - **Missing:** Ethical considerations for student data\n  - **Missing:** Informed consent protocols\n  - **Missing:** Data privacy safeguards beyond technical measures\n  - **Action:** Draft IRB application materials\n  - **Action:** Develop data governance policies\n\n- **Participant Recruitment** 🔶\n  - **Missing:** Specific plans for student/instructor involvement\n  - **Missing:** Selection criteria and sample size justification\n  - **Action:** Design recruitment strategy\n  - **Action:** Establish partnership with language department\n\n#### Justification for Leave Timing\n- **Research Momentum** 🔶\n  - **Missing:** Narrative connecting preliminary work to leave necessity\n  - **Missing:** Explanation of why current foundation requires dedicated time\n  - **Action:** Document current project status and next-phase requirements\n  - **Action:** Articulate why part-time development is insufficient\n\n- **Field Competitiveness** 🔶\n  - **Missing:** Specific positioning relative to competing research groups\n  - **Missing:** Urgency argument for 2027-2028 timeframe\n  - **Action:** Research competing initiatives in CALL/AI education\n  - **Action:** Establish timeline for field advancement\n\n#### Previous Leave Record\n- **Prior Sabbatical History** 🔶\n  - **Missing:** Documentation of any previous leaves and outcomes\n  - **Missing:** Publications resulting from previous sabbaticals\n  - **Action:** Compile sabbatical history\n  - **Action:** Document scholarly productivity from previous leaves\n\n- **Scholarly Productivity Pattern** 🔶\n  - **Missing:** Evidence of publication record justifying leave investment\n  - **Missing:** Demonstration of productive use of uninterrupted time\n  - **Action:** Analyze publication patterns and research output\n  - **Action:** Create productivity trajectory narrative\n\n#### Evaluation and Assessment\n- **Student Learning Assessment** 🔶\n  - **Missing:** Specific metrics for measuring tutoring effectiveness\n  - **Missing:** Pre/post assessment protocols\n  - **Missing:** Long-term learning outcome measures\n  - **Action:** Design comprehensive evaluation framework\n  - **Action:** Establish baseline measurement protocols\n\n- **Pedagogical Evaluation** 🔶\n  - **Missing:** Detailed rubrics for assessing educational value\n  - **Missing:** Expert review protocols for content quality\n  - **Action:** Develop pedagogical assessment criteria\n  - **Action:** Establish educator evaluation panels\n\n## Development Priority Matrix\n\n### High Priority (Essential for Proposal)\n1. **WFU Strategic Alignment** - Required for institutional significance\n2. **Faculty Development Narrative** - Core justification for sabbatical\n3. **Evaluation Framework** - Demonstrates scholarly rigor\n4. **Research Momentum Narrative** - Justifies timing necessity\n\n### Medium Priority (Strengthens Proposal)\n5. **IRB Planning** - Shows preparedness for human subjects research\n6. **Competitive Analysis** - Positions work in field context\n7. **Leave Productivity History** - Establishes track record\n\n### Implementation Timeline\n\n#### Phase 1: Foundation (Week 1)\n- Research WFU strategic priorities and educational technology initiatives\n- Draft personal scholarly trajectory narrative\n- Design preliminary evaluation frameworks\n\n#### Phase 2: Methods (Week 2)\n- Develop detailed experimental design protocols\n- Create IRB planning documents\n- Establish participant recruitment strategy\n\n#### Phase 3: Positioning (Week 3)\n- Strengthen timing justification with momentum narrative\n- Conduct competitive field analysis\n- Document leave history and productivity patterns\n\n#### Phase 4: Integration (Week 4)\n- Integrate new content into proposal sections\n- Ensure narrative coherence across all sections\n- Final review and refinement\n\n## Success Metrics for Proposal Development\n\n### Content Completeness\n- [ ] All proposal sections have substantial content\n- [ ] Institutional alignment clearly articulated\n- [ ] Personal development narrative compelling\n- [ ] Evaluation frameworks rigorous and specific\n\n### Narrative Coherence\n- [ ] Clear connection between preliminary work and leave necessity\n- [ ] Consistent positioning throughout proposal\n- [ ] Strong rationale for timing and resource allocation\n\n### Supporting Evidence\n- [ ] All claims supported by documentation or research\n- [ ] Competitive analysis demonstrates field knowledge\n- [ ] Previous productivity patterns support investment case\n\n## Next Steps\n\n1. **Begin High Priority Items** - Start with WFU alignment research\n2. **Establish Working Documents** - Create drafts for each missing section\n3. **Schedule Regular Reviews** - Weekly progress checks against this framework\n4. **Maintain Version Control** - Track iterations and improvements\n\n---\n\n*This analysis serves as the master planning document for research leave proposal development. Update regularly as work progresses and new requirements emerge.*"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":102,"cache_read_input_tokens":56077,"output_tokens":2093,"service_tier":"standard"}},"requestId":"req_011CQFniY7Go2jcdYdD8c3RT","type":"assistant","uuid":"9e927a5a-f148-459e-a7b0-6cce967b645c","timestamp":"2025-06-18T13:47:14.870Z"}
{"parentUuid":"9e927a5a-f148-459e-a7b0-6cce967b645c","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014Kr9LgoN68wf5cqwE4yYqM","type":"tool_result","content":"File created successfully at: /Users/francojc/Documents/GitHub/francojc/its/specs/research_leave_analysis.md"}]},"uuid":"8bce0d58-3ded-4f2c-8f47-ac60815d7ad5","timestamp":"2025-06-18T13:47:14.910Z","toolUseResult":{"type":"create","filePath":"/Users/francojc/Documents/GitHub/francojc/its/specs/research_leave_analysis.md","content":"# Research Leave Proposal Development Analysis\n\n**Document Type:** Planning Framework  \n**Created:** December 18, 2024  \n**Purpose:** Track progress on research leave proposal development for ITS4LL project\n\n## Executive Summary\n\nThis analysis identifies which sections of the research leave proposal are well-supported by existing repository documentation and which require additional development. The proposal leverages substantial existing research (literature review, technical plan, STEP grant) but needs enhancement in institutional alignment, personal narrative, and evaluation frameworks.\n\n## Current Repository Assets\n\n### Strong Foundation Documents\n- **Literature Review** (`docs/literature/literature_review.qmd`) - Comprehensive 1,400+ line analysis\n- **Technical Plan** (`docs/research/technical-plan.qmd`) - Detailed implementation roadmap\n- **STEP Proposal** (`docs/grants/step_proposal.qmd`) - Proof of technical feasibility\n- **Project Overview** (`index.qmd`) - Clear project vision and architecture\n\n## Section-by-Section Analysis\n\n### ✅ Well-Supported Sections\n\n#### Project Description and Significance\n- **The Question/Problem** ✅\n  - Literature review provides comprehensive background on LLM limitations in CALL\n  - Clear articulation of pedagogical gaps in current AI tutoring systems\n  - Evidence-based positioning of research needs\n\n- **Technical Implementation** ✅\n  - Detailed RAG system architecture with Gemma 3 models\n  - Fine-tuning methodologies thoroughly documented\n  - Local deployment strategy with Ollama clearly specified\n\n- **Field Significance** ✅\n  - Thorough analysis of current CALL research landscape\n  - Identification of specific gaps in existing literature\n  - Clear positioning relative to competing approaches\n\n#### Research Methods and Plan\n- **Technical Implementation** ✅\n  - 8-week implementation phases with specific deliverables\n  - Clear technology stack (Python, FastAPI, ChromaDB/Qdrant)\n  - Resource requirements and DEAC cluster integration plan\n\n- **Demonstrable Competency** ✅\n  - STEP proposal demonstrates technical planning ability\n  - HPC collaboration experience documented\n  - Open-source approach shows technical sophistication\n\n#### Timeline and Deliverables\n- **Academic Year Schedule** ✅\n  - Fall 2027: System development and pilot testing\n  - Spring 2028: Scaled testing and manuscript preparation\n  - Clear milestone progression from prototype to publication\n\n- **Publication Strategy** ✅\n  - Target journals identified with impact considerations\n  - Conference presentation plans (CALICO, EUROCALL)\n  - Open-source code release commitment\n\n#### Funding and Resources\n- **Current Resources** ✅\n  - DEAC cluster infrastructure documented\n  - HPC Systems Administrator support confirmed\n  - Open-source tools minimize licensing costs\n\n- **Budget Approach** ✅\n  - STEP proposal demonstrates cost-effective methodology\n  - Leverage existing institutional resources\n  - No external API dependencies reduce ongoing costs\n\n### 🔶 Sections Needing Development\n\n#### Project Description - Institutional Significance\n- **Significance for Wake Forest University** 🔶\n  - **Missing:** Specific alignment with WFU strategic priorities\n  - **Missing:** Connection to university's educational technology initiatives\n  - **Missing:** Examples of how project enhances WFU's research reputation\n  - **Action:** Research WFU's Pro Humanitate mission alignment\n  - **Action:** Investigate recent educational technology investments\n\n- **Significance for Faculty Development** 🔶\n  - **Missing:** Personal scholarly trajectory narrative\n  - **Missing:** Connection between computational linguistics and educational technology\n  - **Missing:** Career advancement rationale\n  - **Action:** Develop research program evolution story\n  - **Action:** Connect to tenure/promotion goals\n\n#### Research Methods - Human Subjects Components\n- **Experimental Design** 🔶\n  - **Missing:** Detailed protocols for student effectiveness testing\n  - **Missing:** Control group methodology\n  - **Missing:** Quantitative and qualitative assessment methods\n  - **Action:** Design pre/post assessment protocols\n  - **Action:** Develop user experience evaluation framework\n\n- **IRB Requirements** 🔶\n  - **Missing:** Ethical considerations for student data\n  - **Missing:** Informed consent protocols\n  - **Missing:** Data privacy safeguards beyond technical measures\n  - **Action:** Draft IRB application materials\n  - **Action:** Develop data governance policies\n\n- **Participant Recruitment** 🔶\n  - **Missing:** Specific plans for student/instructor involvement\n  - **Missing:** Selection criteria and sample size justification\n  - **Action:** Design recruitment strategy\n  - **Action:** Establish partnership with language department\n\n#### Justification for Leave Timing\n- **Research Momentum** 🔶\n  - **Missing:** Narrative connecting preliminary work to leave necessity\n  - **Missing:** Explanation of why current foundation requires dedicated time\n  - **Action:** Document current project status and next-phase requirements\n  - **Action:** Articulate why part-time development is insufficient\n\n- **Field Competitiveness** 🔶\n  - **Missing:** Specific positioning relative to competing research groups\n  - **Missing:** Urgency argument for 2027-2028 timeframe\n  - **Action:** Research competing initiatives in CALL/AI education\n  - **Action:** Establish timeline for field advancement\n\n#### Previous Leave Record\n- **Prior Sabbatical History** 🔶\n  - **Missing:** Documentation of any previous leaves and outcomes\n  - **Missing:** Publications resulting from previous sabbaticals\n  - **Action:** Compile sabbatical history\n  - **Action:** Document scholarly productivity from previous leaves\n\n- **Scholarly Productivity Pattern** 🔶\n  - **Missing:** Evidence of publication record justifying leave investment\n  - **Missing:** Demonstration of productive use of uninterrupted time\n  - **Action:** Analyze publication patterns and research output\n  - **Action:** Create productivity trajectory narrative\n\n#### Evaluation and Assessment\n- **Student Learning Assessment** 🔶\n  - **Missing:** Specific metrics for measuring tutoring effectiveness\n  - **Missing:** Pre/post assessment protocols\n  - **Missing:** Long-term learning outcome measures\n  - **Action:** Design comprehensive evaluation framework\n  - **Action:** Establish baseline measurement protocols\n\n- **Pedagogical Evaluation** 🔶\n  - **Missing:** Detailed rubrics for assessing educational value\n  - **Missing:** Expert review protocols for content quality\n  - **Action:** Develop pedagogical assessment criteria\n  - **Action:** Establish educator evaluation panels\n\n## Development Priority Matrix\n\n### High Priority (Essential for Proposal)\n1. **WFU Strategic Alignment** - Required for institutional significance\n2. **Faculty Development Narrative** - Core justification for sabbatical\n3. **Evaluation Framework** - Demonstrates scholarly rigor\n4. **Research Momentum Narrative** - Justifies timing necessity\n\n### Medium Priority (Strengthens Proposal)\n5. **IRB Planning** - Shows preparedness for human subjects research\n6. **Competitive Analysis** - Positions work in field context\n7. **Leave Productivity History** - Establishes track record\n\n### Implementation Timeline\n\n#### Phase 1: Foundation (Week 1)\n- Research WFU strategic priorities and educational technology initiatives\n- Draft personal scholarly trajectory narrative\n- Design preliminary evaluation frameworks\n\n#### Phase 2: Methods (Week 2)\n- Develop detailed experimental design protocols\n- Create IRB planning documents\n- Establish participant recruitment strategy\n\n#### Phase 3: Positioning (Week 3)\n- Strengthen timing justification with momentum narrative\n- Conduct competitive field analysis\n- Document leave history and productivity patterns\n\n#### Phase 4: Integration (Week 4)\n- Integrate new content into proposal sections\n- Ensure narrative coherence across all sections\n- Final review and refinement\n\n## Success Metrics for Proposal Development\n\n### Content Completeness\n- [ ] All proposal sections have substantial content\n- [ ] Institutional alignment clearly articulated\n- [ ] Personal development narrative compelling\n- [ ] Evaluation frameworks rigorous and specific\n\n### Narrative Coherence\n- [ ] Clear connection between preliminary work and leave necessity\n- [ ] Consistent positioning throughout proposal\n- [ ] Strong rationale for timing and resource allocation\n\n### Supporting Evidence\n- [ ] All claims supported by documentation or research\n- [ ] Competitive analysis demonstrates field knowledge\n- [ ] Previous productivity patterns support investment case\n\n## Next Steps\n\n1. **Begin High Priority Items** - Start with WFU alignment research\n2. **Establish Working Documents** - Create drafts for each missing section\n3. **Schedule Regular Reviews** - Weekly progress checks against this framework\n4. **Maintain Version Control** - Track iterations and improvements\n\n---\n\n*This analysis serves as the master planning document for research leave proposal development. Update regularly as work progresses and new requirements emerge.*","structuredPatch":[]}}
{"parentUuid":"8bce0d58-3ded-4f2c-8f47-ac60815d7ad5","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01NuTPUJjnSLTUS75AVT27qE","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Q1ejasbAuR6CaoVuMx4KHR","name":"Write","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/specs/README.md","content":"# ITS4LL Project Specifications\n\nThis directory contains planning documents, frameworks, and specifications for the ITS4LL project development.\n\n## Directory Purpose\n\nThe `specs/` directory serves as a centralized location for:\n- Project planning documents\n- Development frameworks\n- Progress tracking specifications\n- Analysis and strategic planning materials\n\n## Current Documents\n\n### Planning & Analysis\n- **[research_leave_analysis.md](research_leave_analysis.md)** - Comprehensive analysis of research leave proposal sections, identifying well-supported areas and development needs\n\n## Document Categories\n\n### 📋 Planning Documents\nStrategic planning, requirement analysis, and project roadmaps\n\n### 📊 Progress Tracking\nStatus updates, milestone tracking, and development progress\n\n### 🔍 Analysis Reports\nResearch analysis, gap identification, and strategic recommendations\n\n### 📝 Specifications\nTechnical specifications, design documents, and implementation guidelines\n\n## Usage Guidelines\n\n1. **Version Control** - All specifications are version controlled with the main repository\n2. **Regular Updates** - Documents should be updated as project requirements evolve\n3. **Cross-References** - Link to relevant code, documentation, and research materials\n4. **Status Tracking** - Maintain current status and completion indicators\n\n## Contributing\n\nWhen adding new specification documents:\n- Use clear, descriptive filenames\n- Include document metadata (purpose, created date, status)\n- Update this README with new document descriptions\n- Follow markdown formatting standards for consistency\n\n---\n\n*This directory supports the systematic development of the ITS4LL project by maintaining clear planning documentation and progress tracking.*"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":2136,"cache_read_input_tokens":56179,"output_tokens":437,"service_tier":"standard"}},"requestId":"req_011CQFnnatKLcagZejfC5KYg","type":"assistant","uuid":"0467de9e-9d4b-4697-abf3-2dd5570a87a0","timestamp":"2025-06-18T13:47:29.987Z"}
{"parentUuid":"0467de9e-9d4b-4697-abf3-2dd5570a87a0","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q1ejasbAuR6CaoVuMx4KHR","type":"tool_result","content":"File created successfully at: /Users/francojc/Documents/GitHub/francojc/its/specs/README.md"}]},"uuid":"cb5e6969-b54c-44b8-a467-68249143389f","timestamp":"2025-06-18T13:47:30.012Z","toolUseResult":{"type":"create","filePath":"/Users/francojc/Documents/GitHub/francojc/its/specs/README.md","content":"# ITS4LL Project Specifications\n\nThis directory contains planning documents, frameworks, and specifications for the ITS4LL project development.\n\n## Directory Purpose\n\nThe `specs/` directory serves as a centralized location for:\n- Project planning documents\n- Development frameworks\n- Progress tracking specifications\n- Analysis and strategic planning materials\n\n## Current Documents\n\n### Planning & Analysis\n- **[research_leave_analysis.md](research_leave_analysis.md)** - Comprehensive analysis of research leave proposal sections, identifying well-supported areas and development needs\n\n## Document Categories\n\n### 📋 Planning Documents\nStrategic planning, requirement analysis, and project roadmaps\n\n### 📊 Progress Tracking\nStatus updates, milestone tracking, and development progress\n\n### 🔍 Analysis Reports\nResearch analysis, gap identification, and strategic recommendations\n\n### 📝 Specifications\nTechnical specifications, design documents, and implementation guidelines\n\n## Usage Guidelines\n\n1. **Version Control** - All specifications are version controlled with the main repository\n2. **Regular Updates** - Documents should be updated as project requirements evolve\n3. **Cross-References** - Link to relevant code, documentation, and research materials\n4. **Status Tracking** - Maintain current status and completion indicators\n\n## Contributing\n\nWhen adding new specification documents:\n- Use clear, descriptive filenames\n- Include document metadata (purpose, created date, status)\n- Update this README with new document descriptions\n- Follow markdown formatting standards for consistency\n\n---\n\n*This directory supports the systematic development of the ITS4LL project by maintaining clear planning documentation and progress tracking.*","structuredPatch":[]}}
{"parentUuid":"cb5e6969-b54c-44b8-a467-68249143389f","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01YF7b2TCNmCyK3ea8tepcZX","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_013wjNxR56Xwrfnm5Qj5uj46","name":"TodoWrite","input":{"todos":[{"id":"analysis_complete","content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high"},{"id":"create_specs_dir","content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high"},{"id":"wfu_alignment","content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high"},{"id":"personal_narrative","content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high"},{"id":"evaluation_framework","content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high"},{"id":"irb_planning","content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium"},{"id":"timing_justification","content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium"},{"id":"leave_history","content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium"}]}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":476,"cache_read_input_tokens":58315,"output_tokens":338,"service_tier":"standard"}},"requestId":"req_011CQFnohdeWxYDRs9SACSr4","type":"assistant","uuid":"327ef1eb-2b04-408a-a109-f057e06f8e1c","timestamp":"2025-06-18T13:47:38.815Z"}
{"parentUuid":"327ef1eb-2b04-408a-a109-f057e06f8e1c","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013wjNxR56Xwrfnm5Qj5uj46","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"c93d038b-9672-45f2-b664-bfc887996906","timestamp":"2025-06-18T13:47:38.835Z","toolUseResult":{"oldTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"in_progress","priority":"high","id":"create_specs_dir"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}],"newTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high","id":"create_specs_dir"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}]}}
{"parentUuid":"c93d038b-9672-45f2-b664-bfc887996906","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01H56zA5uRNr2srVcUkfVjks","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Perfect! I've created the `specs/` directory and added your comprehensive research leave proposal analysis. Here's what I've established:\n\n## Created Framework Structure\n\n**`specs/README.md`** - Directory overview explaining the purpose and organization of planning documents\n\n**`specs/research_leave_analysis.md`** - Detailed analysis including:\n- Executive summary of proposal status\n- Section-by-section analysis (✅ well-supported vs 🔶 needs development)\n- Priority matrix for development tasks\n- 4-week implementation timeline\n- Success metrics and next steps\n\n## Key Benefits of This Framework\n\n**Centralized Planning** - All strategic documents in one location\n**Progress Tracking** - Clear status indicators and completion metrics\n**Version Control** - All planning documents tracked with your code\n**Cross-Reference Capability** - Easy linking between specs and implementation\n\nThe analysis document serves as your master planning guide, identifying that you have strong foundation in technical implementation, literature review, and resource planning, but need to develop institutional alignment, personal narrative, and evaluation frameworks.\n\nYou can now reference `specs/research_leave_analysis.md` to stay on track as we work through the remaining high-priority items like researching WFU's strategic priorities and developing your faculty development narrative."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":677,"cache_read_input_tokens":58791,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFnpLzhXopHh4xZiQjNA","type":"assistant","uuid":"7ac554b4-1013-4e10-b376-920c0f9e68bd","timestamp":"2025-06-18T13:47:48.922Z"}
{"parentUuid":"7ac554b4-1013-4e10-b376-920c0f9e68bd","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"Questions about claude code: how can I ask you to work with my Git repo and GitHub effectively to maintain this project and create key documentation and roll-back points along the way?"},"uuid":"9ccf7ceb-808b-4f12-a017-456e3183e8ec","timestamp":"2025-06-18T13:49:48.699Z"}
{"parentUuid":"9ccf7ceb-808b-4f12-a017-456e3183e8ec","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01KVQ38pn8BtK3ve9KmpPmWs","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"I'll help you understand how to work effectively with Git and GitHub using Claude Code for your ITS4LL project. Let me gather information about Claude Code's Git capabilities."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":471,"cache_read_input_tokens":59468,"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CQFnyvHSCkV1MZpryAgRA","type":"assistant","uuid":"5ca7103e-a885-4b7d-b9f0-27404ec60063","timestamp":"2025-06-18T13:49:54.571Z"}
{"parentUuid":"5ca7103e-a885-4b7d-b9f0-27404ec60063","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01KVQ38pn8BtK3ve9KmpPmWs","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01WbBnzisW8w14eGg7nwBvkR","name":"WebFetch","input":{"url":"https://docs.anthropic.com/en/docs/claude-code/cli-usage","prompt":"What are Claude Code's Git and GitHub capabilities? How can users work with repositories, create commits, manage branches, and handle documentation workflows?"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":471,"cache_read_input_tokens":59468,"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CQFnyvHSCkV1MZpryAgRA","type":"assistant","uuid":"57c75e52-62d0-47d7-a8b8-e7851cefe8eb","timestamp":"2025-06-18T13:49:55.900Z"}
{"parentUuid":"57c75e52-62d0-47d7-a8b8-e7851cefe8eb","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WbBnzisW8w14eGg7nwBvkR","type":"tool_result","content":"Based on the provided documentation, there are no specific details about Claude Code's Git and GitHub capabilities. The content includes a CLI reference and general documentation, but does not elaborate on Git-specific features or repository management workflows. \n\nThe only Git-related reference is a brief mention in the CLI flags section, which shows an example of allowed tools like `\"Bash(git log:*)\" \"Bash(git diff:*)\"`, suggesting some basic Git command support might exist, but no comprehensive details are provided in this document.\n\nFor precise information about Claude Code's Git and GitHub capabilities, I recommend consulting the full Claude Code documentation or contacting Anthropic support directly."}]},"uuid":"10ecc216-2f15-4b6c-877f-eb2166c86a86","timestamp":"2025-06-18T13:50:12.790Z","toolUseResult":{"bytes":2015708,"code":200,"codeText":"OK","result":"Based on the provided documentation, there are no specific details about Claude Code's Git and GitHub capabilities. The content includes a CLI reference and general documentation, but does not elaborate on Git-specific features or repository management workflows. \n\nThe only Git-related reference is a brief mention in the CLI flags section, which shows an example of allowed tools like `\"Bash(git log:*)\" \"Bash(git diff:*)\"`, suggesting some basic Git command support might exist, but no comprehensive details are provided in this document.\n\nFor precise information about Claude Code's Git and GitHub capabilities, I recommend consulting the full Claude Code documentation or contacting Anthropic support directly.","durationMs":8344,"url":"https://docs.anthropic.com/en/docs/claude-code/cli-usage"}}
{"parentUuid":"10ecc216-2f15-4b6c-877f-eb2166c86a86","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01KaiUgg1mM3oEmFii7gdC9b","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_011CYSQrV6mBjWdiVocoek6h","name":"Bash","input":{"command":"git status","description":"Check current Git status to understand repository state"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":452,"cache_read_input_tokens":59939,"output_tokens":30,"service_tier":"standard"}},"requestId":"req_011CQFo1hv6cb9nHEZdgNm7e","type":"assistant","uuid":"b3ab6bf9-a166-4379-96e9-6cffbfe83804","timestamp":"2025-06-18T13:50:18.150Z"}
{"parentUuid":"b3ab6bf9-a166-4379-96e9-6cffbfe83804","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011CYSQrV6mBjWdiVocoek6h","type":"tool_result","content":"On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   docs/grants/research_leave.qmd\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tspecs/\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")","is_error":false}]},"uuid":"52dd5c33-f2bb-40e1-a13d-bc0617ab33dd","timestamp":"2025-06-18T13:50:18.242Z","toolUseResult":{"stdout":"On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   docs/grants/research_leave.qmd\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tspecs/\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"52dd5c33-f2bb-40e1-a13d-bc0617ab33dd","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_011J4tAzjderqPScJ6r9o1RK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01WriYHaKi38ubrSo4auDBqG","name":"Bash","input":{"command":"git log --oneline -5","description":"Check recent commit history to understand project progression"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":367,"cache_read_input_tokens":60391,"output_tokens":36,"service_tier":"standard"}},"requestId":"req_011CQFo26PTc1AGuhaNS1fiq","type":"assistant","uuid":"d8c4b107-caed-4b59-840a-e9ca4163df79","timestamp":"2025-06-18T13:50:24.011Z"}
{"parentUuid":"d8c4b107-caed-4b59-840a-e9ca4163df79","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WriYHaKi38ubrSo4auDBqG","type":"tool_result","content":"9552596 docs: Enhance research leave documentation with project details and alignment.\n806feec feat: Add research leave proposal for ITS4LL project\ncf7298f refactor: update CLAUDE.md with detailed file path guidelines\n30cac17 Okay, here's a concise one-line commit message based on the provided literature review and discussion:\ne8b6d6f feat: Implement RAG system with Gemma 3 for ITS4LL language tutoring","is_error":false}]},"uuid":"8a7d104c-7118-436b-8e3b-d09803cc50aa","timestamp":"2025-06-18T13:50:24.095Z","toolUseResult":{"stdout":"9552596 docs: Enhance research leave documentation with project details and alignment.\n806feec feat: Add research leave proposal for ITS4LL project\ncf7298f refactor: update CLAUDE.md with detailed file path guidelines\n30cac17 Okay, here's a concise one-line commit message based on the provided literature review and discussion:\ne8b6d6f feat: Implement RAG system with Gemma 3 for ITS4LL language tutoring","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"8a7d104c-7118-436b-8e3b-d09803cc50aa","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01MP15aGq3NTXZ9uttchpXDh","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01LX4hvoZ5Cr5peKdSoYLM6v","name":"Bash","input":{"command":"gh --version","description":"Check if GitHub CLI is available for repository management"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":356,"cache_read_input_tokens":60758,"output_tokens":36,"service_tier":"standard"}},"requestId":"req_011CQFo2XBiLV7SSnKABxHNj","type":"assistant","uuid":"192cd8c9-9309-47e0-a4d5-71cb99f782e9","timestamp":"2025-06-18T13:50:28.674Z"}
{"parentUuid":"192cd8c9-9309-47e0-a4d5-71cb99f782e9","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LX4hvoZ5Cr5peKdSoYLM6v","type":"tool_result","content":"gh version 2.74.1 (nixpkgs)\nhttps://github.com/cli/cli/releases/tag/v2.74.1","is_error":false}]},"uuid":"7160986f-3f13-453b-bfe7-1dbc6a007b3d","timestamp":"2025-06-18T13:50:38.246Z","toolUseResult":{"stdout":"gh version 2.74.1 (nixpkgs)\nhttps://github.com/cli/cli/releases/tag/v2.74.1","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"7160986f-3f13-453b-bfe7-1dbc6a007b3d","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_017NeBPVNAwJtr5gGhiSuzWB","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01ReVrvwWTPHHPbX8SVghpoK","name":"exit_plan_mode","input":{"plan":"## Git and GitHub Workflow Plan for ITS4LL Project\n\n### Claude Code's Git Capabilities\n\n**✅ Full Git Support:**\n- Complete Git command access through Bash tool\n- Automatic commit message generation with attribution\n- Branch management and merging capabilities\n- GitHub CLI integration for PR/issue management\n\n**✅ Current Repository Status:**\n- Active branch: main, up to date with origin\n- Recent commits show good documentation practices\n- Untracked specs/ directory ready for initial commit\n- Modified research_leave.qmd needs staging\n\n### Recommended Git Workflow for Your Project\n\n**1. Structured Commit Strategy:**\n- Use semantic commit messages (feat:, docs:, refactor:, fix:)\n- Claude can automatically generate properly formatted commits\n- Regular commits for documentation milestones and rollback points\n\n**2. Branch Management for Major Sections:**\n- Create feature branches for each proposal section development\n- Main branch stays stable with completed work\n- Easy rollback to any previous state\n\n**3. Documentation Milestones:**\n- Commit after completing each major proposal section\n- Tag important versions (e.g., v1.0-draft, v1.1-wfu-alignment)\n- Create releases for proposal submission versions\n\n**4. GitHub Integration:**\n- Use GitHub CLI (gh) for creating issues and PRs\n- Track proposal development progress with GitHub Projects\n- Collaborate with advisors through PR reviews\n\n### Immediate Actions Needed:\n1. Commit the new specs/ framework we just created\n2. Set up branch protection rules for main\n3. Create development workflow documentation\n4. Establish tagging strategy for proposal versions\n\nThis workflow will provide systematic version control, clear rollback points, and professional documentation management for your research leave proposal development."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":277,"cache_read_input_tokens":61114,"output_tokens":39,"service_tier":"standard"}},"requestId":"req_011CQFo3aTSNuPJdpFeC5CiY","type":"assistant","uuid":"1596f714-bcf0-4ec5-a2b4-2a0b083ab387","timestamp":"2025-06-18T13:50:51.671Z"}
{"parentUuid":"1596f714-bcf0-4ec5-a2b4-2a0b083ab387","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"User has approved your plan. You can now start coding.","tool_use_id":"toolu_01ReVrvwWTPHHPbX8SVghpoK"}]},"uuid":"a7dd03a1-ace5-4412-9265-dcf8dc3f8b41","timestamp":"2025-06-18T13:51:36.656Z","toolUseResult":{"plan":"## Git and GitHub Workflow Plan for ITS4LL Project\n\n### Claude Code's Git Capabilities\n\n**✅ Full Git Support:**\n- Complete Git command access through Bash tool\n- Automatic commit message generation with attribution\n- Branch management and merging capabilities\n- GitHub CLI integration for PR/issue management\n\n**✅ Current Repository Status:**\n- Active branch: main, up to date with origin\n- Recent commits show good documentation practices\n- Untracked specs/ directory ready for initial commit\n- Modified research_leave.qmd needs staging\n\n### Recommended Git Workflow for Your Project\n\n**1. Structured Commit Strategy:**\n- Use semantic commit messages (feat:, docs:, refactor:, fix:)\n- Claude can automatically generate properly formatted commits\n- Regular commits for documentation milestones and rollback points\n\n**2. Branch Management for Major Sections:**\n- Create feature branches for each proposal section development\n- Main branch stays stable with completed work\n- Easy rollback to any previous state\n\n**3. Documentation Milestones:**\n- Commit after completing each major proposal section\n- Tag important versions (e.g., v1.0-draft, v1.1-wfu-alignment)\n- Create releases for proposal submission versions\n\n**4. GitHub Integration:**\n- Use GitHub CLI (gh) for creating issues and PRs\n- Track proposal development progress with GitHub Projects\n- Collaborate with advisors through PR reviews\n\n### Immediate Actions Needed:\n1. Commit the new specs/ framework we just created\n2. Set up branch protection rules for main\n3. Create development workflow documentation\n4. Establish tagging strategy for proposal versions\n\nThis workflow will provide systematic version control, clear rollback points, and professional documentation management for your research leave proposal development."}}
{"parentUuid":"a7dd03a1-ace5-4412-9265-dcf8dc3f8b41","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01Ef2Y2m1qdoycTsLqvXo3Nx","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Great! Claude Code has excellent Git and GitHub integration. Let me show you the key capabilities and set up an effective workflow for your ITS4LL project.\n\n## Claude Code's Git & GitHub Capabilities\n\n**🔧 Full Git Command Access** - I can run any Git command through the Bash tool\n**📝 Smart Commit Generation** - Claude automatically creates well-formatted commit messages with attribution\n**🌿 Branch Management** - Complete support for branching, merging, and workflow management\n**🚀 GitHub CLI Integration** - Full `gh` command support for PRs, issues, and repository management\n\n## Let's Set Up Your Workflow"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":467,"cache_read_input_tokens":61391,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFo7sw2KGiENMvQpeqLQ","type":"assistant","uuid":"13c57f7b-ccba-4be9-a812-9ffb58f0f378","timestamp":"2025-06-18T13:51:43.065Z"}
{"parentUuid":"13c57f7b-ccba-4be9-a812-9ffb58f0f378","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01Ef2Y2m1qdoycTsLqvXo3Nx","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_018mKTK2LDQ2j13ec3eW4tuY","name":"TodoWrite","input":{"todos":[{"id":"analysis_complete","content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high"},{"id":"create_specs_dir","content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high"},{"id":"setup_git_workflow","content":"Commit specs framework and establish Git workflow","status":"in_progress","priority":"high"},{"id":"wfu_alignment","content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high"},{"id":"personal_narrative","content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high"},{"id":"evaluation_framework","content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high"},{"id":"irb_planning","content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium"},{"id":"timing_justification","content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium"},{"id":"leave_history","content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":467,"cache_read_input_tokens":61391,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFo7sw2KGiENMvQpeqLQ","type":"assistant","uuid":"3ad75b7c-0bd6-4145-973b-d2abb8841b98","timestamp":"2025-06-18T13:51:49.324Z"}
{"parentUuid":"3ad75b7c-0bd6-4145-973b-d2abb8841b98","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018mKTK2LDQ2j13ec3eW4tuY","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"57161af8-3a65-4c60-9fd3-a658e51abf2b","timestamp":"2025-06-18T13:51:49.345Z","toolUseResult":{"oldTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high","id":"create_specs_dir"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}],"newTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high","id":"create_specs_dir"},{"content":"Commit specs framework and establish Git workflow","status":"in_progress","priority":"high","id":"setup_git_workflow"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}]}}
{"parentUuid":"57161af8-3a65-4c60-9fd3-a658e51abf2b","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01LXy3Jk4GPBqBA8Fy58ahzG","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01MfjhDif3coztNBJRhgQkFd","name":"Bash","input":{"command":"git status","description":"Check current repository status before committing"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":889,"cache_read_input_tokens":61858,"output_tokens":30,"service_tier":"standard"}},"requestId":"req_011CQFo8p1uaLtK1kPyUrBai","type":"assistant","uuid":"59b6e587-568c-43c9-9ceb-99fc28fdf8f0","timestamp":"2025-06-18T13:51:54.265Z"}
{"parentUuid":"59b6e587-568c-43c9-9ceb-99fc28fdf8f0","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01LXy3Jk4GPBqBA8Fy58ahzG","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Ga7MxQUGxhUjStEzk865VY","name":"Bash","input":{"command":"git diff","description":"Review changes to research_leave.qmd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":889,"cache_read_input_tokens":61858,"output_tokens":30,"service_tier":"standard"}},"requestId":"req_011CQFo8p1uaLtK1kPyUrBai","type":"assistant","uuid":"c693090e-ad75-4d68-abf7-3badf274f55b","timestamp":"2025-06-18T13:51:54.686Z"}
{"parentUuid":"c693090e-ad75-4d68-abf7-3badf274f55b","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ga7MxQUGxhUjStEzk865VY","type":"tool_result","content":"diff --git a/docs/grants/research_leave.qmd b/docs/grants/research_leave.qmd\nindex cff3e00..80cf6fb 100644\n--- a/docs/grants/research_leave.qmd\n+++ b/docs/grants/research_leave.qmd\n@@ -24,10 +24,8 @@ Explain how this project addresses critical needs in:\n Detail how this project:\n \n - Enhances Wake Forest's reputation in educational technology\n-  - Wake Forest's commitment to innovation in teaching and learning\n-  - Central motto *Pro Humanitate* aligns with project goals to improve educational outcomes for students engaged in learning about and engaging with other cultures\n-\n-\n+- Wake Forest's commitment to innovation in teaching and learning\n+- Central motto *Pro Humanitate* aligns with project goals to improve educational outcomes for students engaged in learning about and engaging with other cultures\n - Aligns with university's teaching excellence mission\n - Potential for interdisciplinary collaboration\n - Student learning benefits","is_error":false}]},"uuid":"8da3f813-4f9a-49cc-b9b4-1c2409af10c0","timestamp":"2025-06-18T13:51:54.774Z","toolUseResult":{"stdout":"diff --git a/docs/grants/research_leave.qmd b/docs/grants/research_leave.qmd\nindex cff3e00..80cf6fb 100644\n--- a/docs/grants/research_leave.qmd\n+++ b/docs/grants/research_leave.qmd\n@@ -24,10 +24,8 @@ Explain how this project addresses critical needs in:\n Detail how this project:\n \n - Enhances Wake Forest's reputation in educational technology\n-  - Wake Forest's commitment to innovation in teaching and learning\n-  - Central motto *Pro Humanitate* aligns with project goals to improve educational outcomes for students engaged in learning about and engaging with other cultures\n-\n-\n+- Wake Forest's commitment to innovation in teaching and learning\n+- Central motto *Pro Humanitate* aligns with project goals to improve educational outcomes for students engaged in learning about and engaging with other cultures\n - Aligns with university's teaching excellence mission\n - Potential for interdisciplinary collaboration\n - Student learning benefits","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"8da3f813-4f9a-49cc-b9b4-1c2409af10c0","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MfjhDif3coztNBJRhgQkFd","type":"tool_result","content":"On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   docs/grants/research_leave.qmd\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tspecs/\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")","is_error":false}]},"uuid":"3ddd746d-9a75-49d3-825d-bfd4f8d6f1ce","timestamp":"2025-06-18T13:51:54.795Z","toolUseResult":{"stdout":"On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   docs/grants/research_leave.qmd\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tspecs/\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"3ddd746d-9a75-49d3-825d-bfd4f8d6f1ce","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01SemtWXvStdoeYi9GeknZ8q","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Perfect! Now let me create a comprehensive Git workflow and commit our new specs framework:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":265,"cache_creation_input_tokens":300,"cache_read_input_tokens":62747,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFo9DEuM5pyNi5wQqHfd","type":"assistant","uuid":"f0d4ae80-e132-44e4-ad9a-1ae166d44044","timestamp":"2025-06-18T13:51:58.359Z"}
{"parentUuid":"f0d4ae80-e132-44e4-ad9a-1ae166d44044","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01SemtWXvStdoeYi9GeknZ8q","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01XhvFduB53vfxJ7wqDhWhfe","name":"Bash","input":{"command":"git add specs/","description":"Stage the new specs directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":265,"cache_creation_input_tokens":300,"cache_read_input_tokens":62747,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFo9DEuM5pyNi5wQqHfd","type":"assistant","uuid":"abe4368e-cb41-47b1-a8ae-c8dd8e539b94","timestamp":"2025-06-18T13:51:59.384Z"}
{"parentUuid":"abe4368e-cb41-47b1-a8ae-c8dd8e539b94","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01SemtWXvStdoeYi9GeknZ8q","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01CLERB1HMsfWrxd9pPupnjM","name":"Bash","input":{"command":"git add docs/grants/research_leave.qmd","description":"Stage the formatting changes to research leave document"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":265,"cache_creation_input_tokens":300,"cache_read_input_tokens":62747,"output_tokens":164,"service_tier":"standard"}},"requestId":"req_011CQFo9DEuM5pyNi5wQqHfd","type":"assistant","uuid":"cbaf0432-67f8-402a-a0a2-712c02f1e0dc","timestamp":"2025-06-18T13:51:59.875Z"}
{"parentUuid":"cbaf0432-67f8-402a-a0a2-712c02f1e0dc","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XhvFduB53vfxJ7wqDhWhfe","type":"tool_result","content":"","is_error":false}]},"uuid":"70a08974-b7af-4a1d-b1a0-97752fff0f5f","timestamp":"2025-06-18T13:51:59.959Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"70a08974-b7af-4a1d-b1a0-97752fff0f5f","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CLERB1HMsfWrxd9pPupnjM","type":"tool_result","content":"","is_error":false}]},"uuid":"911cb067-de3e-48ad-8705-a2626c23b877","timestamp":"2025-06-18T13:52:00.035Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"911cb067-de3e-48ad-8705-a2626c23b877","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_0156RHzpqSapCV12kNywhMUB","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01BMBvJu7DtcSC8keBTq3VjC","name":"Bash","input":{"command":"git commit -m \"$(cat <<'EOF'\nfeat: Add project specifications framework for research leave proposal development\n\n- Create specs/ directory for centralized planning documentation\n- Add comprehensive research leave proposal analysis with section-by-section status\n- Establish development priority matrix and 4-week implementation timeline\n- Include progress tracking framework and success metrics\n- Minor formatting improvements to research leave proposal structure\n\nThis framework provides systematic approach to proposal development with clear\nrollback points and progress tracking capabilities.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"","description":"Commit the specs framework with detailed message"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":501,"cache_read_input_tokens":63047,"output_tokens":219,"service_tier":"standard"}},"requestId":"req_011CQFo9bLgj7VAJP2PHdMSo","type":"assistant","uuid":"bdf4a2c4-2a37-4a65-a2eb-3da509f60f3e","timestamp":"2025-06-18T13:52:08.316Z"}
{"parentUuid":"bdf4a2c4-2a37-4a65-a2eb-3da509f60f3e","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BMBvJu7DtcSC8keBTq3VjC","type":"tool_result","content":"[main 2e5de86] feat: Add project specifications framework for research leave proposal development\n 3 files changed, 263 insertions(+), 4 deletions(-)\n create mode 100644 specs/README.md\n create mode 100644 specs/research_leave_analysis.md","is_error":false}]},"uuid":"fc892b7b-22cd-4ff0-8384-82abf869b980","timestamp":"2025-06-18T13:52:24.151Z","toolUseResult":{"stdout":"[main 2e5de86] feat: Add project specifications framework for research leave proposal development\n 3 files changed, 263 insertions(+), 4 deletions(-)\n create mode 100644 specs/README.md\n create mode 100644 specs/research_leave_analysis.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"fc892b7b-22cd-4ff0-8384-82abf869b980","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01SY6tXnBVdNdA8QG9hNmz8J","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Now let me create a Git workflow documentation file in your specs directory:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":303,"cache_read_input_tokens":63548,"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CQFoBQ6pRN9sRrVfnTz6b","type":"assistant","uuid":"b2644f94-4f65-4931-90d4-5eab9d75197e","timestamp":"2025-06-18T13:52:28.801Z"}
{"parentUuid":"b2644f94-4f65-4931-90d4-5eab9d75197e","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01SY6tXnBVdNdA8QG9hNmz8J","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01B5J8DosWCuhPU4ibQb1hfd","name":"Write","input":{"file_path":"/Users/francojc/Documents/GitHub/francojc/its/specs/git_workflow.md","content":"# Git & GitHub Workflow for ITS4LL Project\n\n**Purpose:** Systematic version control and collaboration workflow for research leave proposal development  \n**Created:** December 18, 2024\n\n## Claude Code Git Capabilities\n\n### ✅ What Claude Code Can Do\n\n**Git Operations:**\n- Complete Git command access through Bash tool\n- Automatic commit message generation with proper attribution\n- Branch creation, switching, merging, and deletion\n- View history, diffs, and repository status\n- Stash management and conflict resolution\n\n**GitHub Integration:**\n- Full GitHub CLI (`gh`) support for repository management\n- Create and manage pull requests programmatically\n- Issue creation and management\n- Repository settings and collaboration features\n- Release and tag management\n\n**Smart Commit Features:**\n- Automatic semantic commit message generation (feat:, docs:, fix:, refactor:)\n- Consistent attribution with Claude Code branding\n- Multi-line commit messages with detailed descriptions\n- HEREDOC format for complex commit messages\n\n### 🔧 Recommended Workflow Commands\n\n#### Creating Feature Branches\n```bash\n# Create branch for specific proposal section\ngit checkout -b feature/wfu-alignment\ngit checkout -b feature/evaluation-framework\ngit checkout -b docs/irb-requirements\n```\n\n#### Making Strategic Commits\n```bash\n# Claude will generate semantic commit messages\ngit add docs/grants/research_leave.qmd\ngit commit -m \"docs: Add Wake Forest University strategic alignment section\"\n\n# For complex changes, Claude uses HEREDOC format\ngit commit -m \"$(cat <<'EOF'\nfeat: Implement comprehensive evaluation framework for student learning assessment\n\n- Add pre/post assessment protocols for language proficiency\n- Create rubrics for pedagogical effectiveness evaluation\n- Establish baseline measurement procedures\n- Include long-term learning outcome tracking\n\nThis framework enables rigorous evaluation of AI tutoring system effectiveness\nand provides foundation for academic publication of results.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n```\n\n#### Managing Development Workflow\n```bash\n# Check status and plan commits\ngit status\ngit diff\n\n# View recent commits\ngit log --oneline -10\n\n# Create rollback points\ngit tag v1.0-specs-framework\ngit tag v1.1-wfu-analysis\ngit tag v1.2-evaluation-framework\n\n# Push with tags\ngit push origin main --tags\n```\n\n## Structured Development Approach\n\n### Branch Strategy\n\n**Main Branch (`main`):**\n- Stable, completed work only\n- All commits should be ready for review\n- Protected from direct pushes (recommended)\n\n**Feature Branches:**\n- `feature/section-name` - Major proposal sections\n- `docs/document-type` - Documentation updates\n- `refactor/improvement-type` - Structural improvements\n\n**Development Process:**\n1. Create feature branch for each major section\n2. Regular commits with semantic messages\n3. Merge to main when section is complete\n4. Tag major milestones for easy rollback\n\n### Commit Message Standards\n\n**Semantic Prefixes:**\n- `feat:` - New proposal sections or major additions\n- `docs:` - Documentation updates and improvements\n- `refactor:` - Restructuring without content changes\n- `fix:` - Corrections and error fixes\n- `style:` - Formatting and style improvements\n\n**Example Commit Messages:**\n```\nfeat: Add faculty development narrative with scholarly trajectory\ndocs: Enhance IRB requirements section with ethical considerations\nrefactor: Restructure timeline section for better clarity\nfix: Correct citation formats in literature review references\n```\n\n### Milestone Tagging Strategy\n\n**Version Format:** `vX.Y-description`\n\n**Milestone Examples:**\n- `v1.0-foundation` - Initial analysis and framework\n- `v1.1-wfu-alignment` - Wake Forest strategic alignment complete\n- `v1.2-evaluation` - Evaluation frameworks implemented\n- `v2.0-first-draft` - Complete first draft ready for review\n- `v2.1-advisor-feedback` - Incorporated advisor feedback\n- `v3.0-final-submission` - Final proposal submission version\n\n### GitHub Integration Workflow\n\n#### Issue Tracking\n```bash\n# Create issues for major tasks\ngh issue create --title \"Develop Wake Forest University alignment section\" --body \"Research WFU strategic priorities and connect to project significance\"\n\n# List and manage issues\ngh issue list\ngh issue close 1\n```\n\n#### Pull Request Workflow\n```bash\n# Create PR from feature branch\ngh pr create --title \"Add evaluation framework for student assessment\" --body \"Implements comprehensive evaluation protocols for measuring AI tutoring effectiveness\"\n\n# Review and merge PRs\ngh pr list\ngh pr merge 1 --squash\n```\n\n#### Repository Management\n```bash\n# Create releases for major milestones\ngh release create v2.0-first-draft --title \"First Complete Draft\" --notes \"Complete research leave proposal ready for initial review\"\n\n# View repository status\ngh repo view\ngh repo clone francojc/its  # For collaborators\n```\n\n## Rollback and Recovery Strategies\n\n### Safe Rollback Points\n\n**Immediate Rollback (Uncommitted Changes):**\n```bash\n# Discard working directory changes\ngit restore docs/grants/research_leave.qmd\n\n# Discard all uncommitted changes\ngit restore .\n```\n\n**Commit-Level Rollback:**\n```bash\n# View commit history\ngit log --oneline -10\n\n# Reset to specific commit (keeping changes)\ngit reset --soft HEAD~1\n\n# Reset to specific commit (discarding changes)\ngit reset --hard abc1234\n```\n\n**Branch-Level Recovery:**\n```bash\n# Create backup branch before major changes\ngit branch backup-before-major-edits\n\n# Return to previous state\ngit checkout backup-before-major-edits\ngit checkout -b recovery-branch\n```\n\n### Tag-Based Recovery\n```bash\n# List all tags\ngit tag\n\n# Return to tagged version\ngit checkout v1.1-wfu-analysis\n\n# Create new branch from tag\ngit checkout -b fix-from-v1.1 v1.1-wfu-analysis\n```\n\n## Collaboration Best Practices\n\n### Working with Advisors\n\n**Branch Sharing:**\n```bash\n# Push feature branch for advisor review\ngit push origin feature/evaluation-framework\n\n# Create PR for structured feedback\ngh pr create --title \"Evaluation Framework for Review\" --draft\n```\n\n**Review Integration:**\n```bash\n# Incorporate feedback as separate commits\ngit add docs/grants/research_leave.qmd\ngit commit -m \"docs: Address advisor feedback on evaluation methodology\"\n\n# Squash commits before final merge\ngit rebase -i HEAD~3\n```\n\n### Documentation Synchronization\n\n**Keeping Specs Updated:**\n```bash\n# Regular updates to analysis document\ngit add specs/research_leave_analysis.md\ngit commit -m \"docs: Update proposal analysis with completed sections\"\n\n# Cross-reference commits in specs\n# Link to specific commits for traceability\n```\n\n## Emergency Recovery Procedures\n\n### Lost Work Recovery\n```bash\n# Find lost commits in reflog\ngit reflog\n\n# Recover from reflog\ngit checkout -b recovery abc1234\n\n# Cherry-pick specific changes\ngit cherry-pick def5678\n```\n\n### Corrupted Repository Recovery\n```bash\n# Clone fresh copy\ngit clone https://github.com/francojc/its.git its-recovery\n\n# Copy working files to fresh clone\ncp -r specs/ ../its-recovery/\ncd ../its-recovery\n```\n\n## Success Metrics for Git Workflow\n\n### Process Indicators\n- [ ] Regular commits (daily during active development)\n- [ ] Semantic commit messages consistently used\n- [ ] All major milestones tagged for rollback capability\n- [ ] Feature branches used for major section development\n- [ ] Clean main branch with stable, reviewed content\n\n### Collaboration Metrics\n- [ ] Clear PR descriptions for advisor review\n- [ ] Issues used to track development tasks\n- [ ] Documentation kept current with development progress\n- [ ] Rollback procedures tested and verified\n\n## Quick Reference Commands\n\n### Daily Workflow\n```bash\n# Start work session\ngit status\ngit pull origin main\n\n# During work\ngit add .\ngit commit -m \"docs: Add XYZ section to proposal\"\n\n# End work session\ngit push origin main\n```\n\n### Emergency Commands\n```bash\n# Quick backup\ngit branch backup-$(date +%Y%m%d)\n\n# Undo last commit (keep changes)\ngit reset --soft HEAD~1\n\n# View recent activity\ngit log --oneline -5\ngit reflog -5\n```\n\n---\n\n*This workflow document should be updated as project requirements evolve and new Git patterns emerge.*"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":303,"cache_read_input_tokens":63548,"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CQFoBQ6pRN9sRrVfnTz6b","type":"assistant","uuid":"ca78952a-8442-4e8f-b3f9-7a1486d1ea2b","timestamp":"2025-06-18T13:53:05.690Z"}
{"parentUuid":"ca78952a-8442-4e8f-b3f9-7a1486d1ea2b","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01B5J8DosWCuhPU4ibQb1hfd","type":"tool_result","content":"File created successfully at: /Users/francojc/Documents/GitHub/francojc/its/specs/git_workflow.md"}]},"uuid":"45d23fd1-99a5-40ff-b4e2-f9502b35bae3","timestamp":"2025-06-18T13:53:05.707Z","toolUseResult":{"type":"create","filePath":"/Users/francojc/Documents/GitHub/francojc/its/specs/git_workflow.md","content":"# Git & GitHub Workflow for ITS4LL Project\n\n**Purpose:** Systematic version control and collaboration workflow for research leave proposal development  \n**Created:** December 18, 2024\n\n## Claude Code Git Capabilities\n\n### ✅ What Claude Code Can Do\n\n**Git Operations:**\n- Complete Git command access through Bash tool\n- Automatic commit message generation with proper attribution\n- Branch creation, switching, merging, and deletion\n- View history, diffs, and repository status\n- Stash management and conflict resolution\n\n**GitHub Integration:**\n- Full GitHub CLI (`gh`) support for repository management\n- Create and manage pull requests programmatically\n- Issue creation and management\n- Repository settings and collaboration features\n- Release and tag management\n\n**Smart Commit Features:**\n- Automatic semantic commit message generation (feat:, docs:, fix:, refactor:)\n- Consistent attribution with Claude Code branding\n- Multi-line commit messages with detailed descriptions\n- HEREDOC format for complex commit messages\n\n### 🔧 Recommended Workflow Commands\n\n#### Creating Feature Branches\n```bash\n# Create branch for specific proposal section\ngit checkout -b feature/wfu-alignment\ngit checkout -b feature/evaluation-framework\ngit checkout -b docs/irb-requirements\n```\n\n#### Making Strategic Commits\n```bash\n# Claude will generate semantic commit messages\ngit add docs/grants/research_leave.qmd\ngit commit -m \"docs: Add Wake Forest University strategic alignment section\"\n\n# For complex changes, Claude uses HEREDOC format\ngit commit -m \"$(cat <<'EOF'\nfeat: Implement comprehensive evaluation framework for student learning assessment\n\n- Add pre/post assessment protocols for language proficiency\n- Create rubrics for pedagogical effectiveness evaluation\n- Establish baseline measurement procedures\n- Include long-term learning outcome tracking\n\nThis framework enables rigorous evaluation of AI tutoring system effectiveness\nand provides foundation for academic publication of results.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n```\n\n#### Managing Development Workflow\n```bash\n# Check status and plan commits\ngit status\ngit diff\n\n# View recent commits\ngit log --oneline -10\n\n# Create rollback points\ngit tag v1.0-specs-framework\ngit tag v1.1-wfu-analysis\ngit tag v1.2-evaluation-framework\n\n# Push with tags\ngit push origin main --tags\n```\n\n## Structured Development Approach\n\n### Branch Strategy\n\n**Main Branch (`main`):**\n- Stable, completed work only\n- All commits should be ready for review\n- Protected from direct pushes (recommended)\n\n**Feature Branches:**\n- `feature/section-name` - Major proposal sections\n- `docs/document-type` - Documentation updates\n- `refactor/improvement-type` - Structural improvements\n\n**Development Process:**\n1. Create feature branch for each major section\n2. Regular commits with semantic messages\n3. Merge to main when section is complete\n4. Tag major milestones for easy rollback\n\n### Commit Message Standards\n\n**Semantic Prefixes:**\n- `feat:` - New proposal sections or major additions\n- `docs:` - Documentation updates and improvements\n- `refactor:` - Restructuring without content changes\n- `fix:` - Corrections and error fixes\n- `style:` - Formatting and style improvements\n\n**Example Commit Messages:**\n```\nfeat: Add faculty development narrative with scholarly trajectory\ndocs: Enhance IRB requirements section with ethical considerations\nrefactor: Restructure timeline section for better clarity\nfix: Correct citation formats in literature review references\n```\n\n### Milestone Tagging Strategy\n\n**Version Format:** `vX.Y-description`\n\n**Milestone Examples:**\n- `v1.0-foundation` - Initial analysis and framework\n- `v1.1-wfu-alignment` - Wake Forest strategic alignment complete\n- `v1.2-evaluation` - Evaluation frameworks implemented\n- `v2.0-first-draft` - Complete first draft ready for review\n- `v2.1-advisor-feedback` - Incorporated advisor feedback\n- `v3.0-final-submission` - Final proposal submission version\n\n### GitHub Integration Workflow\n\n#### Issue Tracking\n```bash\n# Create issues for major tasks\ngh issue create --title \"Develop Wake Forest University alignment section\" --body \"Research WFU strategic priorities and connect to project significance\"\n\n# List and manage issues\ngh issue list\ngh issue close 1\n```\n\n#### Pull Request Workflow\n```bash\n# Create PR from feature branch\ngh pr create --title \"Add evaluation framework for student assessment\" --body \"Implements comprehensive evaluation protocols for measuring AI tutoring effectiveness\"\n\n# Review and merge PRs\ngh pr list\ngh pr merge 1 --squash\n```\n\n#### Repository Management\n```bash\n# Create releases for major milestones\ngh release create v2.0-first-draft --title \"First Complete Draft\" --notes \"Complete research leave proposal ready for initial review\"\n\n# View repository status\ngh repo view\ngh repo clone francojc/its  # For collaborators\n```\n\n## Rollback and Recovery Strategies\n\n### Safe Rollback Points\n\n**Immediate Rollback (Uncommitted Changes):**\n```bash\n# Discard working directory changes\ngit restore docs/grants/research_leave.qmd\n\n# Discard all uncommitted changes\ngit restore .\n```\n\n**Commit-Level Rollback:**\n```bash\n# View commit history\ngit log --oneline -10\n\n# Reset to specific commit (keeping changes)\ngit reset --soft HEAD~1\n\n# Reset to specific commit (discarding changes)\ngit reset --hard abc1234\n```\n\n**Branch-Level Recovery:**\n```bash\n# Create backup branch before major changes\ngit branch backup-before-major-edits\n\n# Return to previous state\ngit checkout backup-before-major-edits\ngit checkout -b recovery-branch\n```\n\n### Tag-Based Recovery\n```bash\n# List all tags\ngit tag\n\n# Return to tagged version\ngit checkout v1.1-wfu-analysis\n\n# Create new branch from tag\ngit checkout -b fix-from-v1.1 v1.1-wfu-analysis\n```\n\n## Collaboration Best Practices\n\n### Working with Advisors\n\n**Branch Sharing:**\n```bash\n# Push feature branch for advisor review\ngit push origin feature/evaluation-framework\n\n# Create PR for structured feedback\ngh pr create --title \"Evaluation Framework for Review\" --draft\n```\n\n**Review Integration:**\n```bash\n# Incorporate feedback as separate commits\ngit add docs/grants/research_leave.qmd\ngit commit -m \"docs: Address advisor feedback on evaluation methodology\"\n\n# Squash commits before final merge\ngit rebase -i HEAD~3\n```\n\n### Documentation Synchronization\n\n**Keeping Specs Updated:**\n```bash\n# Regular updates to analysis document\ngit add specs/research_leave_analysis.md\ngit commit -m \"docs: Update proposal analysis with completed sections\"\n\n# Cross-reference commits in specs\n# Link to specific commits for traceability\n```\n\n## Emergency Recovery Procedures\n\n### Lost Work Recovery\n```bash\n# Find lost commits in reflog\ngit reflog\n\n# Recover from reflog\ngit checkout -b recovery abc1234\n\n# Cherry-pick specific changes\ngit cherry-pick def5678\n```\n\n### Corrupted Repository Recovery\n```bash\n# Clone fresh copy\ngit clone https://github.com/francojc/its.git its-recovery\n\n# Copy working files to fresh clone\ncp -r specs/ ../its-recovery/\ncd ../its-recovery\n```\n\n## Success Metrics for Git Workflow\n\n### Process Indicators\n- [ ] Regular commits (daily during active development)\n- [ ] Semantic commit messages consistently used\n- [ ] All major milestones tagged for rollback capability\n- [ ] Feature branches used for major section development\n- [ ] Clean main branch with stable, reviewed content\n\n### Collaboration Metrics\n- [ ] Clear PR descriptions for advisor review\n- [ ] Issues used to track development tasks\n- [ ] Documentation kept current with development progress\n- [ ] Rollback procedures tested and verified\n\n## Quick Reference Commands\n\n### Daily Workflow\n```bash\n# Start work session\ngit status\ngit pull origin main\n\n# During work\ngit add .\ngit commit -m \"docs: Add XYZ section to proposal\"\n\n# End work session\ngit push origin main\n```\n\n### Emergency Commands\n```bash\n# Quick backup\ngit branch backup-$(date +%Y%m%d)\n\n# Undo last commit (keep changes)\ngit reset --soft HEAD~1\n\n# View recent activity\ngit log --oneline -5\ngit reflog -5\n```\n\n---\n\n*This workflow document should be updated as project requirements evolve and new Git patterns emerge.*","structuredPatch":[]}}
{"parentUuid":"45d23fd1-99a5-40ff-b4e2-f9502b35bae3","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01ScA1DgCT7ihKpn9ert4aXT","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_0153saYWzqQQknbR2ftVpGft","name":"Bash","input":{"command":"git add specs/git_workflow.md","description":"Stage the new Git workflow documentation"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":2160,"cache_read_input_tokens":63851,"output_tokens":35,"service_tier":"standard"}},"requestId":"req_011CQFoESpN9Dns3aCebvjEV","type":"assistant","uuid":"9c02e863-9c2a-4218-bf4f-75918227e016","timestamp":"2025-06-18T13:53:11.392Z"}
{"parentUuid":"9c02e863-9c2a-4218-bf4f-75918227e016","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01ScA1DgCT7ihKpn9ert4aXT","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_017185SJCMMjjuFaqLaNLxFY","name":"Bash","input":{"command":"git commit -m \"$(cat <<'EOF'\ndocs: Add comprehensive Git workflow documentation for project management\n\n- Establish semantic commit message standards and branching strategy\n- Document Claude Code's full Git and GitHub CLI capabilities  \n- Create rollback procedures and milestone tagging approach\n- Include collaboration workflows for advisor review process\n- Add emergency recovery procedures and quick reference commands\n\nThis provides systematic version control approach for research leave proposal\ndevelopment with clear rollback points at every stage.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"","description":"Commit the Git workflow documentation"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":2160,"cache_read_input_tokens":63851,"output_tokens":35,"service_tier":"standard"}},"requestId":"req_011CQFoESpN9Dns3aCebvjEV","type":"assistant","uuid":"954d0c4c-e464-4398-ad3f-7eba354ee06e","timestamp":"2025-06-18T13:53:14.357Z"}
{"parentUuid":"954d0c4c-e464-4398-ad3f-7eba354ee06e","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0153saYWzqQQknbR2ftVpGft","type":"tool_result","content":"","is_error":false}]},"uuid":"30c3a500-1e70-4967-9038-97deef7d7b30","timestamp":"2025-06-18T13:53:14.458Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"30c3a500-1e70-4967-9038-97deef7d7b30","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017185SJCMMjjuFaqLaNLxFY","type":"tool_result","content":"[main 12d939e] docs: Add comprehensive Git workflow documentation for project management\n 1 file changed, 316 insertions(+)\n create mode 100644 specs/git_workflow.md","is_error":false}]},"uuid":"a0a75475-d885-4161-a61f-dbf249d26cef","timestamp":"2025-06-18T14:46:33.374Z","toolUseResult":{"stdout":"[main 12d939e] docs: Add comprehensive Git workflow documentation for project management\n 1 file changed, 316 insertions(+)\n create mode 100644 specs/git_workflow.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"a0a75475-d885-4161-a61f-dbf249d26cef","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01Fhw9WZkfav5nfbRdx6WEqz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Now let me create a first milestone tag for this framework:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":66741,"cache_read_input_tokens":0,"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CQFsJtxZCdLQu8aHXitze","type":"assistant","uuid":"e0a4d441-c01e-4e7e-8bbe-43c652b2df19","timestamp":"2025-06-18T14:46:42.535Z"}
{"parentUuid":"e0a4d441-c01e-4e7e-8bbe-43c652b2df19","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01Fhw9WZkfav5nfbRdx6WEqz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01Jw8tEoYLCbRULXiNhU8aBg","name":"Bash","input":{"command":"git tag v1.0-specs-framework -m \"Project specifications framework and Git workflow established\"","description":"Create milestone tag for specs framework completion"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":66741,"cache_read_input_tokens":0,"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CQFsJtxZCdLQu8aHXitze","type":"assistant","uuid":"c7276150-1de5-4c87-b9ba-1f5434db942a","timestamp":"2025-06-18T14:46:44.802Z"}
{"parentUuid":"c7276150-1de5-4c87-b9ba-1f5434db942a","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_01Fhw9WZkfav5nfbRdx6WEqz","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_01K7yfuTMBvGMHHFN9vqjtsB","name":"Bash","input":{"command":"git push origin main --tags","description":"Push commits and tags to remote repository"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":66741,"cache_read_input_tokens":0,"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CQFsJtxZCdLQu8aHXitze","type":"assistant","uuid":"d5691531-cb42-438b-b7ba-08938cdd0739","timestamp":"2025-06-18T14:46:46.397Z"}
{"parentUuid":"d5691531-cb42-438b-b7ba-08938cdd0739","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Jw8tEoYLCbRULXiNhU8aBg","type":"tool_result","content":"","is_error":false}]},"uuid":"2bfb02b8-2f0b-4b16-b9f2-f6a701888d7d","timestamp":"2025-06-18T14:47:03.830Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"2bfb02b8-2f0b-4b16-b9f2-f6a701888d7d","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01K7yfuTMBvGMHHFN9vqjtsB","type":"tool_result","content":"To github.com:francojc/Spanish-ITS.git\n   9552596..12d939e  main -> main\n * [new tag]         v1.0-specs-framework -> v1.0-specs-framework","is_error":false}]},"uuid":"f397ae5c-d953-439c-bf89-8f72be90dcfc","timestamp":"2025-06-18T14:47:06.723Z","toolUseResult":{"stdout":"To github.com:francojc/Spanish-ITS.git\n   9552596..12d939e  main -> main\n * [new tag]         v1.0-specs-framework -> v1.0-specs-framework","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"f397ae5c-d953-439c-bf89-8f72be90dcfc","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_016SgMk5VhX29qg2yS1ed9bK","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"tool_use","id":"toolu_012qLTNz5nSuxmi1UnkdVvRH","name":"TodoWrite","input":{"todos":[{"id":"analysis_complete","content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high"},{"id":"create_specs_dir","content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high"},{"id":"setup_git_workflow","content":"Commit specs framework and establish Git workflow","status":"completed","priority":"high"},{"id":"wfu_alignment","content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high"},{"id":"personal_narrative","content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high"},{"id":"evaluation_framework","content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high"},{"id":"irb_planning","content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium"},{"id":"timing_justification","content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium"},{"id":"leave_history","content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium"}]}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":700,"cache_read_input_tokens":66741,"output_tokens":374,"service_tier":"standard"}},"requestId":"req_011CQFsMN4mjDYYNtZjeUWyp","type":"assistant","uuid":"3aebb053-186a-46b9-bb5d-15fbf18358c8","timestamp":"2025-06-18T14:47:17.275Z"}
{"parentUuid":"3aebb053-186a-46b9-bb5d-15fbf18358c8","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012qLTNz5nSuxmi1UnkdVvRH","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"5c79219f-c6f8-40ab-a969-2fa07ceece86","timestamp":"2025-06-18T14:47:17.300Z","toolUseResult":{"oldTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high","id":"create_specs_dir"},{"content":"Commit specs framework and establish Git workflow","status":"in_progress","priority":"high","id":"setup_git_workflow"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}],"newTodos":[{"content":"Complete analysis of research leave proposal sections","status":"completed","priority":"high","id":"analysis_complete"},{"content":"Create specs/ directory and add research leave proposal analysis","status":"completed","priority":"high","id":"create_specs_dir"},{"content":"Commit specs framework and establish Git workflow","status":"completed","priority":"high","id":"setup_git_workflow"},{"content":"Research Wake Forest University's strategic priorities and educational technology initiatives","status":"pending","priority":"high","id":"wfu_alignment"},{"content":"Develop faculty development section with scholarly trajectory narrative","status":"pending","priority":"high","id":"personal_narrative"},{"content":"Design detailed evaluation frameworks for student learning assessment","status":"pending","priority":"high","id":"evaluation_framework"},{"content":"Develop IRB requirements and ethical considerations section","status":"pending","priority":"medium","id":"irb_planning"},{"content":"Strengthen justification for leave timing with research momentum narrative","status":"pending","priority":"medium","id":"timing_justification"},{"content":"Document previous leave record and scholarly productivity pattern","status":"pending","priority":"medium","id":"leave_history"}]}}
{"parentUuid":"5c79219f-c6f8-40ab-a969-2fa07ceece86","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","message":{"id":"msg_011v1uwhNMVnLa8umpqM4iA6","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[{"type":"text","text":"Perfect! I've established a comprehensive Git and GitHub workflow for your ITS4LL project. Here's what we've accomplished:\n\n## ✅ Git Workflow Framework Complete\n\n**Systematic Version Control:**\n- Created `specs/git_workflow.md` with complete documentation\n- Established semantic commit standards (feat:, docs:, refactor:, fix:)\n- Set up milestone tagging strategy (`v1.0-specs-framework` created)\n- Documented rollback procedures and emergency recovery\n\n**Claude Code's Full Capabilities:**\n- **Git Operations:** Complete command access, smart commit generation, branch management\n- **GitHub Integration:** Full `gh` CLI support for PRs, issues, releases\n- **Collaboration Features:** Structured workflows for advisor review and feedback integration\n\n**Key Benefits for Your Project:**\n1. **Clear Rollback Points** - Every major section gets its own tag for easy recovery\n2. **Professional Commits** - Automatic semantic messages with Claude attribution\n3. **Systematic Development** - Feature branches for each proposal section\n4. **Advisor Collaboration** - PR-based review workflow with structured feedback\n\n## How to Use This Going Forward\n\n**For Each Proposal Section:**\n```bash\n# Create feature branch\ngit checkout -b feature/wfu-alignment\n\n# Work on section, Claude commits automatically\n# Claude generates: \"docs: Add Wake Forest strategic alignment section\"\n\n# Merge and tag when complete\ngit checkout main\ngit merge feature/wfu-alignment\ngit tag v1.1-wfu-alignment\n```\n\n**Quick Commands You'll Use:**\n- `git status` - Check what's changed\n- `git log --oneline -5` - See recent commits\n- `git tag` - List all milestone versions\n- `gh pr create` - Get advisor feedback on sections\n\nThe framework is now committed and tagged as `v1.0-specs-framework`, giving you a solid rollback point. Ready to start on the high-priority sections like WFU strategic alignment research?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":741,"cache_read_input_tokens":67441,"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CQFsN8eQeBJSdwZPmXAWT","type":"assistant","uuid":"bd8edee8-5177-4d4e-bb8e-a49c149c967e","timestamp":"2025-06-18T14:47:29.090Z"}
{"parentUuid":"92ad797c-c7ff-4907-9258-b93d83c03789","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"<bash-input>gl</bash-input>"},"uuid":"b7e23195-8deb-41a9-b3c0-56d0f0a9c6da","timestamp":"2025-06-18T14:47:39.174Z"}
{"parentUuid":"b7e23195-8deb-41a9-b3c0-56d0f0a9c6da","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"<bash-stdout>* 12d939e - (66 seconds ago) docs: Add comprehensive Git workflow documentation for project management - francojc (HEAD -> main, tag: v1.0-specs-framework, origin/main, origin/HEAD)\n* 2e5de86 - (55 minutes ago) feat: Add project specifications framework for research leave proposal development - francojc\n* 9552596 - (2 hours ago) docs: Enhance research leave documentation with project details and alignment. - Jerid Francom\n* 806feec - (15 hours ago) feat: Add research leave proposal for ITS4LL project - francojc\n* cf7298f - (16 hours ago) refactor: update CLAUDE.md with detailed file path guidelines - francojc\n* 30cac17 - (16 hours ago) Okay, here's a concise one-line commit message based on the provided literature review and discussion: - francojc\n* e8b6d6f - (17 hours ago) feat: Implement RAG system with Gemma 3 for ITS4LL language tutoring - francojc\n* 3bf37bf - (17 hours ago) feat: Add CLAUDE.md documentation and update literature review with Bloom's 2 Sigma Problem analysis - francojc\n* c090bc1 - (18 hours ago) feat: Add technical plan and documentation for ITS4LL system - francojc\n| * 15fac6b - (18 hours ago) Claude Code Review workflow - Jerid Francom (origin/add-claude-github-actions-1750191648089, origin/add-claude-github-actions-1750191647845)\n| * cb1016c - (18 hours ago) Claude PR Assistant workflow - Jerid Francom\n|/  \n* f913891 - (3 weeks ago) feat: Add survey paper on LLMs in education with key findings and future directions. - francojc\n* ed77663 - (3 weeks ago) fix: Update citation to use the correct BibTeX key for Ye et al. (2025) - francojc\n* c7cd078 - (3 weeks ago) feat: Add LLM tutoring system design considerations and literature review updates - francojc\n* a23ea9c - (3 weeks ago) feat: Add literature review and update site content - francojc\n* 6207280 - (6 weeks ago) chore: Update reference file path for Kahl et al. 2024 - francojc\n* ae03212 - (7 weeks ago) feat: integrate fine-tuning, rag, and local deployment for llm tutoring - francojc\n* ee56589 - (9 weeks ago) feat: add literature review for LLM research proposal - francojc\n* 28a4e02 - (9 weeks ago) docs: add literature review for adaptive second language tutoring project - francojc\n* 241596c - (9 weeks ago) chore: remove nix-direnv-reload script and update website title - francojc\n* 804a190 - (9 weeks ago) docs: add literature review for adaptive second language tutoring project - francojc\n* 150e37e - (4 months ago) feat: Add academic integrity post and remove old post with code - francojc\n* 668856a - (4 months ago) feat: Add fine-tuning post and update gitignore, add flake.lock - francojc\n* a268cf2 - (4 months ago) feat: Initial commit for STEP grant proposal and Nix environment setup - francojc\n* a45197a - (4 months ago) feat: Incorporate suggestions to improve grant proposal document - francojc\" (aider)\n* cdbf03d - (4 months ago) fix: Clarify language learning challenges and project scope - francojc\n* bc113b2 - (4 months ago) feat: Elaborate on the problem statement in the grant proposal. - francojc\" (aider)\n* 2ca100a - (4 months ago) feat: Expand grant proposal with project details and student impact - francojc\n* d5da950 - (4 months ago) feat: Clarify project goals and success metrics in proposal - francojc\" (aider)\n* 711aac8 - (4 months ago) feat: Draft STEP grant proposal for adaptive language tutoring with LLMs - francojc\n* 7520f4a - (4 months ago) feat: Add bibliography and update project proposal details - francojc\n* 843fd4b - (4 months ago) refactor: Restructure and enhance STEP grant proposal draft with comprehensive details - francojc\n* 0f550a1 - (4 months ago) updates proposal - francojc\n* b9482a1 - (4 months ago) updates to draft outline - francojc\n* 8f5f9aa - (4 months ago) initial commit - francojc</bash-stdout><bash-stderr></bash-stderr>"},"uuid":"7949ac4d-df52-4178-bc1a-485bc3e9e844","timestamp":"2025-06-18T14:47:39.251Z"}
{"parentUuid":"92ad797c-c7ff-4907-9258-b93d83c03789","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"<user-memory-input>In Markdown (md) and Quarto (qmd) documents, make sure to add a line between: \n\n- headers and body\n- body and bullet lists</user-memory-input>"},"uuid":"29473737-f702-45ab-9ac7-a56d0bef2955","timestamp":"2025-06-18T14:49:30.436Z"}
{"parentUuid":"29473737-f702-45ab-9ac7-a56d0bef2955","isSidechain":false,"userType":"external","cwd":"/Users/francojc/Documents/GitHub/francojc/its","sessionId":"b249a4ac-a629-4b98-aa1e-abb0fba6e476","version":"1.0.21","type":"user","message":{"role":"user","content":"(no content)"},"uuid":"8a4e168f-d30d-4f37-ac23-2ab280b1c6d4","timestamp":"2025-06-18T14:49:30.451Z"}
